[[REDES/archivos/bibliografia/Tema3Redes.pdf|Tema3Redes]]
[[REDES/archivos/bibliografia/[1] Redes de Computadores.pdf|[1] Redes de Computadores]]

# Introducción
La capa de transporte es un componente clave en la arquitectura de redes, cuya función es asegurar que los datos enviados desde una aplicación en el origen lleguen de manera correcta al proceso de destino. Aquí te explico de manera más detallada los puntos clave de la capa de transporte:
### Funciones principales de la capa de transporte:
1. **Preparación de los datos para la transmisión**: 
   - La capa de transporte recibe los datos (mensajes) generados por las aplicaciones y los prepara para su transmisión. Dependiendo del protocolo que se utilice (TCP o UDP), los datos pueden fragmentarse en segmentos o simplemente añadírseles una cabecera.
   
2. **Entrega de los datos al destino**: 
   - Una vez que los datos llegan al destino, la capa de transporte es responsable de reconstruir los mensajes (si fueron fragmentados) y entregarlos al proceso correcto en el sistema receptor.

3. **Independencia del canal no fiable**: 
   - La capa de transporte no necesita conocer cómo funciona el canal de transmisión (la capa inferior que maneja los paquetes), ya que se asume que puede haber muchos errores en la transmisión. El objetivo es realizar una **comunicación lógica** entre el origen y el destino, sin importar cómo se manejen los errores en las capas inferiores.
![[archivos/imagenes/Pasted image 20241018195728.png]]

4. **Comunicación lógica**:
   - La capa de transporte permite una comunicación lógica entre los procesos en el origen y el destino. Esto significa que el envío de datos se percibe como una comunicación directa entre aplicaciones, aunque físicamente los datos atraviesan múltiples dispositivos y redes intermedias.

5. **Implementación en el origen y destino**: 
   - La capa de transporte está presente solo en los dispositivos de origen y destino, no en los routers intermedios. Los routers se ocupan de las capas inferiores, como la red, pero no gestionan los detalles del transporte de datos.

### Protocolos en la capa de transporte:
1. **TCP (Transmission Control Protocol)**:
   - **Fragmentación de mensajes**: TCP divide los mensajes en segmentos más pequeños.
   - **Cabecera de control**: A cada segmento se le añade una cabecera con información necesaria para asegurar la correcta transmisión y el control de errores.
   - TCP garantiza que los segmentos se entreguen en el orden correcto y sin errores, gracias a mecanismos como la retransmisión de segmentos perdidos.
![[archivos/imagenes/Pasted image 20241018195754.png]]
2. **UDP (User Datagram Protocol)**:
   - UDP no realiza fragmentación de mensajes ni garantiza la entrega ordenada. Simplemente añade una cabecera a los datos y los envía. Es más rápido, pero menos fiable que TCP.

### Nomenclatura en las capas:
- **Capa de aplicación**: los datos se llaman **mensajes**.
- **Capa de transporte**: los datos se dividen en **segmentos** (en TCP) o permanecen como mensajes (en UDP).
- **Capa de red**: los segmentos o mensajes se encapsulan en **paquetes** o **datagramas**.
- **Capa de enlace**: los paquetes o datagramas se convierten en **tramas** (frames).

Este esquema de comunicación a través de capas permite que cada capa cumpla su función sin necesidad de conocer los detalles de las capas superiores o inferiores. En particular, la capa de transporte se encarga de asegurar la correcta transmisión de datos entre aplicaciones, sin importar los detalles de cómo se manejen los errores en las capas inferiores.

## Multiplexión y demultiplexión
La **multiplexión** y **demultiplexión** son conceptos clave en el funcionamiento de la capa de transporte en las redes de comunicación, ya que se encargan de gestionar el envío y recepción de mensajes entre múltiples aplicaciones a través de una red.

### Multiplexión
La **multiplexión** es el proceso en el cual la capa de transporte recoge datos de múltiples procesos de aplicación, los organiza y los envía a través de la red. Esto se hace recorriendo cada uno de los sockets asociados a las aplicaciones, procesando los datos de cada socket, y enviando los segmentos (paquetes) correspondientes a la red. Cada proceso de aplicación tiene su propio socket, lo cual permite que varios procesos diferentes transmitan datos simultáneamente. La multiplexión asegura que los datos de distintos procesos sean recogidos y enviados a través de la red de manera ordenada.

**Ejemplo**: 
Imagina que tienes tres aplicaciones en un mismo dispositivo transmitiendo información (por ejemplo, una aplicación de chat, una aplicación de correo y una aplicación de streaming). Cada una tiene su propio socket. La capa de transporte recoge los datos de cada aplicación, genera segmentos, y luego los envía a la red a través de un único enlace físico. Esto es multiplexión.

### Demultiplexión
La **demultiplexión** ocurre en el lado del receptor. Aquí, la capa de transporte recibe segmentos de la capa de red, reconstruye los mensajes originales y los distribuye a los sockets correspondientes en función de los números de puerto que identifican a cada socket. De esta manera, los procesos en el lado del receptor pueden recoger los mensajes que les corresponden.

**Ejemplo**: 
Cuando un servidor recibe datos de múltiples clientes, la capa de transporte se encarga de procesar esos datos, identificando a qué socket (y, por tanto, a qué proceso) deben ser entregados. Así, los mensajes de cada cliente llegan al proceso correcto.
![[archivos/imagenes/Pasted image 20241018200435.png]]
### Identificación mediante puertos
Para identificar a qué socket corresponde un mensaje, se usan los **números de puerto**, que son enteros de 16 bits (0-65535). Estos números permiten diferenciar qué proceso debe recibir los datos en el sistema. Los puertos entre 0-1023 están reservados para servicios bien conocidos (como HTTP o FTP), mientras que los puertos superiores a 1024 están disponibles para las aplicaciones de usuario.
![[archivos/imagenes/Pasted image 20241018200452.png]]
### Multiplexión y Demultiplexión con sockets sin conexión (UDP)
En el caso de **UDP** (User Datagram Protocol), los sockets se identifican únicamente por la dirección IP de destino y el puerto de destino. Por ejemplo, un servidor que proporciona la hora del día a múltiples clientes (como el servicio daytime en el puerto 13) recibe datagramas de diferentes clientes y responde a cada uno de forma individual. Todos los datagramas se entregan al mismo puerto de destino, pero el puerto de origen permite que el servidor sepa a quién responder.
![[archivos/imagenes/Pasted image 20241018200547.png]]
### Multiplexión y Demultiplexión con sockets orientados a conexión (TCP)
En el caso de **TCP** (Transmission Control Protocol), los sockets se identifican con una tupla de 4 elementos: la dirección IP de origen, la dirección IP de destino, el puerto de origen y el puerto de destino. Esto significa que TCP puede gestionar múltiples conexiones al mismo puerto de destino, ya que las direcciones IP y los puertos de origen pueden ser diferentes. Así, un servidor web (que escucha en el puerto 80 o 443) puede atender a múltiples clientes simultáneamente, distinguiendo cada conexión por su IP y puerto de origen.
![[archivos/imagenes/Pasted image 20241018200605.png]]
### Sockets de Servidor y Conexión en TCP
En TCP, hay dos tipos de sockets:
1. **Socket de servidor**: Solo espera conexiones de clientes.
2. **Socket de conexión**: Se encarga de manejar una conexión específica. 

Cuando un cliente establece una conexión con un servidor, el socket de servidor transfiere la conexión a un socket de conexión dedicado a esa interacción. Así, múltiples conexiones pueden ser manejadas simultáneamente por un solo servidor, como ocurre en servicios como **telnet** o **HTTP**.
![[archivos/imagenes/Pasted image 20241018200647.png]]
Estos mecanismos permiten que múltiples aplicaciones en diferentes dispositivos puedan comunicarse de manera eficiente y ordenada a través de la red, utilizando un solo enlace físico pero gestionando múltiples flujos de datos simultáneos.
![[archivos/imagenes/Pasted image 20241018200659.png]]

## Capa de Transporte Sin Conexión: UDP
UDP (User Datagram Protocol) es un protocolo de transporte de capa 4 en el modelo OSI. A diferencia de TCP, es un protocolo sin conexión, lo que significa que no establece una conexión entre el emisor y el receptor antes de enviar los datos, ni garantiza que los datos lleguen en orden o sin errores. Aquí tienes una explicación más clara de sus características y funcionamiento:

### Funcionamiento básico:
1. **En el origen**: UDP toma el mensaje que se va a enviar y le añade una cabecera simple para formar lo que se conoce como un "segmento". La cabecera de UDP tiene solo 4 campos:
   - **Puerto de origen**: identifica el puerto desde donde se envían los datos.
![[archivos/imagenes/Pasted image 20241019190923.png]]
   - **Puerto de destino**: identifica el puerto del receptor.
   - **Longitud total**: el tamaño del segmento (incluyendo la cabecera y los datos).
   - **Suma de comprobación**: usada para detectar errores en los datos.

2. **En el destino**: UDP verifica si el segmento llegó sin errores utilizando la suma de comprobación. Si no hay errores, los datos se pasan al socket para ser procesados por la aplicación. Si hay errores, el segmento puede descartarse, aunque en algunas implementaciones podría entregarse con un aviso de error.

### Características principales:
- **Sin conexión**: No hay una negociación previa entre emisor y receptor. Los segmentos simplemente se envían sin establecer una conexión. Esto reduce la latencia, ya que no hay un proceso de "handshake" como en TCP.
- **Sin retransmisión ni control de errores avanzado**: UDP no garantiza la entrega de los segmentos ni los retransmite si se pierden o llegan con errores. Tampoco reordena los segmentos que puedan llegar fuera de orden.
- **Procesamiento rápido y bajo consumo de recursos**: Debido a que no mantiene el estado de la conexión ni tiene mecanismos de control de errores sofisticados, UDP es muy eficiente. Esto lo hace ideal para servidores que necesitan atender a muchos clientes simultáneamente o para aplicaciones que priorizan la velocidad.
- **Cabeceras más pequeñas**: La cabecera de UDP es mucho más pequeña que la de TCP, lo que implica un procesamiento más rápido y menos sobrecarga de almacenamiento y transmisión.
- **Mayor control para las aplicaciones**: Las aplicaciones que usan UDP pueden implementar sus propios mecanismos de control si es necesario, como la numeración de datos o la detección de errores adicional.

### Ejemplo de la suma de comprobación:
- En UDP, la suma de comprobación se usa para detectar errores en el segmento (tanto en los datos como en la cabecera).
- En el origen, se suman todas las palabras de 16 bits del segmento. Luego se realiza un complemento a 1 del resultado y se inserta en el campo de suma de comprobación.
- Al llegar al destino, se recalcula la suma de comprobación y si coincide con la original, significa que el paquete llegó sin errores.
### Usos de UDP:
UDP es útil en aplicaciones donde la velocidad es más importante que la confiabilidad. Algunos ejemplos incluyen:
- **Streaming de audio y video**: Las pequeñas pérdidas de datos no suelen afectar la calidad general de la transmisión.
- **DNS (Domain Name System)**: Las consultas DNS deben ser rápidas y una retransmisión puede hacerse a nivel de la aplicación si es necesario.
- **Herramientas de gestión de redes**: Donde la pérdida ocasional de datos no es crítica.

UDP es preferido en situaciones donde el tiempo de respuesta rápido es crucial, y la pérdida de datos se considera aceptable o puede manejarse de otra manera.


# Fundamentos de la transmisión fiable
La transmisión fiable se refiere a la capacidad de garantizar que los datos enviados a través de una red lleguen correctamente al receptor. Para lograrlo, se utilizan **protocolos de retransmisión** conocidos como **ARQ (Automatic Repeat reQuest)** o solicitud automática de repetición. Estos protocolos retransmiten paquetes si se detecta un error o si un paquete no llega al destino. Aquí se explican dos tipos de protocolos ARQ: **parar y esperar** y **ventana deslizante**.

## Protocolo ARQ: Parar y esperar
En este protocolo, el emisor envía un paquete y luego se detiene a esperar una confirmación (ACK) del receptor antes de enviar el siguiente paquete. Es un proceso simple pero ineficiente si hay mucha latencia o pérdida de paquetes.

**Casos que pueden ocurrir en este protocolo:**

1. **Caso sin errores**:
   - El receptor recibe el paquete correctamente y envía un **ACK** (confirmación) al emisor. El número del ACK es el número del siguiente paquete esperado. 
   - Una vez que el emisor recibe el ACK, envía el siguiente paquete.
   
   Ejemplo:
   - El emisor envía el paquete 0.
   - El receptor recibe el paquete 0 y envía el ACK1 (indicando que espera el paquete 1).
   - El emisor recibe el ACK1 y envía el paquete 1.

2. **Caso de pérdida de paquetes**:
   - Si un paquete se pierde en el camino o llega con errores, el receptor no enviará el ACK.
   - El emisor tiene un **temporizador** que empieza a contar cuando se envía el paquete. Si no recibe el ACK antes de que el temporizador expire, retransmite el paquete.

   Ejemplo:
   - El emisor envía el paquete 0, pero este se pierde.
   - El temporizador del emisor expira y retransmite el paquete 0.
   - El receptor finalmente recibe el paquete 0 y envía el ACK1.
![[archivos/imagenes/Pasted image 20241019195949.png]]

3. **Caso de pérdida de ACK**:
   - Si el ACK se pierde, el emisor no sabrá que el receptor recibió el paquete. Entonces, cuando el temporizador expire, retransmitirá el paquete.
   - El receptor, al recibir un paquete duplicado (porque ya lo procesó antes), simplemente reconoce que es un duplicado y envía el ACK correspondiente nuevamente.

   Ejemplo:
   - El emisor envía el paquete 0, el receptor lo recibe, pero el ACK1 se pierde.
   - El temporizador del emisor expira y retransmite el paquete 0.
   - El receptor ya procesó el paquete 0, lo reconoce como duplicado y vuelve a enviar el ACK1.
![[archivos/imagenes/Pasted image 20241019200035.png]]
4. **Vencimiento del temporizador**:
   - Si el temporizador se configura con un tiempo muy corto o hay congestión en la red, tanto los paquetes como los ACK pueden retrasarse.
   - El emisor puede recibir duplicados de ACKs o de paquetes debido a este retraso, pero los identifica por el número de secuencia y los ignora si ya fueron procesados.

   Ejemplo:
   - El emisor envía el paquete 0 y el receptor envía el ACK1.
   - Sin embargo, debido a la congestión, el temporizador del emisor expira antes de recibir el ACK, y retransmite el paquete.
   - El receptor recibe el paquete 0 nuevamente, lo ignora y envía el ACK1 duplicado.
![[archivos/imagenes/Pasted image 20241019200108.png]]

## Tiempo desperdiciado en ARQ para-y-esperar
El protocolo ARQ parar y esperar tiene una desventaja significativa: **desperdicia mucho tiempo**, ya que el emisor tiene que esperar a recibir una confirmación (ACK) antes de enviar el siguiente paquete. Durante este tiempo de espera, el enlace de comunicación está inactivo, lo que reduce la eficiencia de la transmisión. Este tiempo de inactividad se llama **tiempo desperdiciado**.
### Desglose de tiempos en ARQ parar y esperar

1. **Tiempo de transmisión (ttrans)**: Es el tiempo que toma al emisor enviar un paquete de datos. Este tiempo depende del tamaño del paquete (L, en bits) y la velocidad de transmisión del enlace (R, en bits por segundo o bps). Se puede calcular con la fórmula:
   $$t_{\text{trans}} = \frac{L}{R}$$

2. **Tiempo de ida y vuelta (RTT - Round Trip Time)**: Es el tiempo que tarda un paquete en ir desde el emisor al receptor, más el tiempo que tarda en regresar el ACK desde el receptor al emisor. Incluye cualquier retraso de propagación en la red.

3. **Tiempo total para transmitir un paquete**: Cada vez que se envía un paquete, el tiempo total que se invierte incluye tanto el tiempo de transmisión como el tiempo de espera para recibir el ACK, que está basado en el RTT. Por lo tanto, el **tiempo total** que se toma para transmitir un solo paquete y recibir su confirmación es:

   $$\text{Tiempo total} = RTT + t_{\text{trans}}$$

### Utilización del enlace (U)

La **utilización del enlace** es la proporción del tiempo en que el emisor realmente está enviando datos, frente al tiempo total (que incluye tanto la transmisión como la espera). Es decir, es el **tiempo útil** dividido por el **tiempo total**. Se calcula de la siguiente forma:

$$U = \frac{t_{\text{trans}}}{RTT + t_{\text{trans}}}$$

Aquí:
- $t_{\text{trans}}$ es el tiempo de transmisión del paquete.
- $RTT$ es el tiempo de ida y vuelta para enviar el paquete y recibir el ACK.

### Explicación

- **Cuando \( RTT \) es grande** en comparación con $t_{\text{trans}}$, la utilización $U$ será pequeña, lo que significa que el enlace está inactivo la mayor parte del tiempo.
- **Cuando \( RTT \) es pequeño** en relación con $t_{\text{trans}}$, la utilización $U$ será alta, lo que significa que el enlace se utiliza eficientemente.

#### Ejemplo

Si un paquete tiene una longitud de 8000 bits (L = 8000 bits) y la velocidad de transmisión es de 1 Mbps (R = 1,000,000 bits/seg), entonces:


$$t_{\text{trans}} = \frac{8000 \text{ bits}}{1,000,000 \text{ bps}} = 0.008 \text{ segundos}$$

Si el RTT es de 0.1 segundos, la utilización del enlace será:

$$U = \frac{0.008}{0.1 + 0.008} = \frac{0.008}{0.108} \approx 0.074$$

Esto significa que solo el **7.4% del tiempo** el enlace está siendo utilizado para enviar datos, mientras que el **92.6% del tiempo** está inactivo esperando el ACK.

### Conclusión

En el protocolo **parar y esperar**, el tiempo desperdiciado aumenta a medida que el **RTT** crece en relación con el **tiempo de transmisión**. Esto hace que el protocolo sea ineficiente en redes con **alta latencia** o **altas tasas de transmisión**, ya que el enlace permanece inactivo la mayor parte del tiempo. Para mejorar esta eficiencia, se utilizan otros protocolos como el **ventana deslizante**, que permiten que el emisor envíe varios paquetes antes de recibir las confirmaciones.


## ARQ con ventana deslizante (entubamiento)

El protocolo **ARQ con ventana deslizante**, también conocido como **entubamiento**, es una mejora sobre el protocolo "parar y esperar", y su principal ventaja es que **reduce el tiempo perdido** esperando confirmaciones (ACKs). En lugar de enviar un paquete y esperar una confirmación antes de enviar el siguiente, el emisor puede enviar **varios paquetes consecutivos** (hasta un número máximo $N$ antes de recibir los ACKs. Esto mejora considerablemente la **utilización del enlace**.

### Concepto de ventana deslizante

1. **Ventana emisora**: Es el conjunto de hasta $N$ paquetes que el emisor puede enviar antes de recibir una confirmación. Estos paquetes pueden haber sido enviados, pero aún no han sido reconocidos. El emisor debe mantener una copia de estos paquetes en memoria en caso de que necesiten ser retransmitidos.
   
2. **Ventana receptora**: Es el conjunto de hasta $N$ paquetes que el receptor puede aceptar y procesar, pero que aún no ha reconocido. El receptor debe tener memoria suficiente para almacenar estos paquetes hasta que sean procesados y confirmados.

### Funcionamiento

El emisor envía varios paquetes de manera consecutiva sin esperar una confirmación por cada uno. La ventana del emisor se va desplazando conforme el emisor recibe los ACKs de los paquetes. Por ejemplo, si la ventana tiene un tamaño de  $N = 5$, el emisor puede enviar 5 paquetes, pero la ventana solo avanzará cuando reciba confirmaciones de los paquetes. Cuando se recibe un ACK, la ventana "desliza" y permite que el emisor envíe más paquetes.
![[archivos/imagenes/Pasted image 20241019205036.png]]
### Cálculo de la utilización del enlace

La **utilización del enlace** se mejora al permitir que se transmitan múltiples paquetes antes de recibir un ACK. El porcentaje de utilización se calcula como:

$$
U = \frac{N \cdot t_{\text{trans}}}{RTT + t_{\text{trans}}}$$

Donde:
- $N \cdot t_{\text{trans}}$ es el tiempo total que el emisor utiliza para transmitir $N$ paquetes.
- $RTT + t_{\text{trans}}$ es el tiempo total que incluye tanto la transmisión de los paquetes como el tiempo de ida y vuelta $RTT$ para recibir el ACK.

Para que el emisor no desperdicie tiempo y la utilización del enlace sea máxima $U = 1$, es necesario que:

$$
N \cdot t_{\text{trans}} \geq RTT + t_{\text{trans}}
$$

De esto se obtiene la condición para que el protocolo sea eficiente:

$$
N \geq 1 + \frac{RTT}{t_{\text{trans}}}
$$

### Requerimientos

Para que el **entubamiento** funcione correctamente, se deben cumplir ciertos requerimientos:

1. **Rango de números de secuencia**: El rango de números de secuencia debe abarcar al menos el doble de la cantidad de paquetes que se pueden enviar de golpe (es decir,  $2N$). Esto es necesario para que no haya confusión entre paquetes viejos y nuevos que puedan usar el mismo número de secuencia.
   
2. **Almacenamiento en memoria**: Tanto el emisor como el receptor deben poder almacenar varios paquetes en memoria. El emisor guarda los paquetes que ha enviado pero aún no han sido reconocidos, y el receptor guarda los paquetes que ha recibido pero aún no ha procesado.

### Tipos de protocolos de ventana deslizante

Existen dos variantes principales de protocolos de ventana deslizante:

1. **Retroceso N (Go-Back-N, GBN)**: 
   - El receptor solo acepta paquetes en orden. Si un paquete se pierde o llega con errores, el receptor descarta todos los paquetes que lleguen después del paquete problemático.
   - El emisor debe reenviar no solo el paquete que falló, sino también todos los paquetes siguientes.
   - Los ACKs son **acumulativos**, lo que significa que un ACK para un paquete también confirma la recepción de todos los paquetes anteriores.

2. **Repetición selectiva**:
   - El receptor puede aceptar paquetes fuera de orden. Si un paquete se pierde o llega con errores, el receptor puede almacenar los paquetes posteriores y solo solicitar la retransmisión del paquete perdido.
   - Solo se retransmiten los paquetes que se pierden o llegan con errores, lo que mejora la eficiencia en comparación con Go-Back-N.
   - Se envía un ACK para cada paquete recibido correctamente, incluso si llegan fuera de orden.

![[archivos/imagenes/Pasted image 20241019205106.png]]
### Ejemplo de ventana deslizante

Imaginemos que el emisor tiene una **ventana de tamaño 5** $N = 5$. El emisor envía los paquetes 0, 1, 2, 3 y 4 consecutivamente. A medida que recibe los ACKs correspondientes, la ventana se desplaza permitiendo que el emisor envíe nuevos paquetes (como el paquete 5, 6, etc.).

- Si se utiliza **Go-Back-N** y el paquete 2 llega con errores, el receptor descartará los paquetes 3, 4, etc., y el emisor tendrá que reenviar todos los paquetes a partir del 2.
- Si se utiliza **Repetición selectiva**, el receptor aceptará los paquetes 3, 4, etc., aunque el paquete 2 se haya perdido, y solo solicitará la retransmisión del paquete 2.

### Conclusión

El **ARQ con ventana deslizante** mejora la eficiencia en comparación con el protocolo "parar y esperar", permitiendo al emisor transmitir varios paquetes antes de recibir ACKs. Esto reduce el tiempo de inactividad del enlace y mejora la utilización del mismo, especialmente en situaciones donde el RTT es elevado.
