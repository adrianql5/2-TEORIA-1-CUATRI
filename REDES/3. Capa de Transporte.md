[[REDES/archivos/bibliografia/[1] Redes de Computadores.pdf|[1] Redes de Computadores]]

Escrito por **Adrián Quiroga Linares**.
# 3.1 Introducción
La capa de transporte es un componente clave en la arquitectura de redes, cuya función es asegurar que los datos enviados desde una aplicación en el origen lleguen de manera correcta al proceso de destino. 

> [!Recordatorio]
> ![[archivos/imagenes/Pasted image 20241108205726.png]]

#### Funciones principales de la capa de transporte:
1. **Preparación de los datos para la transmisión**: 
   - La capa de transporte recibe los **datos** (mensajes) generados por las aplicaciones y los prepara para su transmisión. Dependiendo del protocolo que se utilice (*TCP o UDP*), los datos pueden **fragmentarse en segmentos** o simplemente **añadírseles una cabecera**.
   
2. **Entrega de los datos al destino**: 
   - Una vez que los datos llegan al destino, la capa de transporte es responsable de reconstruir los mensajes (si fueron fragmentados) y entregarlos al proceso correcto en el sistema receptor.

3. **Independencia del canal no fiable**: 
   - La capa de transporte no necesita conocer cómo funciona el canal de transmisión (la capa inferior que maneja los paquetes), ya que se asume que puede haber muchos errores en la transmisión. El objetivo es realizar una **comunicación lógica** entre el origen y el destino, sin importar cómo se manejen los errores en las capas inferiores.
![[archivos/imagenes/Pasted image 20241018195728.png]]

4. **Comunicación lógica**:
   - La capa de transporte permite una comunicación lógica entre los procesos en el origen y el destino. Esto significa que el envío de datos se percibe como una comunicación directa entre aplicaciones, aunque físicamente los datos atraviesan múltiples dispositivos y redes intermedias.

5. **Implementación en el origen y destino**: 
   - La capa de transporte está presente solo en los dispositivos de origen y destino, no en los routers intermedios. Los routers se ocupan de las capas inferiores, como la red, pero no gestionan los detalles del transporte de datos.

#### Protocolos en la capa de transporte:
1. **TCP (Transmission Control Protocol)**:
   - **Fragmentación de mensajes**: TCP divide los mensajes en segmentos más pequeños.
   - **Cabecera de control**: A cada segmento se le añade una cabecera con información necesaria para asegurar la correcta transmisión y el control de errores.
   - TCP garantiza que los segmentos se entreguen en el orden correcto y sin errores, gracias a mecanismos como la retransmisión de segmentos perdidos.

![[archivos/imagenes/Pasted image 20241018195754.png]]

2. **UDP (User Datagram Protocol)**:
   - UDP no realiza fragmentación de mensajes ni garantiza la entrega ordenada. Simplemente añade una cabecera a los datos y los envía. Es más rápido, pero menos fiable que TCP.

## 3.1.1 Multiplexión y demultiplexión
La **multiplexión** y **demultiplexión** son conceptos clave en el funcionamiento de la capa de transporte en las redes de comunicación, ya que se encargan de gestionar el envío y recepción de mensajes entre múltiples aplicaciones a través de una red.

#### Multiplexión
La **multiplexión** es el proceso en el cual la capa de transporte recoge datos de múltiples procesos de aplicación, los organiza y los envía a través de la red. Esto se hace recorriendo cada uno de los sockets asociados a las aplicaciones, procesando los datos de cada socket, y enviando los segmentos (*paquetes*) correspondientes a la red. Cada proceso de aplicación tiene su propio socket, lo cual permite que varios procesos diferentes transmitan datos simultáneamente. La multiplexión asegura que los datos de distintos procesos sean recogidos y enviados a través de la red de manera ordenada.

**Ejemplo**: 
Imagina que tienes tres aplicaciones en un mismo dispositivo transmitiendo información (*por ejemplo, una aplicación de chat, una aplicación de correo y una aplicación de streaming*). Cada una tiene su propio socket. La capa de transporte recoge los datos de cada aplicación, genera segmentos, y luego los envía a la red a través de un único enlace físico. Esto es multiplexión.

#### Demultiplexión
La **demultiplexión** ocurre en el lado del receptor. Aquí, la capa de transporte recibe segmentos de la capa de red, reconstruye los mensajes originales y los distribuye a los sockets correspondientes en función de los números de puerto que identifican a cada socket. De esta manera, los procesos en el lado del receptor pueden recoger los mensajes que les corresponden.

**Ejemplo**: 
Cuando un servidor recibe datos de múltiples clientes, la capa de transporte se encarga de procesar esos datos, identificando a qué socket (y, por tanto, a qué proceso) deben ser entregados. Así, los mensajes de cada cliente llegan al proceso correcto.

![[archivos/imagenes/Pasted image 20241018200435.png]]

#### Identificación mediante puertos
Para identificar a qué socket corresponde un mensaje, se usan los **números de puerto**, que son enteros de 16 bits (*0-65535*). Estos números permiten diferenciar qué proceso debe recibir los datos en el sistema. 

Los puertos entre 0-1023 están reservados para servicios bien conocidos (*como HTTP o FTP*), se conocen como **Puertos  Conocidos**.

Los puertos entre 1024-49152 están disponibles para las aplicaciones de usuario, se llaman **Puertos Registrados**.

Y los puertos restantes son los **Puertos Efímeros** que son los que se usan cuando por ejemplo abrimos varias pestañas de firefox simultáneamente, como no podemos usar el mismo puerto, el SO asigna a cada ventana un puerto efímero diferente, y al cerrarlas se liberan.

![[archivos/imagenes/Pasted image 20241018200452.png]]

#### Multiplexión y Demultiplexión con sockets sin conexión (UDP)
En el caso de **UDP** (User Datagram Protocol), los sockets se identifican únicamente por la dirección IP de destino y el puerto de destino. Por ejemplo, un servidor que proporciona la hora del día a múltiples clientes (como el servicio daytime en el puerto 13) recibe datagramas de diferentes clientes y responde a cada uno de forma individual. Todos los datagramas se entregan al mismo puerto de destino, pero el puerto de origen permite que el servidor sepa a quién responder.

![[archivos/imagenes/Pasted image 20241018200547.png]]

#### Multiplexión y Demultiplexión con sockets orientados a conexión (TCP)
En el caso de **TCP** (Transmission Control Protocol), los sockets se identifican con una tupla de 4 elementos: la dirección IP de origen, la dirección IP de destino, el puerto de origen y el puerto de destino. Esto significa que TCP puede gestionar múltiples conexiones al mismo puerto de destino, ya que las direcciones IP y los puertos de origen pueden ser diferentes. Así, un servidor web (que escucha en el puerto 80 o 443) puede atender a múltiples clientes simultáneamente, distinguiendo cada conexión por su IP y puerto de origen.

![[archivos/imagenes/Pasted image 20241018200605.png]]

#### Sockets de Servidor y Conexión en TCP
En TCP, hay dos tipos de sockets:
1. **Socket de servidor**: Solo espera conexiones de clientes.
2. **Socket de conexión**: Se encarga de manejar una conexión específica. 

Cuando un cliente establece una conexión con un servidor, el socket de servidor transfiere la conexión a un socket de conexión dedicado a esa interacción. Así, múltiples conexiones pueden ser manejadas simultáneamente por un solo servidor, como ocurre en servicios como **telnet** o **HTTP**.

![[archivos/imagenes/Pasted image 20241018200647.png]]

Estos mecanismos permiten que múltiples aplicaciones en diferentes dispositivos puedan comunicarse de manera eficiente y ordenada a través de la red, utilizando un solo enlace físico pero gestionando múltiples flujos de datos simultáneos.

![[archivos/imagenes/Pasted image 20241018200659.png]]

## 3.1.2 Capa de Transporte Sin Conexión: UDP
UDP (User Datagram Protocol) es un protocolo de transporte de capa 4 en el modelo OSI. A diferencia de TCP, es un protocolo sin conexión, lo que significa que no establece una conexión entre el emisor y el receptor antes de enviar los datos, ni garantiza que los datos lleguen en orden o sin errores. Aquí tienes una explicación más clara de sus características y funcionamiento:

#### Funcionamiento básico:
1. **En el origen**: UDP toma el mensaje que se va a enviar y le añade una cabecera simple para formar lo que se conoce como un "segmento". La cabecera de UDP tiene solo 4 campos:
   - **Puerto de origen**: identifica el puerto desde donde se envían los datos.
   
![[archivos/imagenes/Pasted image 20241019190923.png]]

   - **Puerto de destino**: identifica el puerto del receptor.
   - **Longitud total**: el tamaño del segmento (incluyendo la cabecera y los datos).
   - **Suma de comprobación**: usada para detectar errores en los datos.

2. **En el destino**: UDP verifica si el segmento llegó sin errores utilizando la suma de comprobación. Si no hay errores, los datos se pasan al socket para ser procesados por la aplicación. Si hay errores, el segmento puede descartarse, aunque en algunas implementaciones podría entregarse con un aviso de error.

#### Características principales:
- **Sin conexión**: No hay una negociación previa entre emisor y receptor. Los segmentos simplemente se envían sin establecer una conexión. Esto reduce la latencia, ya que no hay un proceso de "handshake" como en TCP.

- **Sin retransmisión ni control de errores avanzado**: UDP no garantiza la entrega de los segmentos ni los retransmite si se pierden o llegan con errores. Tampoco reordena los segmentos que puedan llegar fuera de orden.

- **Procesamiento rápido y bajo consumo de recursos**: Debido a que no mantiene el estado de la conexión ni tiene mecanismos de control de errores sofisticados, UDP es muy eficiente. Esto lo hace ideal para servidores que necesitan atender a muchos clientes simultáneamente o para aplicaciones que priorizan la velocidad.

- **Cabeceras más pequeñas**: La cabecera de UDP es mucho más pequeña que la de TCP, lo que implica un procesamiento más rápido y menos sobrecarga de almacenamiento y transmisión.

- **Mayor control para las aplicaciones**: Las aplicaciones que usan UDP pueden implementar sus propios mecanismos de control si es necesario, como la numeración de datos o la detección de errores adicional.

#### Ejemplo de la suma de comprobación:
- En UDP, la suma de comprobación se usa para detectar errores en el segmento (tanto en los datos como en la cabecera).
- En el origen, se suman todas las palabras de 16 bits del segmento. Luego se realiza un complemento a 1 del resultado y se inserta en el campo de suma de comprobación.
- Al llegar al destino, se recalcula la suma de comprobación y si coincide con la original, significa que el paquete llegó sin errores.

# 3.2 Fundamentos de la transmisión fiable
La transmisión fiable se refiere a la capacidad de garantizar que los datos enviados a través de una red lleguen correctamente al receptor. Para lograrlo, se utilizan **protocolos de retransmisión** conocidos como **ARQ (Automatic Repeat reQuest)** o solicitud automática de repetición. Estos protocolos retransmiten paquetes si se detecta un error o si un paquete no llega al destino. Aquí se explican dos tipos de protocolos ARQ: **parar y esperar** y **ventana deslizante**.

Las confirmaciones de recepción son los **ACKs** (*ACKnowledgment number*)

## 3.2.1 Protocolo ARQ: Parar y esperar
En este protocolo, el emisor envía un paquete y luego se detiene a esperar una confirmación (*ACK*) del receptor antes de enviar el siguiente paquete. Es un proceso simple pero ineficiente si hay mucha latencia o pérdida de paquetes.

**Casos que pueden ocurrir en este protocolo:**
1. **Caso sin errores**:
   - El receptor recibe el paquete correctamente y envía un **ACK** (*confirmación*) al emisor. El número del ACK es el número del siguiente paquete esperado. 
   - Una vez que el emisor recibe el ACK, envía el siguiente paquete.
   
2. **Caso de pérdida de paquetes**:
   - Si un paquete se pierde en el camino o llega con errores, el receptor no enviará el ACK.
   - El emisor tiene un **temporizador** que empieza a contar cuando se envía el paquete. Si no recibe el ACK antes de que el temporizador expire, retransmite el paquete.

![[archivos/imagenes/Pasted image 20241019195949.png]]

3. **Caso de pérdida de ACK**:
   - Si el ACK se pierde, el emisor no sabrá que el receptor recibió el paquete. Entonces, cuando el **temporizador** expire, retransmitirá el paquete.
   - El receptor, al recibir un paquete duplicado (*porque ya lo procesó antes*), simplemente reconoce que es un duplicado , **lo descarga** y **envía el ACK correspondiente nuevamente**.

4. **Vencimiento del temporizador**:
   - Si el temporizador se configura con un tiempo muy corto o hay congestión en la red, tanto los **paquetes como los ACK pueden retrasarse**.
   - El emisor puede recibir **duplicados de ACKs o de paquetes debido a este retraso**, pero los identifica por el número de secuencia y los **ignora si ya fueron procesados**.

![[archivos/imagenes/Pasted image 20241019200035.png]]

### NAK
Un **NAK** (*Negative-Acknowledge Character*), representado con dos ACKs iguales. Indica la recepción de un paquete con errores (*ya no espera al timeout para reenviar*). Cuando un paquete con errores llega, se devuelve el **ACK** del último correcto. Si vence el **temporizador**, se envían continuamente duplicados de paquetes. Para evitar este problema, son **tres ACKs los que equivalen a un NAK**. TCP usa este sistema con alguna variación.

![[archivos/imagenes/Pasted image 20241019200108.png]]

### Incoveniente de parar y esperar
La **poca utilización de enlace:**

![[archivos/imagenes/Pasted image 20241114191723.png]]

La **utilización del enlace** es la proporción del tiempo en que el emisor realmente está enviando datos, frente al tiempo total (que incluye tanto la transmisión como la espera). Es decir, es el **tiempo útil** dividido por el **tiempo total**. Se calcula de la siguiente forma:

$$U = \frac{t_{\text{trans}}}{RTT + t_{\text{trans}}}$$


## 3.2.2 ARQ con ventana deslizante (entubamiento)
El protocolo **ARQ con ventana deslizante**, también conocido como **entubamiento**, es una mejora sobre el protocolo "parar y esperar", y su principal ventaja es que **reduce el tiempo perdido** esperando confirmaciones (*ACKs*). En lugar de enviar un paquete y esperar una confirmación antes de enviar el siguiente, el emisor puede enviar **varios paquetes consecutivos** (*hasta un número máximo $N$ antes de recibir los ACKs*). Esto mejora considerablemente la **utilización del enlace**.

La **utilización del enlace** se mejora al permitir que se transmitan múltiples paquetes antes de recibir un ACK. 

$$
U = \frac{N \cdot t_{\text{trans}}}{RTT + t_{\text{trans}}}$$
La utilización es **máxima** cuando: 
$$
N \geq 1 + \frac{RTT}{t_{\text{trans}}}
$$


#### Conceptos de ventana deslizante
1. **Ventana emisora**: Es el conjunto de hasta $N$ paquetes que el emisor **puede enviar antes de recibir una confirmación**. Estos paquetes pueden haber sido enviados, pero aún **no han sido reconocidos**. 
   
2. **Ventana receptora**: Es el conjunto de hasta $N$ paquetes que el receptor **puede aceptar y procesar, pero que aún no ha reconocido**. .

3. **Rango de números de secuencia**: El rango de números de secuencia debe abarcar al menos el doble de la cantidad de paquetes que se pueden enviar de golpe (es decir,  $2N$). Esto es necesario para que no haya confusión entre paquetes viejos y nuevos que puedan usar el mismo número de secuencia.
   
4. **Almacenamiento en memoria**: Tanto el emisor como el receptor deben poder almacenar varios paquetes en memoria. El emisor guarda los paquetes que ha enviado pero aún no han sido reconocidos, y el receptor guarda los paquetes que ha recibido pero aún no ha procesado.

El emisor envía varios paquetes de manera consecutiva sin esperar una confirmación por cada uno. La ventana del emisor se va desplazando conforme el emisor recibe los ACKs de los paquetes. Por ejemplo, si la ventana tiene un tamaño de  $N = 5$, el emisor puede enviar 5 paquetes, pero la ventana solo avanzará cuando reciba confirmaciones de los paquetes. Cuando se recibe un ACK, la ventana **"desliza"** y permite que el **emisor envíe más paquetes**.

![[archivos/imagenes/Pasted image 20241019205036.png]]


### Tipos de ventana deslizante
Existen dos variantes principales de protocolos de ventana deslizante:

1. **Retroceso N (Go-Back-N, GBN)**: 
   - El receptor solo acepta paquetes en orden. Si un paquete se pierde o llega con errores, el receptor descarta todos los paquetes que lleguen después del paquete problemático.
   - El emisor debe reenviar no solo el paquete que falló, sino también todos los paquetes siguientes.
   - Los ACKs son **acumulativos**, lo que significa que un ACK para un paquete también confirma la recepción de todos los paquetes anteriores.

![[archivos/imagenes/Pasted image 20241114194736.png]]

2. **Repetición selectiva**:
   - El receptor puede aceptar paquetes fuera de orden. Si un paquete se pierde o llega con errores, el receptor puede almacenar los paquetes posteriores y solo solicitar la retransmisión del paquete perdido.
   - Solo se retransmiten los paquetes que se pierden o llegan con errores, lo que mejora la eficiencia en comparación con Go-Back-N.
   - Se envía un ACK para cada paquete recibido correctamente, incluso si llegan fuera de orden.

![[archivos/imagenes/Pasted image 20241114194656.png]]

![[archivos/imagenes/Pasted image 20241019205106.png]]

#### Conclusión
El **ARQ con ventana deslizante** mejora la eficiencia en comparación con el protocolo "parar y esperar", permitiendo al emisor transmitir varios paquetes antes de recibir ACKs. Esto reduce el tiempo de inactividad del enlace y mejora la utilización del mismo, especialmente en situaciones donde el RTT es elevado.

# 3.3 TCP
La capa de transporte en Internet se encarga de gestionar la comunicación confiable entre aplicaciones en distintos sistemas. TCP (*Transmission Control Protocol*) es un protocolo que asegura una transmisión de datos fiable y en orden. A continuación, se desglosan los aspectos técnicos más importantes de TCP, incluidos sus mecanismos de transmisión, numeración de secuencia, control de flujo y la conexión.

 **Números de secuencia**: TCP asigna números de secuencia a los segmentos de datos. Estos números de secuencia son de 32 bits y tienen algunas particularidades:

   - **Inicialización aleatoria**: En lugar de comenzar en 0, TCP elige un número aleatorio (llamémoslo $x$) como punto de partida, lo que ayuda a diferenciar distintas conexiones y reducir posibles problemas de seguridad.
   - **Incremento en función de los bytes enviados:** Cada segmento tiene su propio número de secuencia, que es igual al número del último byte del segmento anterior más el número de bytes del segmento actual.

![[archivos/imagenes/Pasted image 20241027104559.png]]

**Superposición (Piggybacking):** En muchas comunicaciones, los datos se transmiten en ambas direcciones. TCP optimiza el envío de datos y reconocimientos (*ACK*) utilizando una técnica llamada superposición o piggybacking. Esto significa que cuando un segmento de datos llega al receptor, este puede esperar un momento a enviar el ACK, combinándolo con los datos de respuesta para reducir el número de transmisiones.

![[archivos/imagenes/Pasted image 20241027104623.png]]

**Transferencia fiable de datos:** TCP utiliza **ACK acumulativos**, si el emisor envía varios segmentos, **un solo ACK puede confirmar múltiples segmentos**, lo cual es más eficiente. Si el emisor no recibe un ACK dentro del tiempo del temporizador, solo retransmitirá el segmento específico no reconocido, optimizando el uso de ancho de banda.
   
![[archivos/imagenes/Pasted image 20241027104711.png]]

**Duplicación del tiempo de espera:** Cuando el temporizador expira, **TCP retransmite el segmento y duplica el tiempo de espera del temporizador**. Este ajuste progresivo del temporizador ayuda a mejorar el rendimiento en redes con retrasos fluctuantes.

$\text{Temporizador} = \text{EstimacionRTT} + 4 \times \text{DevRTT}$

`EstimacionRTT` es una media ponderada de los RTT recientes (el tiempo entre enviar un segmento y recibir el ACK)   
$\text{EstimacionRTT} = (1-\alpha)\times \text{EstimacionRTT} + \alpha \times \text{MuestraRTT}$
`DevRTT` mide la variación de RTT, ayudando a TCP a ajustar los tiempos de espera.
   
   $\text{DevRTT} = (1-\beta)\times \text{DevRTT} + \beta\text{|MuestraRTT} - \text{EstimacionRTT|}$
Normalmente $\alpha =0.125$ y $\beta = 0.25$

**Recuperación rápida:** TCP no tiene NAKs, pero sí que interpreta 3 ACKs repetidos como un NAK. Cuando el receptor recibe el paquete siguiente al que esperaba, manda un ACK. El emisor no hace caso y sigue mandando el siguiente. Cuando llega éste al receptor, éste vuelve a mandar otro ACK más igual, por lo que el emisor ya emplea una recuperacion rápida para mandar el paquete perdido antes de que venza el temporizador. Ante esto, TCP distingue dos eventos de pérdidas: vencimiento del temporizador (lo cual se considera como un problema grave pues se han perdido los paquetes y los ACKs) y los ACKs triplicados (lo cual es un problema leve, ya que por lo menos los ACKs han llegado).

> [! Info]
> En TCP disitinguimos dos tipos:
> - **Reno:** si recibimos 3 **ACKs** duplicados reduce la ventana a la mitad de su valor actual y comienza la fase de **recuperación rápida**.
> - **Tahoe:** al recibir 3 **ACKs** duplicados reudce la ventana a **1 MSS** y vuelve a la fase de **inicio lento**.
> Reno es más eficiente, si se produce **timeout (expira el contador)** ambos vuelven a la fase de **inicio lento**.

![[archivos/imagenes/Pasted image 20241115181211.png]]


![[archivos/imagenes/Pasted image 20241114200112.png]]

**ARQ intermedio:** TCP podría considerarse un ARQ intermedio entre retroceder N y repetición selectiva, ya que los ACKs son acumulativos (el ACK de un segmento implica los ACKs de los anteriores) pero puede aceptar también segmentos en desorden y esperar a que lleguen después los intermedios.

**Control de flujo:** El control de flujo es el mecanismo que permite al receptor indicar al emisor el ritmo al que puede recibir datos. En el momento de la conexión, el receptor indica el tamaño de su ventana de recepción y el emisor fija a este valor su ventana de envío. Esto se hace mediante un campo en la cabecera TCP, lo que permite modificar también este valor en cada transmisión.

**Conexión:** TCP establece la conexión a través de un proceso de **tres vías** (three-way handshake) para sincronizar los números de secuencia y asegurarse de que ambas partes estén listas para intercambiar datos. La secuencia es la siguiente:
   - Emisor → Solicitud de conexión (SYN), número de secuencia $x$.
   - Receptor → Aceptación (SYN, ACK), número de secuencia $y$, reconoce $x + 1$.
   - Emisor → Confirmación (ACK), reconoce $y + 1$.

   Tras la confirmación, se pueden enviar datos en ambas direcciones.

![[archivos/imagenes/Pasted image 20241027105422.png]]

**Desconexión:** La desconexión es un proceso en dos pasos:
   - Cuando una de las partes desea finalizar la conexión, envía una solicitud de desconexión (FIN). La otra parte envía un ACK para reconocerla y también envía un FIN.
   - Ambas partes cierran el flujo en la dirección opuesta. 

![[archivos/imagenes/Pasted image 20241027105452.png]]

### Transmisión de datos
![[archivos/imagenes/Pasted image 20241114200611.png]]

Una vez establecida la conexión, empieza la transmisión. La aplicación va pasando los datos a la capa de transporte (escribiendo en el socket), que los va acumulando.

**Mecanismos para Disparar la Transmisión de un Segmento:**
- **Segmentación**: cuando el número de bytes supere el MSS (Maximum Segment Size).
- Cuando la aplicación fuerza el envío (push)
- Cuando un temporizador llega a 0

Depués **TCP genera el segmento y se lo pasa a IP**

#### Generación de ACKs
1. **A → B**: se debe incluir el ACK (piggybacking).
2. Si el receptor no tiene datos para enviar, recibe un segmento en orden y el anterior fue confirmado, entonces retrasa el ACK hasta que:
   - reciba otro segmento, o
   - transcurra un periodo de tiempo (normalmente 0,5 s).
3. Si llega un segmento esperado y el anterior no se confirmó, se envía el ACK.
4. Si llega un segmento con un número de secuencia mayor del esperado, se envía un ACK con el número de secuencia esperado.
5. Si llega un segmento que faltaba, se envía un ACK con el siguiente número esperado (acumulativo).
6. Si llega un segmento duplicado, se envía un ACK con el número esperado.


## 3.3.2 Estructura del segmento TCP
![[archivos/imagenes/Pasted image 20241027105921.png]]

- **Puertos de origen y destino**
  - El **puerto de destino** es estándar y lo elige la aplicación.
  - El **puerto de origen** se decide aleatoriamente.

- **Número de secuencia**
  - Identificación del número de byte por el que empieza el segmento. No se empieza numerando desde 0, sino desde un número aleatorio.

- **Agradecimiento superpuesto**
  - Reconoce el número de bytes recibidos correctamente siempre que el bit **ACK** está activado. En caso de no estarlo, este campo no se usa.

- **Longitud de la cabecera**
  - Especifica la longitud, ya que existe el campo de opciones.

- **Indicadores**
  - `URG` – El segmento tiene datos urgentes (urgent).
  - `ACK` – El segmento tiene un reconocimiento (acknowledgment).
  - `PSH` – El segmento fue empujado (push).
  - `RST` – Se solicita reinicio de la conexión (reset).
  - `SYN` – Se solicita inicio de conexión (synchronize).
  - `FIN` – Se solicita fin de conexión (finished).

- **Ventana otorgada**
  - Indica cuántos bytes de datos puede recibir (usada para control de flujo).

- **Suma de comprobación**
  - Suma de 16 bits en complemento a uno (C1) de la cabecera TCP y cuerpo (y algunos campos más de la cabecera IP). Se calcula en los dos lados de la transferencia para verificar la transmisión.

- **Puntero urgente**
  - Indica la posición de los datos urgentes dentro del segmento. En caso de que haya datos urgentes, **URG** está a 1.

- **Opciones**
  - Tiene varios usos, como negociar el tamaño máximo de los segmentos.

# 3.4 Congestion
## 3.4.1 Introducción
La congestión en redes TCP ocurre cuando demasiados paquetes intentan atravesar la red al mismo tiempo, causando retrasos y pérdida de datos debido a la saturación de las memorias de los routers. Esta saturación hace que los routers tengan que desechar paquetes, lo cual provoca más retransmisiones y empeora el problema. TCP implementa mecanismos para manejar esta congestión, regulando la tasa de envío en función de la congestión percibida en la red. Estos mecanismos son esenciales para mantener un flujo de datos eficiente y equilibrado. Veamos en detalle cada escenario de congestión y las técnicas de control que usa TCP:

#### Escenarios de Congestión
##### Escenario 1: Memoria Infinita en los Routers
Imaginemos que los routers pueden almacenar una cantidad infinita de datos. En este caso, conforme la tasa de envío de paquetes se acerca a la capacidad del enlace, los paquetes comienzan a acumularse en la cola del router, generando retrasos. Estos retrasos se van acumulando con cada nuevo paquete, creando un "cuello de botella". 

Por ejemplo, si la capacidad del enlace es de 10 Mbps y la tasa de envío es de 9 Mbps, habrá un leve retraso. Sin embargo, al alcanzar los 10 Mbps, los retrasos aumentan drásticamente, afectando a todos los paquetes que esperan en la cola.

![[archivos/imagenes/Pasted image 20241027110713.png]]

##### Escenario 2: Memoria Finita en un Router
En este caso, el router tiene una memoria limitada. Cuando la cola se llena, el router empieza a descartar paquetes. Esto obliga al emisor a retransmitir los paquetes perdidos, lo que, a su vez, aumenta aún más la carga en la red y agrava la congestión.

Por ejemplo, si un router puede almacenar hasta 1000 paquetes y se llena debido a una tasa de envío alta, los paquetes adicionales se descartan. Esto desencadena retransmisiones, y el emisor, en lugar de reducir su tasa, sigue enviando más paquetes, empeorando la situación.

##### Escenario 3: Camino con Múltiples Routers
Cuando hay varios routers en el camino, si un paquete se pierde a mitad del camino, los routers anteriores han gastado recursos procesando un paquete que finalmente no llegó a su destino. Esto reduce la eficiencia general de la red, ya que se desperdicia capacidad en procesar paquetes que no alcanzarán su destino.

Por ejemplo, en una red con cinco routers, si el tercer router descarta un paquete, el esfuerzo de los primeros dos routers es en vano, y la capacidad útil de la red se reduce.

![[archivos/imagenes/Pasted image 20241027110733.png]]

## 3.4.2 Control de Congestión en TCP
Los recursos de la red siempre deben repartirse entre las diferentes peticiones. Si hay demasiados paquetes en la red, se producen retardos en las transmisiones, lo cual provoca muchas pérdidas de paquetes. Normalmente, esta congestión se produce por desbordamiento de memoria en los routers. Para controlarla, se suelen usar dos técnicas: 

1. **Reservar recursos antes de que ocurra.**  
2. **Dejar que ocurra y después resolverla.**

Los origenes de la congestion son:
1. **Capacidad de velocidad finita C del router con dos emisores:**  
   - Mientras la tasa de transmisión está entre 0 y C/2, todo se recibe correctamente.  
   - Cuando se supera, el enlace no puede proporcionar paquetes a esa velocidad, por lo que la cola del router no deja de aumentar.

2. **Carga ofrecida por el router con dos emisores y misma velocidad que el anterior:**  
   - Cuando la tasa de transmisión supera el C/2, la tasa entregada disminuye porque algunos paquetes son duplicados.

3. **Varios emisores, routers y enlaces con alta tasa de transmisión:**  
   - Los buffers de los routers se llenan y disminuye la tasa entregada.  
   - Esto provoca que la tasa, en el límite, tienda a 0.

En **TCP/IP**, el mecanismo de control de congestión recae en **TCP**, que considera que hay congestión cuando:  

- Expira un temporizador.  
- Se reciben ACKs triplicados.

Para actualizar la ventana de congestión y adecuarla a la transferencia en curso, se estima periódicamente el **RTT** y se actualiza según la fórmula:  

> [!INFO]
>**Ventana de Congestión**
>
> **Qué es:**  
> Una variable controlada por el emisor que limita la cantidad máxima de datos que pueden enviarse antes de recibir un reconocimiento (ACK).
>
> **Objetivo:**  
> Evitar la congestión en la red. Su tamaño se ajusta dinámicamente según las condiciones de la red:
> - **Aumenta gradualmente** cuando no hay pérdidas (control de congestión).
> - **Se reduce** cuando se detecta congestión (por pérdida de paquetes o expiración de temporizadores).
>
> **Unidad:**  
> Se mide en bytes (o segmentos TCP).
>
> **Relacionada con:**  
> La tasa de envío efectiva del emisor.


$$
\text{Tasa de envío} = \frac{\text{ventana de congestión}}{\text{RTT}}
$$
> [!INFO]
> **Umbral de Congestión (ssthresh):**
> - **Definición:** El umbral de congestión es el valor que marca el límite entre las fases de **inicio lento** y **AIMD**.
> - **Función:** Indica el tamaño de la ventana en el que TCP pasa de **inicio lento** a **AIMD**. En inicio lento, la ventana crece exponencialmente hasta alcanzar este umbral, luego se controla linealmente en AIMD.
> - **Crecimiento:** El umbral se ajusta cuando se detecta una pérdida de paquete:
> - En **inicio lento**, si ocurre congestión (pérdida de paquetes), el umbral se reduce a la mitad de la ventana de congestión, pasando a AIMD.
> - En **AIMD**, el umbral no cambia a menos que se vuelva a detectar una pérdida.
> 

### **Inicio Lento**
- Al iniciar una conexión, TCP configura una ventana de congestión inicial pequeña, equivalente al tamaño máximo del segmento (**MSS**).
- La ventana de congestión se incrementa **exponencialmente**, duplicándose en cada intervalo igual al **RTT**, hasta que se detecta una pérdida de paquetes o la ventana alcanza el tamaño del umbral de congestión.

Por ejemplo, si el **MSS** es de 500 bytes y el **RTT** es de 0.2 segundos, la tasa de transmisión inicial sería:

$$
\text{Tasa inicial} = \frac{500 \times 8}{0.2} = 20 \, \text{kbps}.
$$

Cuando ocurre una pérdida o se alcanza el umbral, TCP abandona el inicio lento y pasa a la siguiente fase.

![[archivos/imagenes/Pasted image 20241027110812.png]]


### **AIMD (Additive Increase, Multiplicative Decrease):**
- **Definición:** AIMD es un enfoque de control de congestión utilizado en TCP para gestionar la ventana de congestión (cwnd). Se basa en dos principios:
  - **Aumento aditivo:** Cuando no hay congestión (es decir, no se detectan pérdidas de paquetes), la ventana de congestión aumenta de forma lineal (en unidades de 1 segmento por RTT).
  - **Disminución multiplicativa:** Cuando se detecta congestión (por ejemplo, a través de la pérdida de paquetes), la ventana de congestión se reduce a la mitad (una disminución multiplicativa).
  
- **Fases:** 
  - **Inicio lento:** Aquí, TCP aumenta la ventana de forma exponencial hasta que alcanza el umbral de congestión (ssthresh).
  - **Evitar la congestión (AIMD):** Después de superar el umbral (ssthresh), TCP cambia a un aumento lineal (aditivo) y una reducción multiplicativa en respuesta a la congestión.

![[archivos/imagenes/Pasted image 20241027110833.png]]

### **Recuperación Rápida en TCP**
La **recuperación rápida** es un mecanismo dentro de TCP diseñado para mejorar la **recuperación de la ventana de congestión** después de una **pérdida de paquetes detectada mediante tres ACKs duplicados**. A diferencia de un **fin de temporización**, que reinicia la ventana de congestión a 1 MSS, la **recuperación rápida** permite a TCP **recuperarse sin reducir drásticamente su ventana**, manteniendo la eficiencia de la conexión.

#### **¿Cómo funciona la recuperación rápida?**
- **Detección de congestión leve:** Cuando TCP recibe **tres ACKs duplicados**, interpreta esto como una señal de congestión leve (es decir, solo un paquete se ha perdido, pero la red no está completamente congestionada).
    
- **Reducción de la ventana de congestión:**
    - La ventana de congestión se reduce a la mitad del tamaño previo, **más un margen de 3 MSS** (tamaño máximo de segmento).
    - La fórmula para calcular la nueva ventana de congestión es:  
        $$\text{Nueva ventana de congestión} = \frac{\text{Ventana previa}}{2} + 3 \, \text{MSS}$$

- **Retransmisión del paquete perdido:** Durante esta fase, TCP retransmite el segmento perdido y continúa enviando nuevos segmentos dentro del límite de la ventana ajustada.
    
- **Incremento lineal (AIMD):** Una vez que se ha resuelto la congestión, la ventana de congestión se incrementa de forma **lineal** (en unidades de 1 segmento por RTT) hasta alcanzar el ancho de banda disponible sin causar sobrecarga en la red.
    
### **Vencimiento del Temporizador**
- Cuando el temporizador de retransmisión expira sin recibir un **ACK**, TCP interpreta esto como una congestión **grave**:
  - Reinicia la ventana de congestión a **1 MSS**.
  - Entra en la fase de **inicio lento**, incrementando la ventana de manera **exponencial** hasta alcanzar la mitad del tamaño previo a la congestión.
  - Después, la ventana crece de forma **lineal**.

Por ejemplo:
- Si la ventana de congestión era de **24 KB** antes del vencimiento:
  - Se reinicia a **1 MSS**.
  - Crece exponencialmente hasta **12 KB** (mitad del tamaño previo).
  - A partir de ahí, el crecimiento se vuelve lineal.

---
![[archivos/imagenes/Pasted image 20241027110849.png]]


## 3.4.3 Imparcialidad
Cuando varias conexiones TCP comparten un enlace, ajustan su tasa de envío automáticamente para repartir la capacidad disponible del enlace de manera equitativa. Por ejemplo, si dos conexiones TCP comparten un enlace de 10 Mbps, cada una recibirá aproximadamente 5 Mbps.

![[archivos/imagenes/Pasted image 20241027110946.png]]

![[archivos/imagenes/Pasted image 20241027110958.png]]

Sin embargo, cuando se introduce una conexión UDP junto con TCP, la conexión UDP, al no tener control de congestión, puede acaparar la mayor parte del ancho de banda. Del mismo modo, si se establece una conexión TCP junto con nueve conexiones TCP paralelas, el enlace se repartirá en una proporción de 1/10 para la primera conexión y 9/10 para las demás.
