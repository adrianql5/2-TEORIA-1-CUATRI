[[REDES/archivos/bibliografia/Tema3Redes.pdf|Tema3Redes]]
[[REDES/archivos/bibliografia/[1] Redes de Computadores.pdf|[1] Redes de Computadores]]

# 3.1 Introducción
La capa de transporte es un componente clave en la arquitectura de redes, cuya función es asegurar que los datos enviados desde una aplicación en el origen lleguen de manera correcta al proceso de destino. 

> [!Recordatorio]
> ![[archivos/imagenes/Pasted image 20241108205726.png]]

#### Funciones principales de la capa de transporte:
1. **Preparación de los datos para la transmisión**: 
   - La capa de transporte recibe los datos (mensajes) generados por las aplicaciones y los prepara para su transmisión. Dependiendo del protocolo que se utilice (TCP o UDP), los datos pueden fragmentarse en segmentos o simplemente añadírseles una cabecera.
   
2. **Entrega de los datos al destino**: 
   - Una vez que los datos llegan al destino, la capa de transporte es responsable de reconstruir los mensajes (si fueron fragmentados) y entregarlos al proceso correcto en el sistema receptor.

3. **Independencia del canal no fiable**: 
   - La capa de transporte no necesita conocer cómo funciona el canal de transmisión (la capa inferior que maneja los paquetes), ya que se asume que puede haber muchos errores en la transmisión. El objetivo es realizar una **comunicación lógica** entre el origen y el destino, sin importar cómo se manejen los errores en las capas inferiores.
![[archivos/imagenes/Pasted image 20241018195728.png]]

4. **Comunicación lógica**:
   - La capa de transporte permite una comunicación lógica entre los procesos en el origen y el destino. Esto significa que el envío de datos se percibe como una comunicación directa entre aplicaciones, aunque físicamente los datos atraviesan múltiples dispositivos y redes intermedias.

5. **Implementación en el origen y destino**: 
   - La capa de transporte está presente solo en los dispositivos de origen y destino, no en los routers intermedios. Los routers se ocupan de las capas inferiores, como la red, pero no gestionan los detalles del transporte de datos.

#### Protocolos en la capa de transporte:
1. **TCP (Transmission Control Protocol)**:
   - **Fragmentación de mensajes**: TCP divide los mensajes en segmentos más pequeños.
   - **Cabecera de control**: A cada segmento se le añade una cabecera con información necesaria para asegurar la correcta transmisión y el control de errores.
   - TCP garantiza que los segmentos se entreguen en el orden correcto y sin errores, gracias a mecanismos como la retransmisión de segmentos perdidos.

![[archivos/imagenes/Pasted image 20241018195754.png]]

2. **UDP (User Datagram Protocol)**:
   - UDP no realiza fragmentación de mensajes ni garantiza la entrega ordenada. Simplemente añade una cabecera a los datos y los envía. Es más rápido, pero menos fiable que TCP.

## 3.1.1 Multiplexión y demultiplexión
La **multiplexión** y **demultiplexión** son conceptos clave en el funcionamiento de la capa de transporte en las redes de comunicación, ya que se encargan de gestionar el envío y recepción de mensajes entre múltiples aplicaciones a través de una red.

#### Multiplexión
La **multiplexión** es el proceso en el cual la capa de transporte recoge datos de múltiples procesos de aplicación, los organiza y los envía a través de la red. Esto se hace recorriendo cada uno de los sockets asociados a las aplicaciones, procesando los datos de cada socket, y enviando los segmentos (*paquetes*) correspondientes a la red. Cada proceso de aplicación tiene su propio socket, lo cual permite que varios procesos diferentes transmitan datos simultáneamente. La multiplexión asegura que los datos de distintos procesos sean recogidos y enviados a través de la red de manera ordenada.

**Ejemplo**: 
Imagina que tienes tres aplicaciones en un mismo dispositivo transmitiendo información (*por ejemplo, una aplicación de chat, una aplicación de correo y una aplicación de streaming*). Cada una tiene su propio socket. La capa de transporte recoge los datos de cada aplicación, genera segmentos, y luego los envía a la red a través de un único enlace físico. Esto es multiplexión.

#### Demultiplexión
La **demultiplexión** ocurre en el lado del receptor. Aquí, la capa de transporte recibe segmentos de la capa de red, reconstruye los mensajes originales y los distribuye a los sockets correspondientes en función de los números de puerto que identifican a cada socket. De esta manera, los procesos en el lado del receptor pueden recoger los mensajes que les corresponden.

**Ejemplo**: 
Cuando un servidor recibe datos de múltiples clientes, la capa de transporte se encarga de procesar esos datos, identificando a qué socket (y, por tanto, a qué proceso) deben ser entregados. Así, los mensajes de cada cliente llegan al proceso correcto.

![[archivos/imagenes/Pasted image 20241018200435.png]]

#### Identificación mediante puertos
Para identificar a qué socket corresponde un mensaje, se usan los **números de puerto**, que son enteros de 16 bits (*0-65535*). Estos números permiten diferenciar qué proceso debe recibir los datos en el sistema. 

Los puertos entre 0-1023 están reservados para servicios bien conocidos (*como HTTP o FTP*), se conocen como **Puertos  Conocidos**.

Los puertos entre 1024-49152 están disponibles para las aplicaciones de usuario, se llaman **Puertos Registrados**.

Y los puertos restantes son los **Puertos Efímeros** que son los que se usan cuando por ejemplo abrimos varias pestañas de firefox simultáneamente, como no podemos usar el mismo puerto, el SO asigna a cada ventana un puerto efímero diferente, y al cerrarlas se liberan.

![[archivos/imagenes/Pasted image 20241018200452.png]]

#### Multiplexión y Demultiplexión con sockets sin conexión (UDP)
En el caso de **UDP** (User Datagram Protocol), los sockets se identifican únicamente por la dirección IP de destino y el puerto de destino. Por ejemplo, un servidor que proporciona la hora del día a múltiples clientes (como el servicio daytime en el puerto 13) recibe datagramas de diferentes clientes y responde a cada uno de forma individual. Todos los datagramas se entregan al mismo puerto de destino, pero el puerto de origen permite que el servidor sepa a quién responder.

![[archivos/imagenes/Pasted image 20241018200547.png]]

#### Multiplexión y Demultiplexión con sockets orientados a conexión (TCP)
En el caso de **TCP** (Transmission Control Protocol), los sockets se identifican con una tupla de 4 elementos: la dirección IP de origen, la dirección IP de destino, el puerto de origen y el puerto de destino. Esto significa que TCP puede gestionar múltiples conexiones al mismo puerto de destino, ya que las direcciones IP y los puertos de origen pueden ser diferentes. Así, un servidor web (que escucha en el puerto 80 o 443) puede atender a múltiples clientes simultáneamente, distinguiendo cada conexión por su IP y puerto de origen.

![[archivos/imagenes/Pasted image 20241018200605.png]]

#### Sockets de Servidor y Conexión en TCP
En TCP, hay dos tipos de sockets:
1. **Socket de servidor**: Solo espera conexiones de clientes.
2. **Socket de conexión**: Se encarga de manejar una conexión específica. 

Cuando un cliente establece una conexión con un servidor, el socket de servidor transfiere la conexión a un socket de conexión dedicado a esa interacción. Así, múltiples conexiones pueden ser manejadas simultáneamente por un solo servidor, como ocurre en servicios como **telnet** o **HTTP**.

![[archivos/imagenes/Pasted image 20241018200647.png]]

Estos mecanismos permiten que múltiples aplicaciones en diferentes dispositivos puedan comunicarse de manera eficiente y ordenada a través de la red, utilizando un solo enlace físico pero gestionando múltiples flujos de datos simultáneos.

![[archivos/imagenes/Pasted image 20241018200659.png]]

## 3.1.2 Capa de Transporte Sin Conexión: UDP
UDP (User Datagram Protocol) es un protocolo de transporte de capa 4 en el modelo OSI. A diferencia de TCP, es un protocolo sin conexión, lo que significa que no establece una conexión entre el emisor y el receptor antes de enviar los datos, ni garantiza que los datos lleguen en orden o sin errores. Aquí tienes una explicación más clara de sus características y funcionamiento:

#### Funcionamiento básico:
1. **En el origen**: UDP toma el mensaje que se va a enviar y le añade una cabecera simple para formar lo que se conoce como un "segmento". La cabecera de UDP tiene solo 4 campos:
   - **Puerto de origen**: identifica el puerto desde donde se envían los datos.
   
![[archivos/imagenes/Pasted image 20241019190923.png]]

   - **Puerto de destino**: identifica el puerto del receptor.
   - **Longitud total**: el tamaño del segmento (incluyendo la cabecera y los datos).
   - **Suma de comprobación**: usada para detectar errores en los datos.

2. **En el destino**: UDP verifica si el segmento llegó sin errores utilizando la suma de comprobación. Si no hay errores, los datos se pasan al socket para ser procesados por la aplicación. Si hay errores, el segmento puede descartarse, aunque en algunas implementaciones podría entregarse con un aviso de error.

#### Características principales:
- **Sin conexión**: No hay una negociación previa entre emisor y receptor. Los segmentos simplemente se envían sin establecer una conexión. Esto reduce la latencia, ya que no hay un proceso de "handshake" como en TCP.

- **Sin retransmisión ni control de errores avanzado**: UDP no garantiza la entrega de los segmentos ni los retransmite si se pierden o llegan con errores. Tampoco reordena los segmentos que puedan llegar fuera de orden.

- **Procesamiento rápido y bajo consumo de recursos**: Debido a que no mantiene el estado de la conexión ni tiene mecanismos de control de errores sofisticados, UDP es muy eficiente. Esto lo hace ideal para servidores que necesitan atender a muchos clientes simultáneamente o para aplicaciones que priorizan la velocidad.

- **Cabeceras más pequeñas**: La cabecera de UDP es mucho más pequeña que la de TCP, lo que implica un procesamiento más rápido y menos sobrecarga de almacenamiento y transmisión.

- **Mayor control para las aplicaciones**: Las aplicaciones que usan UDP pueden implementar sus propios mecanismos de control si es necesario, como la numeración de datos o la detección de errores adicional.

#### Ejemplo de la suma de comprobación:
- En UDP, la suma de comprobación se usa para detectar errores en el segmento (tanto en los datos como en la cabecera).
- En el origen, se suman todas las palabras de 16 bits del segmento. Luego se realiza un complemento a 1 del resultado y se inserta en el campo de suma de comprobación.
- Al llegar al destino, se recalcula la suma de comprobación y si coincide con la original, significa que el paquete llegó sin errores.

# 3.2 Fundamentos de la transmisión fiable
La transmisión fiable se refiere a la capacidad de garantizar que los datos enviados a través de una red lleguen correctamente al receptor. Para lograrlo, se utilizan **protocolos de retransmisión** conocidos como **ARQ (Automatic Repeat reQuest)** o solicitud automática de repetición. Estos protocolos retransmiten paquetes si se detecta un error o si un paquete no llega al destino. Aquí se explican dos tipos de protocolos ARQ: **parar y esperar** y **ventana deslizante**.

Las confirmaciones de recepción son los **ACKs** (*ACKnowledgment number*)

## 3.2.1 Protocolo ARQ: Parar y esperar
En este protocolo, el emisor envía un paquete y luego se detiene a esperar una confirmación (*ACK*) del receptor antes de enviar el siguiente paquete. Es un proceso simple pero ineficiente si hay mucha latencia o pérdida de paquetes.

**Casos que pueden ocurrir en este protocolo:**

1. **Caso sin errores**:
   - El receptor recibe el paquete correctamente y envía un **ACK** (*confirmación*) al emisor. El número del ACK es el número del siguiente paquete esperado. 
   - Una vez que el emisor recibe el ACK, envía el siguiente paquete.
   
   Ejemplo:
   - El emisor envía el paquete 0.
   - El receptor recibe el paquete 0 y envía el ACK1 (*indicando que espera el paquete 1*).
   - El emisor recibe el ACK1 y envía el paquete 1.

2. **Caso de pérdida de paquetes**:
   - Si un paquete se pierde en el camino o llega con errores, el receptor no enviará el ACK.
   - El emisor tiene un **temporizador** que empieza a contar cuando se envía el paquete. Si no recibe el ACK antes de que el temporizador expire, retransmite el paquete.

   Ejemplo:
   - El emisor envía el paquete 0, pero este se pierde.
   - El temporizador del emisor expira y retransmite el paquete 0.
   - El receptor finalmente recibe el paquete 0 y envía el ACK1.

![[archivos/imagenes/Pasted image 20241019195949.png]]

3. **Caso de pérdida de ACK**:
   - Si el ACK se pierde, el emisor no sabrá que el receptor recibió el paquete. Entonces, cuando el temporizador expire, retransmitirá el paquete.
   - El receptor, al recibir un paquete duplicado (*porque ya lo procesó antes*), simplemente reconoce que es un duplicado y envía el ACK correspondiente nuevamente.

   Ejemplo:
   - El emisor envía el paquete 0, el receptor lo recibe, pero el ACK1 se pierde.
   - El temporizador del emisor expira y retransmite el paquete 0.
   - El receptor ya procesó el paquete 0, lo reconoce como duplicado y vuelve a enviar el ACK1.

![[archivos/imagenes/Pasted image 20241019200035.png]]

4. **Vencimiento del temporizador**:
   - Si el temporizador se configura con un tiempo muy corto o hay congestión en la red, tanto los paquetes como los ACK pueden retrasarse.
   - El emisor puede recibir duplicados de ACKs o de paquetes debido a este retraso, pero los identifica por el número de secuencia y los ignora si ya fueron procesados.

   Ejemplo:
   - El emisor envía el paquete 0 y el receptor envía el ACK1.
   - Sin embargo, debido a la congestión, el temporizador del emisor expira antes de recibir el ACK, y retransmite el paquete.
   - El receptor recibe el paquete 0 nuevamente, lo ignora y envía el ACK1 duplicado.

![[archivos/imagenes/Pasted image 20241019200108.png]]

#### NAK
Un **NAK** (*Negative-Acknowledge Character*), representado con dos ACKs iguales. Indica la recepción de un paquete con errores (*ya no espera al timeout para reenviar*). Cuando un paquete con errores llega, se devuelve el **ACK** del último correcto. Si vence el temporizador, se envían continuamente duplicados de paquetes. Para evitar este problema, son tres ACKs los que equivalen a un NAK. TCP usa este sistema con alguna variación

## 3.2.2 Tiempo desperdiciado en ARQ para-y-esperar
El protocolo ARQ parar y esperar tiene una desventaja significativa: **desperdicia mucho tiempo**, ya que el emisor tiene que esperar a recibir una confirmación (ACK) antes de enviar el siguiente paquete. Durante este tiempo de espera, el enlace de comunicación está inactivo, lo que reduce la eficiencia de la transmisión. Este tiempo de inactividad se llama **tiempo desperdiciado**.

#### Desglose de tiempos en ARQ parar y esperar
1. **Tiempo de transmisión (ttrans)**: Es el tiempo que toma al emisor enviar un paquete de datos. Este tiempo depende del tamaño del paquete (*L, en bits*) y la velocidad de transmisión del enlace (*R, en bits por segundo o bps*). Se puede calcular con la fórmula:
   $$t_{\text{trans}} = \frac{L}{R}$$

2. **Tiempo de ida y vuelta (RTT - Round Trip Time)**: Es el tiempo que tarda un paquete en ir desde el emisor al receptor, más el tiempo que tarda en regresar el ACK desde el receptor al emisor. Incluye cualquier retraso de propagación en la red.

3. **Tiempo total para transmitir un paquete**: Cada vez que se envía un paquete, el tiempo total que se invierte incluye tanto el tiempo de transmisión como el tiempo de espera para recibir el ACK, que está basado en el RTT. Por lo tanto, el **tiempo total** que se toma para transmitir un solo paquete y recibir su confirmación es:

   $$\text{Tiempo total} = RTT + t_{\text{trans}}$$

#### Utilización del enlace (U)
La **utilización del enlace** es la proporción del tiempo en que el emisor realmente está enviando datos, frente al tiempo total (que incluye tanto la transmisión como la espera). Es decir, es el **tiempo útil** dividido por el **tiempo total**. Se calcula de la siguiente forma:

$$U = \frac{t_{\text{trans}}}{RTT + t_{\text{trans}}}$$

Aquí:
- $t_{\text{trans}}$ es el tiempo de transmisión del paquete.
- $RTT$ es el tiempo de ida y vuelta para enviar el paquete y recibir el ACK.

#### Explicación
- **Cuando \( RTT \) es grande** en comparación con $t_{\text{trans}}$, la utilización $U$ será pequeña, lo que significa que el enlace está inactivo la mayor parte del tiempo.
- **Cuando \( RTT \) es pequeño** en relación con $t_{\text{trans}}$, la utilización $U$ será alta, lo que significa que el enlace se utiliza eficientemente.

#### Ejemplo
Si un paquete tiene una longitud de 8000 bits (L = 8000 bits) y la velocidad de transmisión es de 1 Mbps (R = 1,000,000 bits/seg), entonces:


$$t_{\text{trans}} = \frac{8000 \text{ bits}}{1,000,000 \text{ bps}} = 0.008 \text{ segundos}$$

Si el RTT es de 0.1 segundos, la utilización del enlace será:

$$U = \frac{0.008}{0.1 + 0.008} = \frac{0.008}{0.108} \approx 0.074$$

Esto significa que solo el **7.4% del tiempo** el enlace está siendo utilizado para enviar datos, mientras que el **92.6% del tiempo** está inactivo esperando el ACK.

#### Conclusión
En el protocolo **parar y esperar**, el tiempo desperdiciado aumenta a medida que el **RTT** crece en relación con el **tiempo de transmisión**. Esto hace que el protocolo sea ineficiente en redes con **alta latencia** o **altas tasas de transmisión**, ya que el enlace permanece inactivo la mayor parte del tiempo. Para mejorar esta eficiencia, se utilizan otros protocolos como el **ventana deslizante**, que permiten que el emisor envíe varios paquetes antes de recibir las confirmaciones.


## 3.2.3 ARQ con ventana deslizante (entubamiento)
El protocolo **ARQ con ventana deslizante**, también conocido como **entubamiento**, es una mejora sobre el protocolo "parar y esperar", y su principal ventaja es que **reduce el tiempo perdido** esperando confirmaciones (*ACKs*). En lugar de enviar un paquete y esperar una confirmación antes de enviar el siguiente, el emisor puede enviar **varios paquetes consecutivos** (*hasta un número máximo $N$ antes de recibir los ACKs*). Esto mejora considerablemente la **utilización del enlace**.

#### Concepto de ventana deslizante
1. **Ventana emisora**: Es el conjunto de hasta $N$ paquetes que el emisor puede enviar antes de recibir una confirmación. Estos paquetes pueden haber sido enviados, pero aún no han sido reconocidos. El emisor debe mantener una copia de estos paquetes en memoria en caso de que necesiten ser retransmitidos.
   
2. **Ventana receptora**: Es el conjunto de hasta $N$ paquetes que el receptor puede aceptar y procesar, pero que aún no ha reconocido. El receptor debe tener memoria suficiente para almacenar estos paquetes hasta que sean procesados y confirmados.

#### Funcionamiento
El emisor envía varios paquetes de manera consecutiva sin esperar una confirmación por cada uno. La ventana del emisor se va desplazando conforme el emisor recibe los ACKs de los paquetes. Por ejemplo, si la ventana tiene un tamaño de  $N = 5$, el emisor puede enviar 5 paquetes, pero la ventana solo avanzará cuando reciba confirmaciones de los paquetes. Cuando se recibe un ACK, la ventana "desliza" y permite que el emisor envíe más paquetes.

![[archivos/imagenes/Pasted image 20241019205036.png]]

#### Cálculo de la utilización del enlace
La **utilización del enlace** se mejora al permitir que se transmitan múltiples paquetes antes de recibir un ACK. El porcentaje de utilización se calcula como:

$$
U = \frac{N \cdot t_{\text{trans}}}{RTT + t_{\text{trans}}}$$

Donde:
- $N \cdot t_{\text{trans}}$ es el tiempo total que el emisor utiliza para transmitir $N$ paquetes.
- $RTT + t_{\text{trans}}$ es el tiempo total que incluye tanto la transmisión de los paquetes como el tiempo de ida y vuelta $RTT$ para recibir el ACK.

Para que el emisor no desperdicie tiempo y la utilización del enlace sea máxima $U = 1$, es necesario que:

$$
N \cdot t_{\text{trans}} \geq RTT + t_{\text{trans}}
$$

De esto se obtiene la condición para que el protocolo sea eficiente:

$$
N \geq 1 + \frac{RTT}{t_{\text{trans}}}
$$

#### Requerimientos
Para que el **entubamiento** funcione correctamente, se deben cumplir ciertos requerimientos:

1. **Rango de números de secuencia**: El rango de números de secuencia debe abarcar al menos el doble de la cantidad de paquetes que se pueden enviar de golpe (es decir,  $2N$). Esto es necesario para que no haya confusión entre paquetes viejos y nuevos que puedan usar el mismo número de secuencia.
   
2. **Almacenamiento en memoria**: Tanto el emisor como el receptor deben poder almacenar varios paquetes en memoria. El emisor guarda los paquetes que ha enviado pero aún no han sido reconocidos, y el receptor guarda los paquetes que ha recibido pero aún no ha procesado.

#### Tipos de protocolos de ventana deslizante
Existen dos variantes principales de protocolos de ventana deslizante:

1. **Retroceso N (Go-Back-N, GBN)**: 
   - El receptor solo acepta paquetes en orden. Si un paquete se pierde o llega con errores, el receptor descarta todos los paquetes que lleguen después del paquete problemático.
   - El emisor debe reenviar no solo el paquete que falló, sino también todos los paquetes siguientes.
   - Los ACKs son **acumulativos**, lo que significa que un ACK para un paquete también confirma la recepción de todos los paquetes anteriores.

2. **Repetición selectiva**:
   - El receptor puede aceptar paquetes fuera de orden. Si un paquete se pierde o llega con errores, el receptor puede almacenar los paquetes posteriores y solo solicitar la retransmisión del paquete perdido.
   - Solo se retransmiten los paquetes que se pierden o llegan con errores, lo que mejora la eficiencia en comparación con Go-Back-N.
   - Se envía un ACK para cada paquete recibido correctamente, incluso si llegan fuera de orden.

![[archivos/imagenes/Pasted image 20241019205106.png]]

#### Ejemplo de ventana deslizante
Imaginemos que el emisor tiene una **ventana de tamaño 5** $N = 5$. El emisor envía los paquetes 0, 1, 2, 3 y 4 consecutivamente. A medida que recibe los ACKs correspondientes, la ventana se desplaza permitiendo que el emisor envíe nuevos paquetes (como el paquete 5, 6, etc.).

- Si se utiliza **Go-Back-N** y el paquete 2 llega con errores, el receptor descartará los paquetes 3, 4, etc., y el emisor tendrá que reenviar todos los paquetes a partir del 2.
- Si se utiliza **Repetición selectiva**, el receptor aceptará los paquetes 3, 4, etc., aunque el paquete 2 se haya perdido, y solo solicitará la retransmisión del paquete 2.

#### Conclusión
El **ARQ con ventana deslizante** mejora la eficiencia en comparación con el protocolo "parar y esperar", permitiendo al emisor transmitir varios paquetes antes de recibir ACKs. Esto reduce el tiempo de inactividad del enlace y mejora la utilización del mismo, especialmente en situaciones donde el RTT es elevado.


# 3.3 TCP
La capa de transporte en Internet se encarga de gestionar la comunicación confiable entre aplicaciones en distintos sistemas. TCP (*Transmission Control Protocol*) es un protocolo que asegura una transmisión de datos fiable y en orden. A continuación, se desglosan los aspectos técnicos más importantes de TCP, incluidos sus mecanismos de transmisión, numeración de secuencia, control de flujo y la conexión.

## 3.3.1 Transmisión
TCP implementa varios mecanismos para asegurar que los datos se transmitan y reciban de manera fiable.

1. **Números de secuencia**  
   TCP asigna números de secuencia a los segmentos de datos. Estos números de secuencia son de 32 bits y tienen algunas particularidades:

   - **Inicialización aleatoria**: En lugar de comenzar en 0, TCP elige un número aleatorio (llamémoslo \( x \)) como punto de partida, lo que ayuda a diferenciar distintas conexiones y reducir posibles problemas de seguridad.
   - **Incremento en función de los bytes enviados**: Cada segmento tiene su propio número de secuencia, que es igual al número del último byte del segmento anterior más el número de bytes del segmento actual.

   Ejemplo:
   - El emisor envía el primer segmento con \( x = 12 \).
     - `sec=12`, `datos=1` → el siguiente byte esperado será `ack=13`.
   - Si el siguiente segmento contiene 10 bytes:
     - `sec=13`, `datos=10` → `ack=23`.
   - Si se envían 6 bytes más:
     - `sec=23`, `datos=6` → `ack=29`.

![[archivos/imagenes/Pasted image 20241027104559.png]]

2. **Superposición (Piggybacking)**
   En muchas comunicaciones, los datos se transmiten en ambas direcciones. TCP optimiza el envío de datos y reconocimientos (*ACK*) utilizando una técnica llamada superposición o piggybacking. Esto significa que cuando un segmento de datos llega al receptor, este puede esperar un momento a enviar el ACK, combinándolo con los datos de respuesta para reducir el número de transmisiones.

   Ejemplo:
   - Si el cliente envía `sec=12, datos=1, ack=39`, y el servidor responde con `sec=39, datos=1, ack=13`.
   - TCP ajusta el temporizador de espera del receptor para que si no hay datos en espera, el ACK se envíe sin retraso adicional.

![[archivos/imagenes/Pasted image 20241027104623.png]]

3. **Transferencia fiable de datos**
   TCP utiliza **ACK acumulativos**: si el emisor envía varios segmentos, un solo ACK puede confirmar múltiples segmentos, lo cual es más eficiente. Si el emisor no recibe un ACK dentro del tiempo del temporizador, solo retransmitirá el segmento específico no reconocido, optimizando el uso de ancho de banda.
   
![[archivos/imagenes/Pasted image 20241027104711.png]]

4. **Duplicación del tiempo de espera**
   Cuando el temporizador expira, TCP retransmite el segmento y duplica el tiempo de espera del temporizador. Este ajuste progresivo del temporizador ayuda a mejorar el rendimiento en redes con retrasos fluctuantes.

   La fórmula del temporizador se calcula así:
   -  $\text{Temporizador} = \text{EstimacionRTT} + 4 \times \text{DevRTT}$,
   - donde `EstimacionRTT` es una media ponderada de los RTT recientes (el tiempo entre enviar un segmento y recibir el ACK),
   - $\text{EstimacionRTT} = (1-\alpha)\times \text{EstimacionRTT} + \alpha \times \text{MuestraRTT}$
   - y `DevRTT` mide la variación de RTT, ayudando a TCP a ajustar los tiempos de espera.
   - $\text{DevRTT} = (1-\beta)\times \text{DevRTT} + \beta\text{|MuestraRTT} - \text{EstimacionRTT|}$
Normalmente $\alpha =0.125$ y $\beta = 0.25$
5. **Retransmisión rápida**

![[archivos/imagenes/Pasted image 20241027105348.png]]

   TCP no utiliza reconocimientos negativos (*NAK*), pero emplea **ACKs triplicados** para detectar problemas: si el receptor recibe un segmento fuera de orden, emite ACK duplicados. Si el emisor recibe tres ACKs duplicados, considera que hay un segmento perdido y lo retransmite antes de que expire el temporizador.

6. **Control de flujo**
   TCP gestiona la velocidad de transmisión usando un mecanismo de **ventana deslizante**. Durante la conexión, el receptor informa al emisor sobre el tamaño de su ventana receptora en bytes, indicando la cantidad máxima de datos que puede recibir sin riesgo de pérdida. Este tamaño puede ajustarse dinámicamente.

7. **Conexión**
   TCP establece la conexión a través de un proceso de **tres vías** (three-way handshake) para sincronizar los números de secuencia y asegurarse de que ambas partes estén listas para intercambiar datos. La secuencia es la siguiente:
   - Emisor → Solicitud de conexión (SYN), número de secuencia \( x \).
   - Receptor → Aceptación (SYN, ACK), número de secuencia \( y \), reconoce \( x + 1 \).
   - Emisor → Confirmación (ACK), reconoce \( y + 1 \).

   Tras la confirmación, se pueden enviar datos en ambas direcciones.

![[archivos/imagenes/Pasted image 20241027105422.png]]

8. **Desconexión**
   La desconexión es un proceso en dos pasos:
   - Cuando una de las partes desea finalizar la conexión, envía una solicitud de desconexión (FIN). La otra parte envía un ACK para reconocerla y también envía un FIN.
   - Ambas partes cierran el flujo en la dirección opuesta. 

![[archivos/imagenes/Pasted image 20241027105452.png]]
TCP permite la transmisión bidireccional, fiable y controlada, haciendo que sea el protocolo ideal para aplicaciones que requieren integridad y orden, como la web y el correo electrónico.

## 3.3.2 Estructura del segmento TCP
![[archivos/imagenes/Pasted image 20241027105921.png]]

- **Puertos de origen y destino**
  - El **puerto de destino** es estándar y lo elige la aplicación.
  - El **puerto de origen** se decide aleatoriamente.

- **Número de secuencia**
  - Identificación del número de byte por el que empieza el segmento. No se empieza numerando desde 0, sino desde un número aleatorio.

- **Agradecimiento superpuesto**
  - Reconoce el número de bytes recibidos correctamente siempre que el bit **ACK** está activado. En caso de no estarlo, este campo no se usa.

- **Longitud de la cabecera**
  - Especifica la longitud, ya que existe el campo de opciones.

- **Indicadores**
  - `URG` – El segmento tiene datos urgentes (urgent).
  - `ACK` – El segmento tiene un reconocimiento (acknowledgment).
  - `PSH` – El segmento fue empujado (push).
  - `RST` – Se solicita reinicio de la conexión (reset).
  - `SYN` – Se solicita inicio de conexión (synchronize).
  - `FIN` – Se solicita fin de conexión (finished).

- **Ventana otorgada**
  - Indica cuántos bytes de datos puede recibir (usada para control de flujo).

- **Suma de comprobación**
  - Suma de 16 bits en complemento a uno (C1) de la cabecera TCP y cuerpo (y algunos campos más de la cabecera IP). Se calcula en los dos lados de la transferencia para verificar la transmisión.

- **Puntero urgente**
  - Indica la posición de los datos urgentes dentro del segmento. En caso de que haya datos urgentes, **URG** está a 1.

- **Opciones**
  - Tiene varios usos, como negociar el tamaño máximo de los segmentos.

#### Ejemplo Completo de un Proceso de Comunicación TCP
1. **Inicio de conexión**:
   - **SYN**: El cliente envía un segmento con el bit SYN activado para iniciar una conexión.
   - **SYN-ACK**: El servidor responde con SYN y ACK activados, indicando que acepta la conexión y reconoce el SYN del cliente.
   - **ACK**: El cliente responde con un ACK, estableciendo la conexión.

2. **Transmisión de datos**:
   - El cliente envía datos y establece el número de secuencia inicial. Usa ACK para confirmar recepción, y el receptor ajusta la ventana de recepción si es necesario.

3. **Cierre de conexión**:
   - **FIN**: El cliente envía un segmento con FIN activado.
   - **ACK**: El servidor responde con un ACK.
   - **FIN**: El servidor envía un FIN cuando está listo para cerrar.
   - **ACK**: El cliente confirma con un ACK y la conexión se cierra.

Esta estructura y sus campos aseguran que los datos lleguen de manera correcta, ordenada y gestionen problemas de flujo y errores en la transmisión.


# 3.4 Congestion
## 3.4.1 Introducción
La congestión en redes TCP ocurre cuando demasiados paquetes intentan atravesar la red al mismo tiempo, causando retrasos y pérdida de datos debido a la saturación de las memorias de los routers. Esta saturación hace que los routers tengan que desechar paquetes, lo cual provoca más retransmisiones y empeora el problema. TCP implementa mecanismos para manejar esta congestión, regulando la tasa de envío en función de la congestión percibida en la red. Estos mecanismos son esenciales para mantener un flujo de datos eficiente y equilibrado. Veamos en detalle cada escenario de congestión y las técnicas de control que usa TCP:

#### Escenarios de Congestión
##### Escenario 1: Memoria Infinita en los Routers
Imaginemos que los routers pueden almacenar una cantidad infinita de datos. En este caso, conforme la tasa de envío de paquetes se acerca a la capacidad del enlace, los paquetes comienzan a acumularse en la cola del router, generando retrasos. Estos retrasos se van acumulando con cada nuevo paquete, creando un "cuello de botella". 

Por ejemplo, si la capacidad del enlace es de 10 Mbps y la tasa de envío es de 9 Mbps, habrá un leve retraso. Sin embargo, al alcanzar los 10 Mbps, los retrasos aumentan drásticamente, afectando a todos los paquetes que esperan en la cola.
![[archivos/imagenes/Pasted image 20241027110713.png]]

##### Escenario 2: Memoria Finita en un Router
En este caso, el router tiene una memoria limitada. Cuando la cola se llena, el router empieza a descartar paquetes. Esto obliga al emisor a retransmitir los paquetes perdidos, lo que, a su vez, aumenta aún más la carga en la red y agrava la congestión.

Por ejemplo, si un router puede almacenar hasta 1000 paquetes y se llena debido a una tasa de envío alta, los paquetes adicionales se descartan. Esto desencadena retransmisiones, y el emisor, en lugar de reducir su tasa, sigue enviando más paquetes, empeorando la situación.

##### Escenario 3: Camino con Múltiples Routers
Cuando hay varios routers en el camino, si un paquete se pierde a mitad del camino, los routers anteriores han gastado recursos procesando un paquete que finalmente no llegó a su destino. Esto reduce la eficiencia general de la red, ya que se desperdicia capacidad en procesar paquetes que no alcanzarán su destino.

Por ejemplo, en una red con cinco routers, si el tercer router descarta un paquete, el esfuerzo de los primeros dos routers es en vano, y la capacidad útil de la red se reduce.

![[archivos/imagenes/Pasted image 20241027110733.png]]

## 3.4.2 Control de Congestión en TCP
Para manejar la congestión, TCP ajusta la tasa de envío basándose en la congestión percibida, utilizando dos variables: la **ventana de congestión** y el **RTT** (Round-Trip Time). 

La tasa de envío de TCP se calcula así:

$$
\text{Tasa de envío} = \frac{\text{ventana de congestión}}{\text{RTT}}
$$

#### Fases de la Ventana de Congestión en TCP
TCP gestiona la congestión a través de tres fases: 

1. **Arranque Lento**
   - Al iniciar una conexión, TCP empieza con una ventana de congestión pequeña, equivalente al tamaño máximo del segmento (MSS). 
   - Supongamos que **MSS** es de 500 bytes y **RTT** es de 0.2 segundos, la tasa de transmisión inicial es $\frac{500 \times 8}{0.2} = 20 \, \text{kbps}$.
   - La ventana de congestión se duplica cada intervalo RTT hasta que ocurre una pérdida, momento en el que se pasa a la siguiente fase.

![[archivos/imagenes/Pasted image 20241027110812.png]]

2. **Incremento Aditivo, Decremento Multiplicativo (AIMD)**
   - Si se pierden segmentos y el emisor recibe tres ACKs duplicados, TCP interpreta esto como una congestión leve y reduce la ventana a la mitad (decremento multiplicativo).
   - Luego, aumenta la ventana de manera lineal (incremento aditivo), sumando pequeñas cantidades para probar el ancho de banda disponible.
   
   Por ejemplo, si la ventana es de 16 KB y se reciben tres ACKs duplicados, se reduce a 8 KB y luego se incrementa poco a poco.
   
![[archivos/imagenes/Pasted image 20241027110833.png]]

3. **Vencimiento del Temporizador**
   - Si el temporizador expira sin recibir un ACK, TCP interpreta esto como una congestión grave y vuelve a la fase de arranque lento, reiniciando la ventana de congestión a 1 MSS. 
   - Aumenta la ventana exponencialmente al principio, pero luego se detiene en la mitad del valor previo y continúa aumentando de forma lineal.
   
   Por ejemplo, si la ventana de congestión era de 24 KB y el temporizador expira, la ventana vuelve a 1 MSS y se incrementa exponencialmente hasta llegar a la mitad de los 24 KB previos, y luego crece linealmente.
   
![[archivos/imagenes/Pasted image 20241027110849.png]]

## 3.4.3 Imparcialidad
Cuando varias conexiones TCP comparten un enlace, ajustan su tasa de envío automáticamente para repartir la capacidad disponible del enlace de manera equitativa. Por ejemplo, si dos conexiones TCP comparten un enlace de 10 Mbps, cada una recibirá aproximadamente 5 Mbps.

![[archivos/imagenes/Pasted image 20241027110946.png]]

![[archivos/imagenes/Pasted image 20241027110958.png]]

Sin embargo, cuando se introduce una conexión UDP junto con TCP, la conexión UDP, al no tener control de congestión, puede acaparar la mayor parte del ancho de banda. Del mismo modo, si se establece una conexión TCP junto con nueve conexiones TCP paralelas, el enlace se repartirá en una proporción de 1/10 para la primera conexión y 9/10 para las demás.
