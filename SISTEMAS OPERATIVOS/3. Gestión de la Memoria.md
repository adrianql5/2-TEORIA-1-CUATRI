[[archivos/bibliografia/2-Sistemas operativos moderno 3ed Tanenbaum.pdf|2-Sistemas operativos moderno 3ed Tanenbaum]]

Escrito por **Adrián Quiroga Linares**.


Los ordenadores tienen una **jerarquía de memoria**, que incluye **memoria caché** (*rápida, costosa y volátil*), **memoria principal** (*de velocidad media y precio moderado*), almacenamiento en **disco** (*lento, económico y no volátil*), y **almacenamiento removible**. El sistema operativo debe gestionar esta jerarquía de manera eficiente. Esto se logra a **través del ADMINITRADOR DE MEMORIA, encargado de asignar y liberar memoria según sea necesario**.

![[archivos/imagenes/Pasted image 20241121183519.png]]

# Sin abstracción de la memoria: 
En los sistemas más antiguos y simples,  no existía **abstracción de memoria**. Los programas interactuaban directamente con la **memoria física**, lo que significa que cada programa veía un conjunto lineal de direcciones físicas desde 0 hasta un valor máximo, donde cada dirección correspondía a una celda con un tamaño fijo de bits (típicamente 8 bits, un byte). Esto significaba:

1. **Acceso directo**: Si un programa ejecutaba una instrucción como `MOV REGISTRO1, 1000`, simplemente accedía a la ubicación física 1000 en la memoria.
2. **No había separación entre programas**: Si dos programas intentaban usar la misma dirección de memoria, podían sobrescribir los datos del otro, lo que resultaba en **fallos inmediatos**.

## Organización de la memoria en sistemas sin abstracción

A pesar de no tener abstracción de memoria, existían diversas formas de organizar la memoria en estos sistemas, como se muestra en la figura 3-1:

1. **Sistema operativo en RAM (Figura 3-1a)**:
    - El sistema operativo residía en la parte inferior de la memoria RAM.
    - Este modelo era común en las primeras mainframes y minicomputadoras.
    - **Problema**: Un error en **el programa del usuario podía sobrescribir el sistema operativo**.

2. **Sistema operativo en ROM (Figura 3-1b)**:
    - El sistema operativo se colocaba en la parte superior de la memoria, en una ROM.
    - Común en sistemas integrados y computadoras de bolsillo.
    - **La ROM protegía el sistema operativo de ser modificado**, ya que era de solo lectura.

3. **Sistema operativo dividido entre RAM y ROM (Figura 3-1c)**:
    - El sistema operativo principal estaba en RAM, y los controladores de dispositivos en ROM.
    - Ejemplo: Las primeras computadoras personales, como las que usaban MS-DOS.
    - **BIOS (Basic Input Output System)**: Parte del sistema operativo en ROM.

![[archivos/imagenes/Pasted image 20241121183354.png]]

Una vez que los programas **se cargan se pueden ejecutar**. Como tienen distintas llaves de memoria, **ninguno de los dos puede dañar al otro**. Pero el problema es de una naturaleza distinta. El problema central aquí es que **los dos programas hacen referencia a la memoria física absoluta**. Eso, definitivamente, **no es lo que queremos**; deseamos que cada programa haga referencia a un conjunto privado de direcciones locales para él. En breve le mostraremos cómo se logra esto. Lo que la IBM 360 hacía como solución para salir del paso era modificar el segundo programa al instante, a medida que se cargaba en la memoria, usando una técnica conocida como **reubicación estática**. Aunque este mecanismo funciona si se lleva a cabo en la forma correcta, no es una solución muy general y **reduce la velocidad de la carga**.

En la actualidad, los dispositivos como las radios, las lavadoras y los hornos de microondas están llenos de software (en ROM), y en la mayoría de los casos el software **direcciona memoria absoluta**. Esto funciona debido a que todos los programas se conocen de antemano, y **los usuarios no tienen la libertad de ejecutar su propio software**.

![[archivos/imagenes/Pasted image 20241121183424.png]]


# Espacios de Direcciones
Exponer directamente la memoria física a los procesos tiene desventajas, principalmente:

1. **Problemas de protección:** Los procesos pueden alterar accidental o intencionalmente el sistema operativo.
2. **Dificultad para ejecutar múltiples programas:** Es complejo mantener varios programas en memoria al mismo tiempo sin interferencias.

Para resolver esto, se introduce una **abstracción de memoria** conocida como el **espacio de direcciones**.

---
### **La noción de un espacio de direcciones**
Un **espacio de direcciones** es el conjunto de direcciones que un proceso puede utilizar para acceder a la memoria. Cada proceso tiene su propio espacio, independiente de los demás, salvo casos específicos de compartición.

Este concepto se aplica a múltiples contextos, como:

- **Direcciones IP:** Espacio de 32 bits (IPv4: 0 a 232−12^{32}-1).
- **Puertos de E/S:** Espacio de direcciones de 0 a 16,383 en el Pentium.
- **Dominios de Internet:** Cadenas alfanuméricas, como en ".com".

El desafío consiste en asignar a cada programa un espacio de direcciones que corresponda a distintas ubicaciones físicas sin interferencias.

---
#### **Registros base y límite**
Una solución clásica utiliza **reubicación dinámica** con registros especiales en el hardware de la CPU:

1. **Registro base:** Contiene la dirección física donde empieza el programa.
2. **Registro límite:** Define la longitud del programa.

Cuando un proceso accede a la memoria:
- El hardware suma automáticamente el valor del registro base a la dirección generada por el programa.
- Verifica si la dirección resultante excede el rango permitido (base + límite). Si es así, genera un error y aborta el acceso.

##### **Ventajas:**
- Permite a cada proceso un espacio de direcciones privado.
- Protege los registros base y límite, para que solo el sistema operativo pueda modificarlos.

##### **Desventajas:**
- Se requiere realizar una suma y una comparación en cada acceso a memoria, lo que puede ser lento sin circuitos especiales.

![[archivos/imagenes/Pasted image 20241121185123.png]]
---

#### **Conclusión**
Los espacios de direcciones permiten a los sistemas operativos abstraer y gestionar la memoria de forma segura y eficiente, haciendo posible la ejecución de múltiples programas simultáneamente sin interferencias. Este concepto evolucionó con el tiempo hacia métodos más avanzados en los procesadores modernos.

### Itercambio
El intercambio (_swapping_) es una estrategia de administración de memoria que permite a los sistemas operativos ejecutar procesos incluso cuando no hay suficiente memoria física disponible para alojarlos todos al mismo tiempo. Se basa en mover procesos completos entre la memoria principal (RAM) y el almacenamiento secundario (disco) según sea necesario.

#### **Motivación para el Intercambio**
1. **Cantidad limitada de RAM:** En sistemas modernos, la cantidad total de RAM necesaria para ejecutar todos los procesos concurrentemente puede exceder la memoria disponible.
    
    - Por ejemplo, aplicaciones de usuario como navegadores o editores de video pueden consumir entre 50 y 200 MB cada una.
    - Además, procesos en segundo plano como actualizaciones de software o comprobaciones de correo ocupan memoria, incluso antes de que el usuario ejecute sus propias aplicaciones.
2. **Requerimientos dinámicos:** Los procesos pueden necesitar más memoria durante su ejecución debido a estructuras dinámicas como el _heap_ o la pila.


#### **Cómo Funciona el Intercambio**
1. **Movimiento de procesos:**
    - Cuando un proceso está listo para ejecutarse, se carga completamente en la memoria.
    - Una vez que ha usado su tiempo de CPU asignado o se encuentra inactivo, puede ser devuelto al disco, liberando espacio en la memoria.

2. **Ejemplo de Operación:**
    - Inicialmente, sólo el proceso A está en la memoria.
    - Luego, se cargan los procesos B y C, desplazando a A si es necesario.
    - Más tarde, A regresa a memoria en una ubicación diferente, requiriendo que sus direcciones se ajusten.

3. **Reubicación de direcciones:**
    - Cuando un proceso se mueve, las direcciones internas que usa deben ser actualizadas.
    - Esto puede realizarse mediante:
        - **Software:** Reescribiendo las direcciones durante el intercambio.
        - **Hardware:** Usando registros base y límite para traducir las direcciones durante la ejecución.


![[archivos/imagenes/Pasted image 20241121185439.png]]

#### **Desafíos del Intercambio**
1. **Fragmentación de la memoria:**
    - Con el tiempo, el intercambio puede generar espacios vacíos dispersos (*fragmentación externa*).
        
    - Una técnica para solucionar esto es la **compactación de memoria**, donde los procesos se agrupan desplazándolos hacia abajo en la memoria.
        
    - Sin embargo, este proceso es costoso en términos de tiempo de CPU.
        
    
    > Por ejemplo, en un sistema con 1 GB de RAM y un ancho de banda de 4 bytes cada 20 nanosegundos, la compactación completa tomaría cerca de 5 segundos.

>[! Info]
> **Fragmentación interna:**
> La fragmentación interna ocurre cuando un bloque de memoria asignado a un proceso es más grande de lo necesario para contener los datos del proceso. El espacio restante dentro del bloque no puede ser utilizado por otros procesos, lo que genera un desperdicio.
> 
> **Fragmentación externa:**
> La fragmentación externa ocurre cuando hay suficiente memoria libre para satisfacer una solicitud, pero esa memoria está dividida en pequeños bloques no contiguos, lo que impide la asignación de un espacio único lo suficientemente grande.

2. **Asignación de memoria adicional:**
    - Cuando se espera que los procesos crezcan (por ejemplo, usando _heap_), se puede asignar espacio extra para evitar moverlos con frecuencia.
    - Si un proceso crece más allá del espacio asignado, puede:
        - Usar un hueco adyacente.
        - Moverse a otro lugar en la memoria.
        - Intercambiarse al disco hasta que haya espacio disponible.
3. **Eficiencia:**
    - Sólo debe intercambiarse al disco la memoria realmente en uso por el proceso, ya que intercambiar espacio extra es ineficiente.

#### **Esquemas para Crecimiento de Procesos**
1. **Crecimiento de segmentos únicos:**
    - Si sólo se espera que crezca un segmento (por ejemplo, datos), se reserva espacio adicional entre procesos.

2. **Crecimiento de múltiples segmentos:**
    - En lenguajes de programación que usan tanto _heap_ como pila, ambos pueden crecer simultáneamente en direcciones opuestas:
        - _Heap_ crece hacia arriba.
            
        - _Pila_ crece hacia abajo.
               
    > Si el espacio reservado entre ambos se agota, el proceso deberá moverse o intercambiarse.

![[archivos/imagenes/Pasted image 20241121185557.png]]

#### **Conclusión**
El intercambio es una solución efectiva cuando la memoria física no es suficiente para contener todos los procesos. Sin embargo, tiene limitaciones debido al tiempo de procesamiento requerido para mover procesos, gestionar fragmentación y realizar compactación. Esta estrategia sentó las bases para la **memoria virtual**, que ofrece mayor flexibilidad al permitir que procesos se ejecuten parcialmente en memoria, tema que se aborda en la sección siguiente.

### Administración de la memoria libre
Cuando la memoria se asigna dinámicamente, el sistema operativo administra el espacio disponible mediante dos métodos principales: **mapas de bits** y **listas libres**. Cada método tiene ventajas y desventajas según el diseño y las necesidades del sistema.

#### **1. Administración de Memoria con Mapas de Bits**
En este método:
- **División de la memoria**: La memoria se divide en unidades de asignación. Estas unidades pueden ser pequeñas (unas palabras) o grandes (varios kilobytes).
- **Mapa de bits**: Por cada unidad de memoria, existe un bit en el mapa:
    - **0**: Indica que la unidad está libre.
    - **1**: Indica que la unidad está ocupada.

**Ejemplo**: La memoria de la figura 3-6(a) tiene procesos y huecos representados como bloques. Su mapa de bits correspondiente es una secuencia de bits, donde las áreas sombreadas indican unidades libres.

**Diseño del mapa**:
- El tamaño del mapa depende del tamaño de la memoria y de la unidad de asignación.
- Ejemplo: Con unidades de 4 bytes, un mapa de bits requiere 1 bit por cada 4 bytes de memoria. Esto equivale a que el mapa ocupa 1/33 del tamaño total de la memoria.

**Desafíos**:
1. **Búsqueda lenta**: Encontrar un bloque libre de tamaño kk implica buscar en el mapa hasta hallar kk bits consecutivos en 0. Esto puede cruzar límites entre palabras del mapa, volviendo el proceso más lento.
2. **Fragmentación interna**: Si el proceso no ocupa un múltiplo exacto de la unidad de asignación, **2**

![[archivos/imagenes/Pasted image 20241121190131.png]]

#### **2. Administración de Memoria con Listas Ligadas**
En este método:
- **Representación**: La memoria se gestiona como una lista ligada de segmentos. Cada segmento puede ser un proceso o un hueco vacío.
    - **Nodo de la lista**: Contiene información sobre el tipo (proceso o hueco), la dirección inicial, la longitud y un puntero al siguiente segmento.

**Ventajas**:
- La lista se mantiene ordenada por direcciones, lo que facilita actualizaciones cuando un proceso termina o es intercambiado.

**Gestión de huecos**: Cuando un proceso finaliza, su espacio se convierte en un hueco. Esto implica cuatro posibles combinaciones según los vecinos (ver figura 3-7):
1. Un único proceso vecino se reemplaza por un hueco.
2. Dos entradas (un hueco y un proceso) se fusionan.
3. Se eliminan dos entradas y se crea un hueco mayor.
4. Tres entradas (dos huecos y un proceso) se combinan en una sola.

![[archivos/imagenes/Pasted image 20241121190250.png]]

#### **3. Algoritmos de Asignación**
Los algoritmos más comunes son:

1. **Primer Ajuste**:
    - Recorre la lista hasta encontrar el primer hueco suficientemente grande.
    - Es rápido porque no busca más allá del primer hueco adecuado.
2. **Siguiente Ajuste**:    
    - Similar al primer ajuste, pero empieza a buscar desde donde quedó la última búsqueda, no desde el principio.
    - Es ligeramente menos eficiente que el primer ajuste.
3. **Mejor Ajuste**:
    - Busca en toda la lista el hueco más pequeño que sea suficiente.
    - Ventaja: Reduce el desperdicio al dividir grandes huecos innecesariamente.
    - Desventaja: Es más lento y puede fragmentar la memoria con huecos pequeños e inutilizables.
4. **Peor Ajuste**:
    - Selecciona siempre el hueco más grande disponible.
    - Es poco eficiente en la práctica, ya que crea fragmentación rápidamente.
5. **Ajuste Rápido**:
    - Mantiene listas separadas para tamaños comunes (e.g., 4 KB, 8 KB, etc.).
    - Es muy rápido, pero puede causar fragmentación si no se fusionan los huecos vecinos.

---

#### **Optimizaciones**
1. **Listas separadas**:
    - Una lista para procesos y otra para huecos. Esto acelera la asignación pero complica la desasignación.
    - Si la lista de huecos se ordena por tamaño, se optimiza el mejor ajuste.
2. **Información embebida**:
    - En los huecos, se almacena directamente el tamaño y el puntero al siguiente nodo, eliminando la necesidad de estructuras adicionales.

#### Resumen
- **Mapas de bits** son simples y ocupan poca memoria, pero la búsqueda es lenta.
- **Listas libres** son más versátiles, especialmente con algoritmos como el primer o mejor ajuste, aunque pueden ser más complejas de manejar.
- La elección entre ambos métodos depende del balance entre rapidez, eficiencia de memoria y facilidad de implementación.


# Memoria Virtual
La **memoria virtual** es un concepto fundamental en los sistemas operativos modernos que permite a los programas acceder a un espacio de direcciones lógico mayor que la memoria física disponible. Este mecanismo resuelve problemas históricos asociados con la limitación de memoria física y la necesidad de manejar programas que son demasiado grandes para caberen ella.

### Concepto de Memoria Virtual
Introducida en 1961 por Fotheringham, la memoria virtual automatizó este proceso y eliminó la carga de trabajo del programador. La idea básica es que:

- Cada programa tiene su propio **espacio de direcciones lógico**, que es independiente del tamaño de la memoria física.
- Este espacio de direcciones se divide en unidades llamadas **páginas**, que son bloques contiguos de direcciones lógicas.
- Las páginas pueden estar asociadas a la memoria física en un momento dado, pero no todas tienen que estar presentes simultáneamente.

Cuando un programa intenta acceder a una dirección que no está en la memoria física, ocurre un **fallo de página**. En este caso:

1. El hardware detecta la ausencia de la página requerida.
2. El sistema operativo interviene para buscar la página faltante en el disco.
3. La página se carga en la memoria física, y la instrucción que generó el fallo se reintenta.

#### Comparación con Registros Base y Límite
La memoria virtual puede considerarse una evolución de los registros base y límite, que se utilizaban para manejar espacios de direcciones simples. Mientras que estos registros permitían asociar segmentos específicos de un programa (como texto o datos) a ubicaciones fijas de memoria, la memoria virtual extiende este concepto al permitir la asociación dinámica de **todo el espacio de direcciones lógico** en pequeñas unidades (páginas) que se distribuyen a lo largo de la memoria física.

#### Ventajas de la Memoria Virtual
1. **Eficiencia en Sistemas Multiprogramados:** Permite que varias partes de distintos programas estén en la memoria simultáneamente, optimizando el uso de la CPU al cambiar entre procesos mientras las páginas necesarias se cargan desde el disco.
2. **Flexibilidad para Programas Grandes:** Los programas pueden tener un espacio de direcciones lógico mayor que la memoria física sin requerir que el programador los divida manualmente.
3. **Aislamiento y Seguridad:** Cada programa opera en su propio espacio de direcciones lógico, lo que reduce la probabilidad de que un programa afecte a otro.


### **Paginación**
La paginación es una técnica ampliamente utilizada en los sistemas de memoria virtual para gestionar eficientemente la relación entre el espacio de direcciones virtuales y el espacio de memoria física disponible. Este método divide tanto las direcciones virtuales como la memoria física en bloques de tamaño fijo, conocidos como **páginas** y **marcos de página**, respectivamente. A continuación, se explica en detalle el concepto y funcionamiento de la paginación.

#### **Direcciones Virtuales y Físicas**
1. **Direcciones Virtuales**:
    - Las **direcciones virtuales** son generadas por los programas cuando acceden a la memoria. Por ejemplo, una instrucción como `MOV REG, 1000` accede a la dirección virtual 1000.
    - Estas direcciones no corresponden directamente a ubicaciones en la memoria física cuando se utiliza memoria virtual.
    - En cambio, las direcciones virtuales forman el **espacio de direcciones virtuales**, que puede ser mucho mayor que la memoria física disponible.
2. **Direcciones Físicas**:
    - La **memoria física** contiene un espacio de direcciones más limitado. Sin memoria virtual, las direcciones virtuales se colocan directamente en el bus de memoria y se accede a la ubicación física correspondiente.
    - En sistemas con memoria virtual, las direcciones virtuales se transforman en direcciones físicas a través de la **Unidad de Gestión de Memoria (MMU, por sus siglas en inglés)**.

#### **Función de la MMU**
La **MMU** asocia direcciones virtuales con direcciones físicas. Esto se logra mediante una estructura llamada **tabla de páginas**, que contiene:

- Un **índice** basado en el número de página virtual.
- El **marco de página físico** correspondiente.
- Un **bit de presente/ausente**, que indica si la página está cargada en la memoria física.

![[archivos/imagenes/Pasted image 20241202164641.png]]

#### **Estructura de la Paginación**
##### **División en Páginas y Marcos**
- **Páginas**: Unidades del espacio de direcciones virtuales, de tamaño fijo (por ejemplo, 4 KB).
- **Marcos de página**: Bloques equivalentes en la memoria física.
- Por ejemplo, en un sistema con 64 KB de espacio virtual y 32 KB de memoria física:
    - El espacio virtual se divide en **16 páginas** (64 KB ÷ 4 KB).
    - La memoria física se divide en **8 marcos de página** (32 KB ÷ 4 KB).

![[archivos/imagenes/Pasted image 20241202164738.png]]

##### **Tabla de Páginas**
- Asocia cada página virtual a un marco de página físico o marca la página como "no presente".
- En el ejemplo:
    - Solo 8 páginas virtuales pueden estar en memoria física simultáneamente.
    - Las páginas restantes se almacenan en el disco y se cargan según sea necesario.

![[archivos/imagenes/Pasted image 20241202164827.png]]

#### **Transformación de Direcciones**
1. **División de Direcciones Virtuales**:
    - Una dirección virtual se divide en dos partes:
        - **Número de página virtual**: Determina qué página contiene la dirección.
        - **Desplazamiento dentro de la página**: Indica la ubicación exacta dentro de la página.
    - Por ejemplo, una dirección virtual de 16 bits se divide en:
        - 4 bits para el número de página (16 páginas posibles).
        - 12 bits para el desplazamiento (4 KB por página).
2. **Conversión por la MMU**:
    - El número de página virtual se usa como índice en la tabla de páginas.
    - Si la página está presente:
        - Se obtiene el número del marco de página físico.
        - El desplazamiento se combina con este número para formar la dirección física.
    - Si la página no está presente:
        - Ocurre un **fallo de página**.

![[archivos/imagenes/Pasted image 20241202165036.png]]

#### **Fallo de Página y Gestión**
##### **Fallo de Página**
- Si el programa intenta acceder a una página virtual no cargada, la MMU provoca un **trap** al sistema operativo.
- El sistema operativo:
    1. Selecciona un marco de página físico a desalojar (usando técnicas como **LRU**, menos recientemente usado).
    2. Escribe la página desalojada al disco, si ha sido modificada.
    3. Carga la página requerida desde el disco al marco recién liberado.
    4. Actualiza la tabla de páginas para reflejar los cambios.

##### **Ejemplo**:
- Dirección virtual: `32780` (byte 12 dentro de la página virtual 8).
- Si la página virtual 8 no está cargada:
    1. El sistema operativo selecciona un marco físico para liberar.
    2. Carga la página 8 en memoria.
    3. Asocia la página virtual 8 con un marco físico.
    4. Reintenta la operación, ahora accediendo a la dirección física correcta.


![[archivos/imagenes/Pasted image 20241204132639.png]]

#### **Ventajas del Tamaño de Página como Potencia de 2**
- Simplifica el cálculo de la dirección física:
    - Los bits más altos determinan el número de página.
    - Los bits más bajos corresponden al desplazamiento.
- Ejemplo:
    - Dirección virtual `8196` (0010000000000100 en binario):
        - Página virtual: `2` (bits más altos).
        - Desplazamiento: `4` (bits más bajos).
        - La tabla de páginas indica que la página virtual `2` está en el marco físico `6`.
        - Dirección física: `24580`.

---
### **Tablas de Páginas**

#### **División de la Dirección Virtual**

En sistemas con memoria virtual, una dirección virtual consta de dos partes principales:

1. **Número de página virtual:** Representa la página virtual dentro del espacio de direcciones virtuales.
2. **Desplazamiento:** Representa la posición exacta dentro de esa página.

Por ejemplo, en una dirección de 16 bits con páginas de 4 KB:

- Los **4 bits superiores** definen la página virtual, permitiendo identificar hasta 16 páginas.
- Los **12 bits inferiores** representan el desplazamiento dentro de la página, cubriendo las direcciones de 0 a 4095.

La traducción de direcciones implica utilizar el número de página virtual como índice en una tabla de páginas, donde se almacena la asociación entre páginas virtuales y marcos de página físicos.

#### **Función de la Tabla de Páginas**
La **tabla de páginas** actúa como una función que asocia:

- **Entrada:** Número de página virtual.
- **Salida:** Número del marco de página físico.

El resultado se utiliza para reemplazar el campo de página virtual en la dirección virtual con el marco de página físico, formando así una dirección física. Este mecanismo permite que el programa trabaje con un espacio de direcciones virtuales que puede ser más grande que la memoria física disponible.

#### **Estructura de una Entrada en la Tabla de Páginas**
Cada entrada de la tabla de páginas contiene varios campos que ayudan al sistema a manejar la traducción y la gestión de memoria. Una entrada típica tiene un tamaño común de **32 bits** y puede incluir los siguientes elementos:

1. **Número de Marco de Página:**
    
    - Es el valor clave que permite asociar una página virtual con un marco físico.
    - Es el principal objetivo de la tabla.
2. **Bit de Presente/Ausente:**
    
    - Indica si la página virtual está actualmente cargada en la memoria física.
    - Si el bit está en `0`, acceder a esa página genera un **fallo de página**, desencadenando una acción del sistema operativo.
3. **Bits de Protección:**
    
    - Determinan los permisos de acceso.
    - Configuración básica:
        - `0`: Lectura/escritura.
        - `1`: Solo lectura.
    - Configuración avanzada: Permisos separados para lectura, escritura y ejecución.
4. **Bit de Modificada (o Sucia):**
    
    - Se establece automáticamente cuando una página se modifica.
    - Ayuda al sistema operativo a decidir si es necesario escribir la página de vuelta al disco antes de reemplazarla.
5. **Bit de Referenciada:**
    
    - Se marca cuando una página se utiliza (ya sea para lectura o escritura).
    - Es crucial para los **algoritmos de reemplazo de páginas**, ya que indica qué páginas están activamente en uso.
6. **Bit para Deshabilitar Caché:**
    
    - Utilizado para páginas asociadas a dispositivos de entrada/salida (E/S) en lugar de memoria convencional.
    - Garantiza que las operaciones se realicen directamente con el dispositivo y no con datos obsoletos en la caché.

![[archivos/imagenes/Pasted image 20241202170713.png]]

#### **Consideraciones Importantes**
1. **Fallo de Página y Manejador de Disco:**
    
    - La tabla de páginas no incluye información sobre la ubicación en disco de una página no cargada.
    - Esa información la gestiona el sistema operativo en sus propias estructuras de datos.
2. **Memoria Virtual como Abstracción:**
    
    - La memoria virtual abstrae la memoria física, permitiendo que los programas operen en un espacio de direcciones uniforme.
    - Similar a cómo los procesos abstraen la CPU, las tablas de páginas y la memoria virtual crean una ilusión de memoria ilimitada.
3. **Tamaño de Página como Potencia de Dos:**
    
    - Facilita la división de direcciones y la traducción mediante operaciones simples de bits.
    - Ejemplo: Con 4 KB por página, los 12 bits inferiores de una dirección virtual corresponden siempre al desplazamiento.


### Aceleración de la paginación
La **paginación** en sistemas operativos es un mecanismo que permite usar la memoria de forma eficiente mediante la asociación de direcciones virtuales a direcciones físicas. Para **acelerarla**, se introducen técnicas y hardware especializado que minimizan los costos asociados a este proceso. Una de las herramientas más importantes para lograrlo es el **Translation Lookaside Buffer (TLB)**.

#### **¿Qué es el TLB?**
El **Translation Lookaside Buffer (TLB)** es una pequeña memoria caché de hardware, integrada generalmente en la **Unidad de Manejo de Memoria (MMU)**. Su función es almacenar temporalmente las traducciones más recientes entre direcciones virtuales y físicas. Esto evita tener que acceder continuamente a la tabla de páginas principal en la memoria, que es un proceso lento.

![[archivos/imagenes/Pasted image 20241209094711.png]]


#### **Funcionamiento del TLB**
1. **Consulta de direcciones virtuales:**
    
    - Cuando la CPU necesita traducir una dirección virtual a una dirección física, primero consulta el TLB.
    - Si la dirección está en el TLB (**acierto en el TLB**), la traducción ocurre directamente en nanosegundos.
    - Si no está en el TLB (**fallo en el TLB**), el sistema busca la entrada correspondiente en la tabla de páginas en la memoria principal y actualiza el TLB con esta nueva entrada.
2. **Gestión de entradas:**
    
    - Cada entrada del TLB contiene:
        - Número de página virtual.
        - Marco de página física correspondiente.
        - Bits de control, como el bit de **protección** (lectura/escritura/ejecución) y el bit **modificado** (indica si la página fue escrita).
    - Si una página es reemplazada en el TLB (por un fallo), el bit modificado se copia de vuelta a la tabla de páginas para mantener la coherencia.

#### **¿Cómo acelera la paginación el TLB?**
1. **Reducción de accesos a la tabla de páginas:**
    
    - Sin un TLB, cada referencia de memoria requeriría al menos un acceso adicional a la tabla de páginas en memoria principal, lo cual es lento.
    - Con el TLB, una gran proporción de estas referencias puede resolverse directamente en el hardware, sin acceder a la memoria principal.
2. **Principio de localidad:**
    
    - Los programas tienden a acceder repetidamente a un subconjunto pequeño de páginas durante un periodo corto (localidad espacial y temporal). Esto significa que una caché pequeña como el TLB puede ser altamente efectiva.
3. **Velocidad de hardware:**
    
    - El TLB opera con velocidades similares a la de la CPU, lo que evita que la traducción de direcciones sea un cuello de botella.


#### **Tipos de fallos en el TLB**
1. **Fallo suave (soft miss):**
    
    - Ocurre cuando la dirección virtual no tiene una entrada correspondiente en el TLB, pero la página asociada **ya está cargada en la memoria principal**.
    - **Solución:** El hardware o el kernel actualiza el TLB con la traducción correcta desde la tabla de páginas.
    - Este proceso es relativamente rápido, ya que solo requiere acceder a la tabla de páginas en memoria principal y realizar unas pocas operaciones, lo que puede tomar decenas de nanosegundos o microsegundos.
2. **Fallo duro (hard miss):**
    
    - Ocurre cuando la dirección virtual no tiene una entrada en el TLB, y además, **la página no está presente en la memoria principal** (es decir, ocurre un _page fault_).
    - **Solución:** El sistema operativo debe cargar la página desde la memoria secundaria (como el disco) a un marco de la memoria principal y, después, actualizar el TLB con la nueva traducción.
    - Este proceso es mucho más lento debido a las operaciones de E/S de disco, que pueden tardar varios milisegundos. En casos extremos, esto puede causar retrasos significativos en la ejecución del programa.


#### **Optimización del uso del TLB**
1. **Precarga de páginas:**
    
    - El sistema operativo puede anticiparse y cargar entradas al TLB antes de que sean necesarias, basado en patrones de uso del programa.
2. **Estrategias de reemplazo:**
    
    - Cuando el TLB está lleno, utiliza algoritmos como **Least Recently Used (LRU)** para decidir qué entrada reemplazar.
3. **Caché de software para el TLB:**
    
    - Algunas máquinas mantienen una pequeña caché de entradas de tabla de páginas gestionada por software en memoria fija. Esto ayuda a reducir fallos adicionales durante la resolución de un fallo en el TLB.



### Tablas de páginas para memorias extensas
#### **1. Tablas de páginas multinivel**

Este método organiza las tablas de páginas en niveles jerárquicos para manejar eficientemente espacios de direcciones grandes sin cargar tablas innecesarias en memoria.

##### **Cómo funcionan:**

1. **Dirección virtual particionada:**  
    Una dirección virtual de 32 bits se divide en:
    
    - **TP1 (10 bits):** Índice para la tabla de páginas de nivel superior.
    - **TP2 (10 bits):** Índice para una tabla de segundo nivel.
    - **Desplazamiento (12 bits):** Define la posición dentro de una página (tamaño de página = 4 KB).
2. **Jerarquía de tablas:**
    
    - La tabla de nivel superior tiene **1024 entradas (2¹⁰)**, y cada entrada apunta a una tabla de segundo nivel.
    - Cada tabla de segundo nivel también tiene **1024 entradas** y cubre un espacio de direcciones de **4 MB** (1024 páginas de 4 KB).
3. **Ejemplo:**
    
    - Si la dirección virtual es `0x00403004`:
        - **TP1 = 1**: Selecciona la segunda entrada de la tabla de nivel superior (espacio de 4 MB a 8 MB).
        - **TP2 = 2**: Selecciona la tercera entrada de la tabla de segundo nivel dentro de este espacio.
        - **Desplazamiento = 4**: Define la posición dentro de la página.
    - La dirección física resultante se obtiene combinando el marco de página y el desplazamiento.
4. **Ventajas:**
    
    - Sólo las tablas necesarias están en memoria, ahorrando espacio.
    - Es eficiente para procesos con huecos grandes en su espacio de direcciones.
5. **Escalabilidad:**
    
    - Se puede extender a tres o más niveles para manejar espacios aún mayores (por ejemplo, sistemas de 64 bits).

![[archivos/imagenes/Pasted image 20241204135457.png]]


![[1]]

![[archivos/imagenes/Pasted image 20241209122140.png]]

#### **2. Tablas de páginas invertidas**
La **tabla de páginas invertida** (Inverted Page Table o IPT) es una alternativa eficiente a las tablas de páginas tradicionales. Se utiliza en sistemas con memoria virtual para reducir el espacio necesario para almacenar la relación entre direcciones virtuales y físicas, especialmente en sistemas con grandes espacios de direcciones.

En una tabla de páginas convencional, hay **una entrada por cada página del espacio de direcciones virtuales** de cada proceso. Esto puede llevar a tablas de páginas extremadamente grandes, ya que el tamaño crece proporcionalmente al espacio de direcciones y al número de procesos. Por el contrario, una tabla de páginas invertida tiene **una entrada por cada marco de la memoria principal**, lo que la hace mucho más compacta.

##### **Estructura de una tabla de páginas invertida**

Cada entrada de la tabla contiene información sobre:

1. **Dirección virtual**: La dirección virtual asociada al marco físico correspondiente.
2. **ID del proceso**: Identifica el proceso al que pertenece la dirección virtual, ya que las direcciones virtuales pueden repetirse en distintos procesos.
3. **Información de control**: Bits de estado como el de validez, permisos de acceso, y si la página está modificada o referenciada.


##### **¿Cómo funciona la traducción de direcciones?**
El objetivo de la tabla de páginas invertida es traducir una **dirección virtual** a una **dirección física**. Este proceso es diferente al de una tabla de páginas convencional, ya que requiere buscar en la tabla de páginas invertida. Aquí están los pasos detallados:

1. **Separar dirección virtual en campos:**
    - **Número de página virtual (VPN):** Indica la página lógica a la que pertenece la dirección virtual.
    - **Desplazamiento dentro de la página (offset):** Indica la posición exacta dentro de la página. Este valor no cambia en la traducción.
2. **Buscar en la tabla de páginas invertida:**
    - Como la tabla de páginas invertida se organiza por marcos de memoria física (no por páginas virtuales), se necesita buscar una entrada que coincida con:
        - El número de página virtual (VPN).
        - El ID del proceso que está realizando la solicitud.
    - La búsqueda puede implicar recorrer la tabla de manera lineal, lo que sería costoso. Sin embargo, en la práctica, se usa una **estructura hash** para acelerar la búsqueda.
3. **Obtener el marco físico correspondiente:**
    - Si se encuentra una entrada que coincide, el sistema obtiene el número del marco físico asociado a esa entrada.
    - Combina el número de marco físico con el desplazamiento (offset) original para formar la dirección física final.
4. **En caso de fallo:**
    - Si no se encuentra una entrada correspondiente, se genera un **page fault**. Esto significa que la página requerida no está en la memoria principal y debe cargarse desde la memoria secundaria (por ejemplo, disco).


##### **Ventajas y desventajas de la tabla de páginas invertida**
###### **Ventajas:**

1. **Uso eficiente de memoria:**
    - Solo se necesita una entrada por cada marco físico, no por cada página virtual. Esto reduce el tamaño de la tabla significativamente, especialmente en sistemas con grandes espacios de direcciones virtuales.
2. **Escalabilidad:**
    - El tamaño de la tabla depende de la cantidad de memoria física instalada, no del espacio de direcciones virtuales ni del número de procesos.
3. **Ideal para sistemas con muchos procesos:**
    
    - En sistemas donde hay muchos procesos pero poca memoria física, las tablas convencionales crecerían enormemente. La tabla invertida evita este problema.

###### **Desventajas:**

1. **Búsquedas más lentas:**
    
    - La búsqueda en la tabla es más compleja, ya que necesita comprobar el número de página virtual y el ID del proceso. Sin una estructura hash, este proceso puede ser muy lento.
2. **No permite múltiples mapeos de páginas virtuales a un mismo marco:**
    
    - En sistemas con memoria compartida entre procesos, puede ser difícil implementar ciertas funciones sin modificaciones adicionales.
3. **Costo adicional del hashing:**
    
    - Usar una estructura hash para mejorar el rendimiento añade complejidad en la implementación y puede provocar colisiones, lo que impacta el tiempo de búsqueda.

---

##### **Ejemplo de funcionamiento**

Supongamos que tenemos:

- **4 marcos físicos** en memoria principal.
- **Proceso A** con la página virtual **3** solicita acceso a la dirección virtual **0x3000** (desplazamiento 0 dentro de la página).

###### Paso 1: Solicitud de traducción

- El sistema descompone la dirección virtual:
    - VPN = 3
    - Offset = 0x000 (últimos bits de la dirección).

###### Paso 2: Consultar la tabla de páginas invertida

- Se busca en la tabla si alguna entrada tiene:
    - VPN = 3.
    - ID del proceso = A.

###### Paso 3: Resolver la traducción

- Si se encuentra una entrada, por ejemplo:
    - Marco físico = 2.
- El sistema combina el marco físico con el offset, generando la dirección física **0x2000**.

###### Paso 4: Resultado

- La dirección física **0x2000** es entregada al hardware para realizar la operación solicitada (lectura/escritura).


![[archivos/imagenes/Pasted image 20241204135523.png]]

![[archivos/imagenes/Pasted image 20241209122549.png]]

#### **Comparación entre ambos métodos:**

|**Aspecto**|**Tablas multinivel**|**Tablas invertidas**|
|---|---|---|
|**Espacio requerido**|Crece con el espacio de direcciones virtuales.|Proporcional al tamaño de la memoria física.|
|**Búsqueda**|Rápida, usando índices jerárquicos.|Más lenta, requiere buscar en la tabla invertida.|
|**Uso del TLB**|Acelera las traducciones de direcciones.|Fundamental para compensar búsquedas lentas.|
|**Aplicación típica**|Sistemas de 32 bits o direcciones no muy grandes.|Sistemas de 64 bits con grandes espacios virtuales.|

---

En resumen, las **tablas multinivel** son eficientes para direcciones de tamaño moderado al evitar mantener toda la tabla en memoria, mientras que las **tablas invertidas** son necesarias para direcciones de 64 bits debido al inmenso tamaño de las tablas tradicionales. Ambos métodos usan el **TLB** para acelerar el acceso a direcciones.


### Algoritmos de reemplazo de páginas
El **algoritmo de reemplazo de páginas óptimo (OPT)** es un modelo teórico que se utiliza como referencia para evaluar la eficacia de otros algoritmos de reemplazo de páginas. Aunque es imposible implementarlo en un sistema práctico, es útil para comparar su rendimiento con algoritmos realizables.

#### ¿Cómo funciona el algoritmo?

1. **Definición del objetivo:** El algoritmo busca minimizar los fallos de página en el futuro.
2. **Decisión basada en el futuro:**
    - Cada página en memoria se etiqueta con el número de instrucciones que se ejecutarán antes de que esa página sea referenciada de nuevo.
    - Cuando ocurre un fallo de página, el algoritmo selecciona para desalojar la página con la **etiqueta más alta**, es decir, aquella que no será utilizada hasta más adelante en el futuro.

#### Ejemplo:

Imagina que tienes 3 marcos de página y una secuencia de referencias de páginas:  
A, B, C, A, D, B, A, E, C.

1. **Estado inicial:** Los marcos están vacíos.
    
    - **A** se carga en el primer marco. (Fallo de página)
    - **B** se carga en el segundo marco. (Fallo de página)
    - **C** se carga en el tercer marco. (Fallo de página)
2. **Referencia a A:** A ya está en memoria. (Sin fallo)
    
3. **Referencia a D:** La memoria está llena, se debe reemplazar una página.
    
    - Las etiquetas son:
        - A: Se usará en la posición 6.
        - B: Se usará en la posición 6.
        - C: Se usará en la posición 8.
    - El algoritmo elige **C** porque será usada más adelante.  
        **D** reemplaza a **C**. (Fallo de página)
4. Y así sucesivamente, el algoritmo siempre decide basándose en cuándo se necesitará cada página.
    

#### ¿Por qué no es implementable?

El problema principal es que el sistema operativo **no puede prever el futuro**. Al momento de un fallo de página, no sabe cuál será la próxima referencia a cada página. Sin embargo, se puede simular usando un **rastreo previo** de las referencias, lo cual solo es posible en un entorno controlado, como durante una simulación para comparar algoritmos.

#### Usos del algoritmo óptimo

- **Evaluación de rendimiento:** Sirve como punto de referencia para medir qué tan cerca está un algoritmo práctico del óptimo.
- **Simulación:** Se puede usar en simuladores para determinar la secuencia ideal de reemplazos para un programa y entrada específica.


### Explicación del Algoritmo **NRU (Not Recently Used)**

El algoritmo **NRU** es un método práctico y eficiente para seleccionar qué página desalojar en caso de un fallo de página. Utiliza dos bits de estado asociados a cada página en la tabla de páginas:

- **R (Referenciada):** Indica si la página fue referenciada (lectura o escritura) recientemente.
- **M (Modificada):** Indica si la página fue modificada (escrita) mientras estaba en memoria.

#### ¿Cómo funciona el NRU?

1. **Clasificación de las páginas en 4 clases:**
    
    - Las páginas se clasifican según los valores de sus bits **R** y **M** en las siguientes categorías:
        - **Clase 0:** R = 0, M = 0 (No referenciada ni modificada).
        - **Clase 1:** R = 0, M = 1 (No referenciada, pero modificada).
        - **Clase 2:** R = 1, M = 0 (Referenciada, pero no modificada).
        - **Clase 3:** R = 1, M = 1 (Referenciada y modificada).
2. **Selección de la página a eliminar:**
    
    - Se elige una página al azar de la **clase de menor numeración que no esté vacía**.
    - Esto implica la siguiente prioridad para ser desalojadas:
        1. **Clase 0:** Estas páginas son las menos costosas de eliminar (no referenciadas ni modificadas).
        2. **Clase 1:** Moderadamente costosas, ya que requieren ser escritas al disco antes de eliminarlas.
        3. **Clase 2:** Son páginas de uso frecuente, pero no modificadas, por lo que tienen menor prioridad.
        4. **Clase 3:** Son las más costosas de eliminar porque son de uso frecuente y están modificadas.
3. **Actualización periódica del bit R:**
    
    - En cada **interrupción de reloj**, el sistema operativo **borra el bit R** de todas las páginas.
    - Esto permite distinguir entre las páginas que han sido referenciadas recientemente y las que no.
    - El bit **M** no se borra automáticamente porque se necesita para saber si una página modificada debe escribirse al disco.

#### Ejemplo:

Supongamos que tenemos las siguientes páginas en memoria con sus bits R y M:

|Página|R|M|Clase|
|---|---|---|---|
|A|0|0|0|
|B|0|1|1|
|C|1|0|2|
|D|1|1|3|

Si ocurre un fallo de página:

1. El algoritmo busca una página en la clase más baja:
    
    - Encuentra que la página **A** (Clase 0) es elegible para ser desalojada.
    - Si no hubiera páginas en Clase 0, seleccionaría al azar una página de Clase 1, y así sucesivamente.
2. **Desaloja la página A**, ya que es la menos costosa.
    

#### Ventajas del NRU:

- **Eficiencia razonable:** Aunque no es óptimo, proporciona un buen rendimiento.
- **Facilidad de implementación:** Utiliza información simple (bits R y M).
- **Priorización inteligente:** Intenta minimizar el coste al desalojar páginas menos importantes.

#### Limitaciones del NRU:

- **Decisión aleatoria dentro de una clase:** No utiliza ningún criterio adicional para elegir entre páginas de la misma clase.
- **No es óptimo:** No considera patrones de uso futuro, a diferencia del algoritmo teórico óptimo.


### Explicación del Algoritmo **FIFO (First-In, First-Out)**

El algoritmo **FIFO** es uno de los métodos más simples para la gestión de reemplazo de páginas en sistemas de memoria virtual. Su funcionamiento se basa en una estructura de lista que almacena las páginas en el orden en que ingresaron a la memoria.

#### Funcionamiento del Algoritmo FIFO

1. **Lista ordenada por tiempo de llegada:**
    
    - El sistema operativo mantiene una lista de todas las páginas en memoria.
    - Las páginas se agregan al **final de la lista** cuando se cargan en memoria.
    - La página que se encuentra en el **frente de la lista** es la que lleva más tiempo en memoria.
2. **Mecanismo de reemplazo:**
    
    - Cuando ocurre un **fallo de página** (la página requerida no está en memoria):
        1. **Elimina** la página del frente de la lista (la más antigua).
        2. **Agrega** la nueva página al final de la lista.

#### Ejemplo

Supongamos que tenemos 3 marcos de página disponibles y la siguiente secuencia de referencias a páginas: **A, B, C, D, A, B, E, D, C, A**.

- Al inicio, la memoria está vacía.
- Aplicamos FIFO para reemplazo de páginas:

|Referencia|Estado de la Memoria|Página Eliminada|Fallo de Página|
|---|---|---|---|
|A|A|-|Sí|
|B|A, B|-|Sí|
|C|A, B, C|-|Sí|
|D|B, C, D|A|Sí|
|A|C, D, A|B|Sí|
|B|D, A, B|C|Sí|
|E|A, B, E|D|Sí|
|D|B, E, D|A|Sí|
|C|E, D, C|B|Sí|
|A|D, C, A|E|Sí|

**Total de fallos de página:** 10.

#### Problemas de FIFO

1. **Reemplazo no inteligente:**
    
    - FIFO elimina la página que lleva más tiempo en memoria, sin importar si ha sido referenciada recientemente o si es probable que se necesite pronto.
    - Esto puede llevar a la eliminación de páginas importantes, afectando el rendimiento.
2. **Anomalía de Belady:**
    
    - En algunos casos, agregar más marcos de página puede **incrementar** el número de fallos de página, algo contraintuitivo.
    - Este fenómeno se llama **anomalía de Belady** y ocurre porque FIFO no toma en cuenta patrones de acceso.

#### Ventajas de FIFO

- **Simplicidad:** Es fácil de implementar y mantener.
- **Baja sobrecarga:** No requiere estadísticas ni bits adicionales.

#### Limitaciones de FIFO

- **Rendimiento subóptimo:** No considera patrones de acceso ni el estado reciente de las páginas.
- **Poco adaptable:** No distingue entre páginas frecuentemente usadas y poco usadas.


### **Algoritmo de Segunda Oportunidad**

El **algoritmo de segunda oportunidad** es una mejora sobre **FIFO** que evita reemplazar páginas frecuentemente utilizadas. Lo hace al evaluar el bit de referencia (**R**) de la página más antigua antes de decidir si debe ser desalojada.

#### **Funcionamiento**

1. **Lista de páginas:**  
    Se mantiene una lista de las páginas en memoria, ordenadas según su tiempo de llegada, como en FIFO.
    
2. **Inspección del bit R:**
    
    - Cuando ocurre un fallo de página, se examina la página más antigua.
    - Si el bit **R** es **0**, significa que la página no ha sido referenciada recientemente, por lo que es desalojada.
    - Si el bit **R** es **1**, indica que la página ha sido referenciada. En este caso:
        - El bit **R** se desactiva (se pone en 0).
        - La página se mueve al **final de la lista**, simulando que acaba de llegar a la memoria.
        - Se continúa inspeccionando la siguiente página.
3. **Iteración continua:**
    
    - El proceso se repite hasta encontrar una página con **R = 0**, que será la página desalojada.

#### **Ejemplo**

Supongamos que tenemos las páginas **A, B, C, D** en memoria, en ese orden de llegada, y ocurre un fallo de página al intentar cargar **E**. Los valores de **R** son los siguientes:

|Página|R (Bit de referencia)|
|---|---|
|A|1|
|B|0|
|C|1|
|D|0|

- Se inspecciona **A**:
    
    - **R = 1**, así que se pone **R = 0** y se mueve al final de la lista.
- Se inspecciona **B**:
    
    - **R = 0**, por lo que **B** se desaloja y **E** ocupa su lugar.

Nuevo estado de memoria: **C, D, A, E**.

![[archivos/imagenes/Pasted image 20241205110145.png]]


### **Algoritmo del Reloj**

El **algoritmo del reloj** es una optimización del algoritmo de segunda oportunidad que organiza las páginas en una **estructura circular** similar a un reloj.

#### **Funcionamiento**

1. **Estructura circular:**
    
    - Las páginas se almacenan en una lista circular.
    - Una "manecilla" apunta a la página más antigua.
2. **Inspección del bit R:**
    
    - Cuando ocurre un fallo de página, se inspecciona la página señalada por la manecilla:
        - Si **R = 0**, se reemplaza con la nueva página y la manecilla avanza a la siguiente posición.
        - Si **R = 1**, el bit **R** se pone en **0** y la manecilla avanza a la siguiente página.
3. **Iteración:**
    
    - Este proceso se repite hasta encontrar una página con **R = 0**.

#### **Ejemplo**

Supongamos que tenemos un reloj con las páginas **A, B, C, D** y los bits **R** como sigue:

|Página|R (Bit de referencia)|
|---|---|
|A|1|
|B|1|
|C|0|
|D|1|

La manecilla apunta inicialmente a **A**:

- Inspecciona **A**:
    
    - **R = 1**, se pone **R = 0** y la manecilla avanza.
- Inspecciona **B**:
    
    - **R = 1**, se pone **R = 0** y la manecilla avanza.
- Inspecciona **C**:
    
    - **R = 0**, se reemplaza con la nueva página.

Nuevo estado del reloj: **E, B, D, A** (la manecilla ahora apunta a **B**).

---
![[archivos/imagenes/Pasted image 20241205110528.png]]


### LRU
El algoritmo **LRU (Least Recently Used)** es una técnica de reemplazo de páginas que intenta aproximar el comportamiento del algoritmo óptimo, basándose en la idea de que las páginas que se han usado recientemente probablemente se volverán a usar pronto. Aquí tienes un resumen de los puntos clave y las implementaciones descritas:

#### **Definición del algoritmo LRU**

- **Principio**: Descarta la página que no se haya utilizado durante el período más largo de tiempo.
- **Fundamento**: Las páginas que no se han usado en mucho tiempo probablemente seguirán sin usarse por un tiempo más.


#### **Implementaciones del algoritmo**

##### **1. Lista enlazada**

- **Descripción**: Mantener una lista enlazada de páginas en memoria.
    - **Más reciente**: La página más usada recientemente se coloca al frente.
    - **Menos reciente**: La página menos usada se coloca al final.
- **Desventaja**: Cada acceso a memoria requiere buscar la página, moverla al frente y actualizar la lista, lo cual es costoso.


##### **2. Contador con hardware especial**

- **Descripción**:
    1. Se utiliza un contador global (C) que se incrementa automáticamente con cada instrucción.
    2. Cada entrada de la tabla de páginas tiene un campo para almacenar el valor actual de C cuando la página es referenciada.
    3. En caso de fallo de página, el sistema operativo inspecciona los contadores y descarta la página con el menor valor.
- **Ventaja**: Implementación más directa.
- **Desventaja**: Requiere hardware adicional (un contador y espacio extra en la tabla de páginas).

---

##### **3. Matriz de bits**

- **Descripción**:
    - Para un sistema con nn marcos de página, se utiliza una matriz de n×nn \times n bits.
    - **Reglas**:
        1. Al referenciar la página kk, se ponen en 1 todos los bits de la fila kk y en 0 todos los de la columna kk.
        2. La fila cuyo valor binario sea el menor representa la página menos usada recientemente.
- **Ejemplo**:
    - Con 4 páginas y referencias: 0, 1, 2, 3, 2, 1, 0, 3, 2, 3, se genera una matriz que evoluciona con cada referencia.
    - La fila con el valor más bajo binario indica cuál página descartar.
- **Ventaja**: Permite ordenar fácilmente las páginas por antigüedad de uso.
- **Desventaja**: Requiere hardware especial y memoria adicional para la matriz.

---

#### **Ventajas y desventajas del LRU**

- **Ventajas**:
    - Proporciona un buen rendimiento en términos de tasas de fallos de página.
    - Se aproxima bien al algoritmo óptimo.
- **Desventajas**:
    - Requiere un soporte de hardware considerable para implementaciones eficientes.
    - Las aproximaciones puramente por software son lentas debido a los costos de mantenimiento de estructuras como listas.

![[archivos/imagenes/Pasted image 20241205110818.png]]




### Algoritmo de envejecimiento:

1. **Inicialización**:
    
    - Cada página tiene un contador asociado, inicializado en 0.
    - El hardware mantiene un bit de referencia (**R**) por página, que se establece en 1 si la página es accedida.
2. **Ciclo en cada pulso de reloj**:
    
    - **Desplazamiento del contador**: Los contadores de todas las páginas se desplazan 1 bit a la derecha.
    - **Actualización con el bit R**: El valor de **R** se inserta en el bit más significativo (izquierda) del contador.
    - **Reinicio de R**: El bit **R** se pone en 0 para comenzar el siguiente ciclo.
3. **Selección de página para reemplazo**:
    
    - Cuando ocurre un fallo de página, se selecciona la página con el **contador menor** para ser reemplazada.
    - En caso de empate, se elige cualquiera de las páginas empatadas.

![[archivos/imagenes/Pasted image 20241205111806.png]]

#### Ventajas:

- **Aproximación al LRU**: Las páginas con contadores mayores son aquellas más usadas recientemente, simulando el comportamiento de LRU.
- **Eficiencia**: Sólo requiere actualizar contadores en cada interrupción de reloj, lo que es computacionalmente manejable.
- **Control del horizonte temporal**: Los contadores tienen un límite de bits (por ejemplo, 8), lo que permite ignorar referencias demasiado antiguas.

#### Limitaciones:

1. **Granularidad temporal**:
    
    - No distingue entre dos accesos que ocurren dentro del mismo intervalo de reloj.
    - Puede cometer errores en la selección si dos páginas tienen contadores idénticos.
2. **Horizonte limitado**:
    
    - Si dos páginas tienen contadores en 0, no es posible distinguir si fueron referenciadas recientemente o hace mucho tiempo.
3. **Resolución**:
    
    - La precisión depende de la frecuencia del reloj y el tamaño del contador. Por ejemplo, con un pulso cada 20 ms y un contador de 8 bits, el algoritmo recuerda referencias hasta 160 ms atrás.

En términos prácticos, el algoritmo de envejecimiento es útil porque mantiene un balance entre precisión y eficiencia, aunque no sea tan exacto como LRU puro.


### WS
El algoritmo del conjunto de trabajo es un enfoque eficiente para manejar el reemplazo de páginas en sistemas de memoria virtual. A continuación, se resumen los conceptos clave y el funcionamiento de este algoritmo:

#### **Conceptos principales**

1. **Conjunto de trabajo**:
    
    - Es el conjunto de páginas que un proceso necesita en un momento dado para ejecutarse con pocos fallos de página.
    - Se define como las páginas referenciadas en las últimas kk referencias a memoria o dentro de un periodo de tiempo τ\tau.
2. **Localidad de referencia**:
    
    - Los procesos suelen acceder a un subconjunto pequeño de páginas repetidamente durante un periodo específico, cambiando lentamente con el tiempo.
3. **Paginación bajo demanda**:
    
    - Las páginas solo se cargan cuando se necesitan, lo que minimiza la carga inicial, pero puede causar fallos de página frecuentes al principio.
4. **Prepaginación**:
    
    - El sistema intenta anticiparse a las páginas que un proceso necesitará al reanudar su ejecución, cargando previamente las páginas del conjunto de trabajo.
5. **Thrashing (sobrepaginación)**:
    
    - Ocurre cuando un proceso genera demasiados fallos de página debido a que su conjunto de trabajo no cabe en la memoria disponible.

![[archivos/imagenes/Pasted image 20241205112322.png]]

#### **Funcionamiento del algoritmo del conjunto de trabajo**

1. **Estructura requerida**:
    
    - Una tabla de páginas con:
        - Tiempo de último uso de cada página.
        - Bit RR (referenciada), que indica si la página fue usada durante el pulso de reloj actual.
2. **Proceso del algoritmo**:
    
    - Se ejecuta en cada fallo de página:
        1. Se exploran las páginas en memoria.
        2. Si R=1R = 1:
            - Actualizar el tiempo de último uso con el tiempo virtual actual.
        3. Si R=0R = 0:
            - Calcular la edad de la página: edad=tiempo actual−tiempo de uˊltimo uso\text{edad} = \text{tiempo actual} - \text{tiempo de último uso}.
            - Si edad>τ\text{edad} > \tau, la página ya no está en el conjunto de trabajo y puede ser reemplazada.
            - Si edad≤τ\text{edad} \leq \tau, reservar la página como potencial candidata, priorizando la más antigua (menor tiempo de último uso).
3. **Desalojo de páginas**:
    
    - Si se encuentra una página fuera del conjunto de trabajo, se reemplaza.
    - Si todas las páginas están en el conjunto de trabajo:
        - Seleccionar la más antigua con R=0R = 0.
        - Si todas tienen R=1R = 1, elegir una al azar, preferiblemente una página limpia (no modificada).
4. **Interrupciones periódicas**:
    
    - Se ejecuta un proceso para borrar el bit RR de todas las páginas en cada pulso de reloj, lo que permite determinar si han sido referenciadas recientemente.

![[archivos/imagenes/Pasted image 20241205112341.png]]

#### **Ventajas y desafíos**

**Ventajas**:

- Reduce significativamente los fallos de página al mantener el conjunto de trabajo en memoria.
- Se adapta dinámicamente a los cambios en el comportamiento de los procesos.

**Desafíos**:

- El cálculo exacto del conjunto de trabajo puede ser costoso en términos de tiempo y recursos.
- Requiere mecanismos de hardware y software para mantener información precisa sobre las páginas (como el bit RR y el tiempo de último uso).

En conclusión, el modelo del conjunto de trabajo equilibra el uso eficiente de la memoria y el rendimiento de los procesos, convirtiéndolo en un enfoque esencial para sistemas multiprogramados.

### WS Clock
El algoritmo **WSClock** es una mejora al algoritmo del conjunto de trabajo, utilizando la estructura de un reloj circular para decidir qué página reemplazar. Este método es más eficiente que el conjunto de trabajo básico al evitar recorrer toda la tabla de páginas en cada fallo de página. A continuación, se resumen los pasos principales del algoritmo WSClock:

#### **Estructura del WSClock**

- **Lista circular de marcos de página**:
    - Cada entrada contiene:
        - **Bit R (referenciado)**: Indica si la página ha sido accedida recientemente.
        - **Tiempo de último uso**: Utilizado para calcular la "edad" de la página.
        - **Bit M (modificado)**: Indica si la página ha sido modificada (no siempre se muestra explícitamente en el algoritmo básico).

#### **Proceso del algoritmo WSClock**

1. **Revisión inicial**:
    
    - La manecilla apunta a una página.
    - Si el bit **R = 1**, la página se considera activa (parte del conjunto de trabajo):
        - Se pone **R = 0** y la manecilla avanza al siguiente marco.
        - Repite este proceso con las siguientes páginas.
2. **Página con R = 0**:
    
    - Se analiza si la página está **fuera del conjunto de trabajo**:
        - Si la **edad** (tiempo desde el último uso) es mayor que un umbral **τ**:
            - **Página limpia**: Se reemplaza directamente (ya tiene copia válida en disco).
            - **Página sucia**: Se programa para escritura en disco, pero la búsqueda continúa con la siguiente página.
3. **Escrituras planificadas**:
    
    - Si una página sucia se programa para escritura, el algoritmo sigue avanzando hasta encontrar una página limpia para reemplazo inmediato.
    - Para limitar la cantidad de escrituras, se puede establecer un **máximo de n escrituras** por ciclo.
4. **Ciclo completo del reloj**:
    
    - **Caso 1**: Se han planificado escrituras.
        - Se espera a que termine al menos una escritura.
        - La primera página limpia encontrada se usa como reemplazo.
    - **Caso 2**: No se han planificado escrituras.
        - Si todas las páginas están en el conjunto de trabajo:
            - Se reemplaza una página limpia (si existe).
            - Si no hay páginas limpias, se selecciona la página actual como víctima y se escribe en disco.


![[archivos/imagenes/Pasted image 20241205112701.png]]

#### **Ventajas del WSClock**

- **Eficiencia**: Reduce el recorrido completo de la tabla de páginas al utilizar una estructura circular.
- **Flexibilidad**: Integra decisiones basadas en el estado del bit R, la edad de la página y el estado (limpia o sucia).
- **Reducción del tráfico de disco**: Minimiza escrituras innecesarias al planificar solo páginas sucias.

#### **Desventajas**

- **Sobrecarga de planificación**: Puede ser más complejo implementar la gestión de escrituras en sistemas de tiempo real.
- **Dependencia de parámetros**: El rendimiento depende del ajuste correcto del umbral **τ** y el límite de escrituras.

En general, WSClock es un algoritmo ampliamente utilizado debido a su buen rendimiento y simplicidad relativa en comparación con otros algoritmos de reemplazo más complejos.


### RESUMEN
![[archivos/imagenes/Pasted image 20241205112726.png]]


# Cuestiones de Diseño para los Sistemas de Paginación


### Políticas de asignación local contra las de asignación global
1. **Asignación local vs. global**:
    
    - **Local**: Cuando un proceso tiene un fallo de página, el sistema busca reemplazar **una página dentro del conjunto asignado a ese proceso**. Es decir, no afecta las páginas de otros procesos.
    - **Global**: Cuando ocurre un fallo, el sistema puede reemplazar **cualquier página en memoria**, sin importar de qué proceso sea.
2. **Ejemplo básico**: Supongamos que tenemos tres procesos (A, B y C), cada uno con un conjunto de páginas en memoria:
    
    - A tiene 6 páginas (A0 a A5).
    - B tiene 7 páginas (B0 a B6).
    - C tiene 3 páginas (C0 a C2).
    
    Si el proceso A tiene un fallo de página:
    
    - Con una **política local**, el sistema sólo puede reemplazar páginas dentro del conjunto de A (por ejemplo, A5).
    - Con una **política global**, el sistema busca la página menos usada entre **todas las páginas en memoria** (puede ser, por ejemplo, B3).
3. **Ventajas y desventajas**:
    
    - **Local**:
        - Cada proceso tiene garantizada una cantidad fija de memoria.
        - Si el tamaño del conjunto de trabajo (las páginas activas que un proceso necesita en un momento dado) crece más allá de lo asignado, puede ocurrir **sobrepaginación**.
    - **Global**:
        - Es más flexible porque redistribuye dinámicamente los marcos de memoria.
        - Requiere algoritmos que monitoricen el uso de páginas, como el algoritmo **PFF** (Page Fault Frequency), para mantener un equilibrio adecuado entre procesos.

![[archivos/imagenes/Pasted image 20241208165003.png]]

#### **Ejemplo práctico para clarificar**

Imagina que tienes un ordenador con 16 GB de RAM, y estás ejecutando tres programas:

- **Programa A**: Editor de texto (necesita pocas páginas activas).
- **Programa B**: Navegador con 20 pestañas abiertas (necesita muchas páginas activas).
- **Programa C**: Reproductor de música (necesita muy pocas páginas).

##### **Con asignación local**:

- Divides la memoria en bloques fijos: 6 GB para A, 6 GB para B, y 4 GB para C.
- Si el navegador abre más pestañas (conjunto de trabajo mayor), podría quedarse sin memoria incluso si el editor y el reproductor no están usando toda su parte.

#### **Con asignación global**:

- El navegador puede tomar memoria "prestada" de los otros procesos cuando la necesita.
- Esto asegura que los recursos del sistema se utilicen eficientemente.



#### **Algoritmo PFF (Frecuencia de fallos de página)**

El algoritmo **PFF** mide la cantidad de fallos de página que ocurren por segundo:

- Si hay **demasiados fallos**, significa que el proceso necesita más memoria, así que se le asignan más marcos de página.
- Si hay **pocos fallos**, puede estar usando demasiada memoria, así que se le quitan marcos y se redistribuyen.

![[archivos/imagenes/Pasted image 20241208165259.png]]

##### Ejemplo con el gráfico de la figura 3-24:

- **Zona A (fallos altos)**: Imagina que el navegador tiene 2 GB asignados pero necesita 4 GB. Cada pocos segundos hay fallos porque no tiene suficientes páginas activas.
- **Zona B (fallos bajos)**: El editor tiene 6 GB asignados, pero sólo usa 1 GB. Los fallos son tan raros que podría ceder parte de su memoria.

#### **Conclusión sobre la elección local vs. global**

- **¿Cuándo usar local?**
    - En sistemas con alta prioridad en la estabilidad de procesos individuales. Ejemplo: Sistemas de tiempo real.
- **¿Cuándo usar global?**
    - En sistemas generales donde el rendimiento global importa más que la prioridad de un proceso individual.

### **Control de carga**

Incluso con algoritmos de reemplazo y asignación global de marcos óptimos, puede surgir **sobrecarga de paginación** cuando los conjuntos de trabajo combinados de todos los procesos superan la capacidad de la memoria. Esto provoca un ciclo continuo de fallos de página, ralentizando el sistema de manera significativa.

#### **Detección de sobrepaginación**

Un síntoma típico de sobrepaginación es que el algoritmo **PFF** (Frecuencia de Fallo de Páginas) señala que varios procesos necesitan más marcos de página, pero ningún proceso puede liberar memoria sin afectar a otro. En este caso, es imposible mejorar el rendimiento simplemente redistribuyendo marcos.

#### **Solución: Reducción de carga**

La única solución viable es **reducir la cantidad de procesos activos en memoria**. Esto se logra mediante **intercambio (swapping)**, que implica enviar algunos procesos al disco, liberando así sus marcos de página para otros procesos que lo necesiten:

1. **Proceso de intercambio:**
    
    - Un proceso es intercambiado al disco.
    - Sus marcos son redistribuidos a procesos que están sobrepaginando.
    - Si el sobrepaginado persiste, se repite el proceso con más procesos.
2. **Ventaja del intercambio:**
    
    - Permite que el sistema vuelva a un estado operativo estable.
    - Reduce la demanda global de memoria, evitando ciclos de fallos constantes.
3. **Desventaja del intercambio:**
    
    - Introduce latencia debido al tiempo necesario para escribir y leer procesos desde el disco.

#### **Planificación de procesos intercambiados**

Este enfoque se asemeja a la **planificación en dos niveles**:

- **Nivel 1:** Algunos procesos son colocados en disco.
- **Nivel 2:** Se planifican los procesos restantes en la memoria principal.

El intercambio se realiza de manera periódica, alternando entre traer procesos desde el disco y enviar otros al mismo, buscando optimizar el uso de la memoria y evitar fallos excesivos.

#### **Impacto en el grado de multiprogramación**

El grado de multiprogramación también influye en el rendimiento:

- Si hay **muy pocos procesos en memoria**, la CPU podría quedar inactiva, afectando la eficiencia.
- Por ello, es crucial considerar características adicionales al decidir qué procesos intercambiar, tales como:
    - Si el proceso es intensivo en **CPU** o en **E/S**.
    - El impacto en el rendimiento de los procesos restantes.

De esta forma, se logra un equilibrio entre la cantidad de procesos en memoria y la eficiencia del sistema.

### **Tamaño de página**

El tamaño de página es un parámetro clave en los sistemas de paginación, y su elección depende de equilibrar diversos factores. Aunque el hardware puede definir un tamaño mínimo, los sistemas operativos suelen tener cierta flexibilidad para agrupar páginas y configurar tamaños efectivos más grandes.

#### **Factores a favor de páginas pequeñas**

1. **Reducción de fragmentación interna:**
    - La última página de un segmento suele estar parcialmente vacía.
    - Con páginas más pequeñas, el desperdicio promedio por fragmentación interna ($np/2$) es menor, ya que $p$ disminuye.
2. **Menor uso de memoria activa:**
    
    - En programas con fases secuenciales (e.g., de 4 KB), un tamaño pequeño permite cargar sólo las páginas necesarias, minimizando la memoria ocupada.

#### **Factores a favor de páginas grandes**

1. **Menor tamaño de la tabla de páginas:**
    
    - Un programa grande requiere menos páginas si estas son grandes, lo que reduce el número de entradas en la tabla de páginas.
    - Ejemplo: Un programa de 32 KB necesita **4 páginas de 8 KB**, pero **64 páginas de 512 bytes**.
2. **Mayor eficiencia en transferencias de disco:**
    
    - Las transferencias incluyen tiempo fijo debido a búsquedas y rotación del disco.
    - Transferir una página grande toma casi el mismo tiempo que una pequeña, pero reduce la cantidad de operaciones de E/S.
3. **Menor sobrecarga en hardware:**
    
    - En máquinas donde la tabla de páginas se carga en registros al cambiar de proceso, un tamaño pequeño aumenta el tiempo de carga y el espacio ocupado por las tablas.

#### **Balance: Fragmentación interna vs. tabla de páginas**

La elección óptima del tamaño de página implica minimizar:

- **Fragmentación interna:** Proporcional a $p/2$.
- **Sobrecarga de la tabla de páginas:** Proporcional a $se/p$.

La **sobrecarga total** es:

Sobrecarga $\text{Sobrecarga total} = \frac{se}{p} + \frac{p}{2}$

Al minimizar esta expresión con derivadas, se obtiene:

$p = \sqrt{2se}$

#### **Ejemplo práctico**

Para un proceso promedio de $s = 1\ \text{MB}$ y entradas de tabla de páginas de $e = 8\ \text{bytes}$, el tamaño óptimo de página es:

$p = \sqrt{2 \cdot 1\ \text{MB} \cdot 8\ \text{bytes}} = 4\ \text{KB}$

#### **Conclusión**

Aunque valores comunes oscilaban entre 1 KB y 8 KB, hoy en día tamaños de **4 KB y 8 KB** son los más utilizados, especialmente con el crecimiento de la memoria RAM. Sin embargo, este aumento no implica necesariamente un crecimiento lineal en el tamaño de página.

### **Espacios separados de instrucciones y datos**

En la mayoría de las computadoras modernas, el espacio de direcciones virtuales combina tanto las instrucciones del programa como los datos, como se muestra en la figura 3-25(a). Aunque esta configuración es práctica y suficiente cuando el espacio de direcciones es amplio, puede convertirse en un problema en sistemas con espacios más limitados, obligando a los desarrolladores a optimizar manualmente la distribución de código y datos.

![[archivos/imagenes/Pasted image 20241208171849.png]]

#### **Espacios separados: I y D**
Una solución a este problema es la separación del espacio de direcciones en dos:

1. **Espacio I (Instrucciones):**
    - Contiene el texto del programa (código ejecutable).
2. **Espacio D (Datos):**
    - Contiene los datos y estructuras de memoria asociadas al programa.

Esto se muestra en la figura 3-25(b), donde cada espacio comienza desde la dirección virtual 0 y puede alcanzar un valor máximo (e.g., $2^{16} - 1$ o $2^{32} - 1$, dependiendo del sistema).

#### **Ventajas del modelo I/D separado**

1. **Ampliación del espacio de direcciones:**
    
    - Al separar las instrucciones y los datos, se duplica efectivamente el espacio de direcciones disponible para el programa.
    - Esto permite manejar programas más grandes sin restricciones severas de memoria.
2. **Independencia en la paginación:**
    
    - Cada espacio tiene su propia tabla de páginas y se pagina de forma independiente.
    - Las instrucciones y los datos pueden asignarse a marcos de memoria física diferentes, optimizando el uso de la memoria.
3. **Facilidad para el hardware:**
    
    - Cuando el hardware accede a una instrucción, consulta directamente la tabla del espacio I.
    - De manera similar, las referencias a datos pasan a través de la tabla del espacio D.
    - Este diseño no introduce complicaciones adicionales para el hardware.

#### **Requisitos del sistema**

- **Soporte en el enlazador:**
    - El enlazador debe ser consciente de esta separación para asignar correctamente las direcciones virtuales. Por ejemplo:
        - Los datos se reubican desde la dirección virtual 0 en el espacio D.
        - Esto evita que las direcciones de datos colisionen con las de instrucciones.

#### **Ejemplo: PDP-11**

El modelo I/D separado se utilizó por primera vez en la PDP-11, un sistema de 16 bits con un espacio de direcciones limitado. En este contexto, la separación fue una solución eficaz para permitir que programas más grandes pudieran ejecutarse, distribuyendo instrucciones y datos en espacios independientes.

#### **Conclusión**

La separación de espacios I y D es una estrategia que mejora significativamente el uso de la memoria virtual, permitiendo manejar programas más grandes sin requerir cambios drásticos en el diseño del hardware o software. Esta idea, aunque menos común en sistemas modernos con espacios de direcciones amplios, sigue siendo relevante en sistemas embebidos o con recursos limitados.

### **Páginas compartidas**

En un sistema de multiprogramación, es habitual que múltiples usuarios ejecuten el mismo programa de manera simultánea. Para optimizar el uso de memoria, se busca compartir las páginas comunes entre procesos, reduciendo la duplicación innecesaria en memoria física.

#### **Condiciones para compartir páginas**

1. **Páginas de solo lectura:**
    - Solo las páginas que no se modifican (e.g., el código del programa o bibliotecas estáticas) pueden compartirse entre procesos.
2. **Páginas de datos:**
    - Estas generalmente no pueden compartirse porque cada proceso tiene su propio estado único en las variables y estructuras de datos.


#### **Espacios separados I y D**
Cuando se implementan espacios I y D separados, es más sencillo compartir el texto del programa:

- Los procesos comparten la misma tabla de páginas para el **espacio I** (código).
- Cada proceso mantiene su propia tabla de páginas para el **espacio D** (datos).

En este caso, las tablas de páginas son independientes de la tabla de procesos. Cada proceso tiene:

- Un apuntador a la tabla de páginas del espacio I.
- Un apuntador a la tabla de páginas del espacio D.

Cuando el planificador selecciona un proceso, configura la **Unidad de Gestión de Memoria (MMU)** con los apuntadores apropiados para acceder a las tablas correspondientes.

![[archivos/imagenes/Pasted image 20241208172631.png]]

#### **Compartición sin espacios I y D separados**

Aunque es posible compartir programas sin separar espacios I y D, el mecanismo es más complejo. Por ejemplo:

- Las bibliotecas compartidas pueden configurarse para que múltiples procesos usen el mismo conjunto de páginas en memoria.


#### **Problemas con las páginas compartidas**

1. **Eliminación de procesos:**
    - Si el planificador elimina un proceso (A), puede liberar sus páginas, aunque otro proceso (B) todavía las necesite, causando múltiples fallos de página para volver a cargarlas.
2. **Liberación de páginas en uso:**
    - Cuando un proceso termina, es esencial verificar que las páginas compartidas aún están en uso antes de liberarlas.
    - Buscar manualmente en todas las tablas de páginas es costoso, por lo que se usan estructuras de datos especializadas para rastrear el estado de las páginas compartidas.


#### **Compartición de datos: el caso de `fork`**
En sistemas como UNIX, cuando un proceso crea un hijo con la llamada al sistema `fork`:

1. Ambos procesos comparten:
    - El texto del programa (código).
    - Los datos del proceso.
2. Inicialmente, todas las páginas compartidas están marcadas como **solo lectura**.
3. Si alguno de los procesos intenta modificar una página:
    - Se genera una violación de protección, que lanza un **trap** al sistema operativo.
    - El sistema operativo realiza una **copia de la página afectada**.
    - Las nuevas copias se marcan como **lectura-escritura** para evitar más traps en el futuro.

#### **Ventajas de copiar en escritura (copy-on-write)**

1. **Optimización del rendimiento:**
    - Evita copiar páginas innecesarias que nunca serán modificadas.
2. **Eficiencia en memoria:**
    - Las páginas se comparten hasta que es imprescindible separarlas.
3. **Reducción de overhead:**
    - Solo las páginas modificadas se duplican, minimizando el costo de memoria y CPU.


#### **Conclusión**
El uso de páginas compartidas mejora significativamente la eficiencia en sistemas multiprogramados, especialmente cuando se combinan estrategias como los espacios I y D separados y el mecanismo de copiar en escritura. Estas técnicas permiten compartir recursos mientras garantizan la consistencia y aislamiento de procesos en memoria.

### Bibliotecas compartidas
Las **bibliotecas compartidas** (como las DLLs en Windows) permiten que múltiples programas compartan código y datos comunes sin duplicarlos, ahorrando memoria y espacio en disco. Aquí se destacan los conceptos principales:

![[archivos/imagenes/Pasted image 20241208172935.png]]

#### **Beneficios de las bibliotecas compartidas**
1. **Reducción del tamaño de los ejecutables**: Las funciones no se copian en cada programa, sino que se cargan desde una biblioteca central.
2. **Ahorro de memoria**: Las bibliotecas cargadas son compartidas entre procesos. Esto evita múltiples copias de las mismas funciones.
3. **Actualización centralizada**: Si se corrige un error en la biblioteca, los programas que la usan pueden beneficiarse sin necesidad de recompilarlos.
4. **Paginación eficiente**: Solo las páginas necesarias de la biblioteca se cargan en memoria.

#### **Problemas al compartir bibliotecas**
1. **Direcciones relativas vs. absolutas**:
    - Al cargar una biblioteca compartida en diferentes procesos, las direcciones virtuales pueden ser distintas.
    - Por ejemplo, en un proceso puede cargarse en la dirección **36K** y en otro en **12K**, causando conflictos si las instrucciones contienen direcciones absolutas.


#### **Soluciones**
1. **Código independiente de la posición (PIC)**:
    
    - Compilar la biblioteca con instrucciones que utilicen **desplazamientos relativos** en lugar de direcciones absolutas.
    - Esto permite que la biblioteca funcione correctamente sin importar dónde esté ubicada en el espacio de direcciones virtuales.
2. **Copia en escritura**:
    
    - Se crean copias privadas de las páginas de la biblioteca solo si un proceso necesita modificarlas.


Este enfoque asegura eficiencia y flexibilidad en sistemas modernos, especialmente cuando múltiples procesos utilizan bibliotecas extensas, como las gráficas o de interfaz de usuario.


### Archivos asociados a memoria

Los **archivos asociados a memoria** son una herramienta que permite asociar un archivo del sistema de archivos a una porción del espacio de direcciones virtuales de un proceso. Esto posibilita el acceso al contenido del archivo como si fuera una región de memoria, simplificando la manipulación de datos.

#### **Características principales**
1. **Asociación a memoria**:
    - Un archivo puede asociarse a una región del espacio de direcciones virtuales de un proceso mediante una llamada al sistema.
    - Las páginas no se cargan al asociar el archivo, sino que se traen bajo demanda, una página a la vez.
2. **Escritura diferida**:
    - Las páginas modificadas se escriben en el archivo asociado cuando el proceso termina o desasocia el archivo explícitamente.
3. **Acceso simplificado**:
    - El archivo puede manejarse como un gran arreglo de memoria, eliminando la necesidad de operaciones tradicionales de entrada/salida (lectura y escritura).

#### **Comunicación entre procesos**
- Si dos o más procesos asocian el mismo archivo a memoria, pueden comunicarse mediante **memoria compartida**:
    - Cambios realizados por un proceso son visibles inmediatamente para los demás.
    - Esto convierte al archivo asociado en un **canal de comunicación eficiente** con gran ancho de banda.

#### **Aplicaciones**
1. **Bibliotecas compartidas**:
    - Las bibliotecas compartidas pueden implementarse como archivos asociados a memoria, aprovechando este mecanismo para compartir código entre procesos.
2. **Archivos temporales**:
    - Es común asociar archivos temporales para compartir datos entre procesos sin necesidad de almacenamiento persistente.
3. **E/S eficiente**:
    - Los archivos asociados a memoria simplifican el manejo de grandes volúmenes de datos, como bases de datos o grandes estructuras de texto, permitiendo manipulación directa en memoria.

Este modelo no solo ofrece un enfoque eficiente para la gestión de archivos, sino que también facilita la **comunicación interprocesos** y reduce la sobrecarga de E/S en aplicaciones modernas.

### Política de limpieza en la paginación

La **política de limpieza** es una estrategia utilizada en sistemas de paginación para mantener un número adecuado de **marcos de página libres**, optimizando el rendimiento al manejar fallos de página.

---

#### **Importancia de la limpieza**

- Los fallos de página requieren marcos de página libres para cargar las nuevas páginas.
- Si todos los marcos están ocupados y **modificados**, una página debe escribirse en disco antes de ser reemplazada, lo que aumenta la latencia.


#### **Demonio de paginación**
- **Definición**: Proceso en segundo plano que administra los marcos de página.
- **Función**:
    1. Se despierta periódicamente para inspeccionar el estado de la memoria.
    2. Identifica páginas que pueden ser desalojadas usando un **algoritmo de reemplazo de páginas**.
    3. Escribe en el disco las páginas modificadas y las marca como limpias.
    4. Garantiza que los marcos libres estén listos para ser usados inmediatamente.

---

#### **Beneficios**
- **Reducción de la latencia**: Los marcos libres ya están limpios y listos para uso inmediato.
- **Rendimiento mejorado**: Minimiza la necesidad de escribir en disco durante los fallos de página, agilizando la respuesta del sistema.

---

#### **Implementación: Reloj con dos manecillas**
- **Manecilla principal**:
    - Controlada por el demonio de paginación.
    - Escribe las páginas sucias en disco y las avanza.
    - Si encuentra una página limpia, simplemente la avanza sin realizar cambios.
- **Manecilla secundaria**:
    - Se usa para seleccionar páginas que serán reemplazadas, como en el algoritmo de reloj estándar.
    - La probabilidad de encontrar páginas limpias aumenta gracias al trabajo previo de la manecilla principal.

Este enfoque asegura un mejor balance entre la disponibilidad de marcos libres y el rendimiento del sistema, evitando cuellos de botella en momentos críticos.

# Cuestiones de Implementación


---
### Participación del sistema operativo en la paginación
#### **1. Creación de un proceso**
Cuando se inicia un proceso, el sistema operativo debe configurar las estructuras necesarias para que el proceso pueda utilizar memoria virtual. Esto incluye:

- **Determinación del tamaño inicial de memoria:** El SO evalúa cuánto espacio necesita el programa y sus datos al inicio. Por ejemplo, un programa con una sección de código de 4 KB y datos de 8 KB necesitaría al menos 12 KB de espacio en disco y en memoria virtual.
    
- **Creación e inicialización de la tabla de páginas:** Esta tabla asocia las direcciones virtuales del proceso con marcos de memoria física. Inicialmente, puede estar vacía o contener solo las entradas necesarias para arrancar.
    
    Ejemplo: Una tabla de páginas para un proceso con direcciones virtuales de 0x0000 a 0xFFFF se inicializa con mapeos vacíos para la mayoría de las páginas y un mapeo válido para la página del código inicial.
    
- **Reserva de espacio en el área de intercambio:** Este espacio actúa como respaldo para las páginas que no caben en memoria. Algunos sistemas modernos optimizan esto leyendo directamente del archivo ejecutable, lo que elimina la necesidad de duplicar la información en disco.
    
    Ejemplo: Si un proceso tiene un archivo ejecutable `programa.exe`, las páginas del código pueden paginarse directamente desde este archivo, ahorrando tiempo y espacio.
    
- **Registro de información en la tabla de procesos:** Datos como la ubicación de la tabla de páginas y del área de intercambio se almacenan en una estructura administrativa del SO.
    


#### **2. Ejecución de un proceso**

Cuando el planificador decide ejecutar un proceso, el sistema operativo prepara el hardware y la memoria:

- **Restablecimiento de la MMU y vaciado del TLB:** La MMU (Unidad de Gestión de Memoria) traduce las direcciones virtuales a físicas. Su configuración debe ajustarse al nuevo proceso, y el TLB (Buffer de Traducción de Direcciones) se vacía para evitar inconsistencias.
    
    Ejemplo: Si el proceso previo usaba la página virtual 0x0003 para el marco físico 0x01, esa entrada se elimina al cambiar al nuevo proceso.
    
- **Actualización de la tabla de páginas:** Esto puede implicar copiar la tabla o apuntar a ella desde registros de hardware.
    
- **Carga opcional de páginas:** Para evitar demasiados fallos de página al inicio, el SO puede cargar de antemano las páginas más probables. Por ejemplo, la página que contiene la instrucción donde apunta el PC (Contador de Programa).
    


#### **3. Manejo de un fallo de página**
Un fallo de página ocurre cuando el proceso intenta acceder a una página que no está en memoria. Esto activa varias acciones:

1. **Identificación de la página faltante:** El hardware indica qué dirección virtual causó el fallo, y el SO determina qué página debe cargarse.
    
    Ejemplo: Si el proceso accede a la dirección 0x1234 y la página correspondiente no está cargada, el SO busca la página 0x1 en el disco.
    
2. **Selección de un marco de página:** Si no hay marcos libres, el SO debe desalojar una página existente, posiblemente guardándola en disco si ha sido modificada.
    
    Ejemplo: Si la página 0x2 del proceso A debe ser reemplazada por la 0x1 del proceso B, el contenido de 0x2 se guarda en el área de intercambio.
    
3. **Lectura de la página desde el disco y actualización de estructuras:** Una vez cargada la página en el marco seleccionado, se actualiza la tabla de páginas.
    
4. **Reintento de la instrucción:** Se ajusta el PC para que la instrucción que causó el fallo pueda ejecutarse correctamente ahora que la página está disponible.
    


#### **4. Terminación de un proceso**
Cuando un proceso termina, el sistema operativo libera los recursos asociados:

- **Liberación de la tabla de páginas y marcos:** Se desasignan las estructuras de datos en memoria.
    
- **Liberación de espacio en disco:** Las páginas del área de intercambio se eliminan si ya no son necesarias.
    
- **Manejo de páginas compartidas:** Si otras aplicaciones comparten estas páginas, se verifica que sean liberadas únicamente cuando ya no estén en uso.
    
    Ejemplo: Dos procesos comparten una página de biblioteca dinámica. Al terminar uno de ellos, el SO verifica que el otro aún la utiliza antes de liberar la página.
    

Este fragmento detalla la secuencia precisa de eventos que ocurren durante un **fallo de página** en un sistema operativo. Desglosemos cada paso, explicándolo con detalle y complementándolo con ejemplos:


### Manejo de fallos de página
#### **1. Interrupción por el hardware**

Cuando ocurre un fallo de página:

- El hardware genera una **interrupción** que transfiere el control al kernel del sistema operativo.
- El **contador de programa (PC)** se guarda para registrar la instrucción que causó el fallo.
- En algunos sistemas, registros especiales de la CPU almacenan información adicional sobre el estado de la instrucción.

**Ejemplo:** Supongamos que un programa intenta acceder a la dirección virtual 0x1234, pero esta página no está en memoria. El hardware pausa la ejecución y notifica al kernel.

#### **2. Salvaguarda de los registros**

Una rutina en ensamblador protege la información volátil (como registros generales) para evitar que sea sobrescrita durante el manejo del fallo. Esto garantiza que el estado del proceso fallido se pueda restaurar más adelante.

**Ejemplo:** Los registros de propósito general (por ejemplo, R0, R1, etc., en arquitecturas como ARM o x86) se guardan temporalmente en una pila o área de memoria específica.

#### **3. Identificación de la página faltante**

El sistema operativo analiza el fallo para determinar qué página virtual necesita ser cargada. Esto puede hacerse de dos maneras:

- Consultando un registro de hardware que indique la dirección virtual involucrada.
- En casos más complejos, analizando la instrucción en software.

**Ejemplo:** Si la dirección 0x1234 causó el fallo, el sistema operativo determina que corresponde a la página virtual 0x1.

#### **4. Verificación de la dirección virtual**

El sistema operativo verifica:

- **Validez:** Si la dirección pertenece al espacio de direcciones asignado al proceso.
- **Permisos:** Si el tipo de acceso (lectura/escritura/ejecución) está permitido.

Si no se cumplen estas condiciones, el proceso es notificado (por ejemplo, mediante una señal como `SIGSEGV` en Unix/Linux) o finalizado.

**Ejemplo:** Si el proceso intenta escribir en una página de solo lectura, el sistema genera una violación de acceso y termina el proceso.

#### **5. Selección de un marco de página**
Si la página es válida pero no está en memoria:

- Se busca un **marco de página libre**.
- Si no hay marcos disponibles, se aplica un **algoritmo de reemplazo de páginas** para elegir una página víctima.

Si la página víctima ha sido modificada (está "sucia"), debe escribirse al disco antes de liberar el marco.

**Ejemplo:** Un algoritmo de segunda oportunidad selecciona la página víctima, verifica si está sucia y la escribe en el área de intercambio antes de desalojarla.

#### **6. Carga de la página desde el disco**

Una vez seleccionado un marco, el sistema localiza la página requerida en el disco y planifica su carga. Mientras tanto:

- El marco se marca como ocupado.
- El proceso que causó el fallo queda suspendido.
- Otro proceso puede ejecutarse mientras la operación de disco está en progreso.

**Ejemplo:** Si la página virtual 0x1 del proceso reside en el bloque 200 del área de intercambio, el SO inicia la lectura de ese bloque en el marco seleccionado.

#### **7. Actualización de la tabla de páginas**
Cuando la operación de disco finaliza, el sistema:

- Actualiza la tabla de páginas para indicar que la página está en memoria y en qué marco reside.
- Marca el marco como válido y disponible para uso normal.

**Ejemplo:** La entrada en la tabla de páginas para la página virtual 0x1 ahora apunta al marco físico 0x5.

#### **8. Restauración del estado inicial**
El sistema respalda la instrucción que falló y ajusta el **contador de programa (PC)** para que el proceso pueda reintentarla.

**Ejemplo:** Si la instrucción `LOAD R1, [0x1234]` falló, el PC se ajusta para volver a ejecutarla ahora que la página necesaria está en memoria.

#### **9. Reanudación del proceso**
El proceso suspendido se reprograma para continuar su ejecución. El SO pasa el control a la rutina de ensamblador que gestionó el fallo.

#### **10. Restauración de los registros**
La rutina recarga los registros y el estado previo del proceso, devolviendo el control al programa en el espacio de usuario.

**Ejemplo:** Los registros generales y el PC vuelven a sus valores originales, y la instrucción fallida se ejecuta exitosamente.


#### **Complemento: Optimización del manejo de fallos**
- **Paginación anticipada:** Algunos sistemas intentan predecir qué páginas se necesitarán próximamente para cargarlas por adelantado, reduciendo fallos de página futuros.
- **TLB (Buffer de Traducción):** El TLB debe actualizarse con la nueva entrada para evitar consultas frecuentes a la tabla de páginas.


### Respaldo de instruccion
**Respaldo de la instrucción** que causó el fallo. El principal objetivo es asegurarse de que, una vez que el sistema operativo haya recuperado la página necesaria desde el disco, el programa pueda reanudar la ejecución de la instrucción que produjo el fallo de manera correcta. Este proceso es más complicado de lo que parece debido a la naturaleza de las instrucciones de la CPU, especialmente en arquitecturas con modos de direccionamiento complejos como el Motorola 680x0.

#### **1. El problema del respaldo de la instrucción**
Cuando un fallo de página ocurre, la CPU interrumpe la ejecución y el sistema operativo toma control. La clave aquí es que el **contador de programa (PC)** no siempre señala un lugar claro de inicio para la instrucción que falló. Esto se debe a la complejidad de las instrucciones de la CPU, como las que tienen **varios operandos** o las que utilizan **modos de direccionamiento avanzados**.

##### **Ejemplo de instrucción compleja:**
La instrucción `MOV.L #6(A1), 2(A0)` es una instrucción de 6 bytes, que puede incluir lo siguiente:

- El **código de operación** (MOV.L).
- El **primer operando** (`#6(A1)`, que podría ser una dirección de memoria desplazada desde A1).
- El **segundo operando** (`2(A0)`, otra dirección desplazada desde A0).

![[archivos/imagenes/Pasted image 20241208190025.png]]

Esto implica que la instrucción hace tres referencias a memoria: una para la propia instrucción (6 bytes), una para el primer operando (A1) y otra para el segundo operando (A0). Dependiendo de cuál de estas referencias falle, el contador de programa podría estar apuntando a una dirección distinta:

- **Si falla la instrucción misma** (la palabra de la instrucción), el PC estaría en 1000.
- **Si falla el primer operando** (A1), el PC estaría en 1002.
- **Si falla el segundo operando** (A0), el PC estaría en 1004.

El **problema** radica en que, cuando el fallo ocurre, **no siempre es claro cuál de estas tres referencias causó el problema**, lo que significa que el sistema operativo no puede saber con certeza en qué punto exacto de la instrucción debe reiniciar la ejecución.

#### **2. El desafío con el autoincremento y autodecremento**

Un problema adicional surge con el **modo de direccionamiento de autoincremento** y **autodecremento**, muy usado en CPUs como la del Motorola 680x0. En estos modos:

- **Autoincremento:** La dirección de un operando se incrementa automáticamente después de acceder a la memoria.
- **Autodecremento:** La dirección se decrementa automáticamente antes de acceder a la memoria.

Estos efectos secundarios de la ejecución de la instrucción pueden complicar aún más la situación, ya que el sistema operativo no sabe si el autoincremento o autodecremento ya ha ocurrido cuando el fallo de página se produce.

#### **Ejemplo del problema:**

Si una instrucción usa **autoincremento**, podría ser que el registro involucrado (por ejemplo, A1) haya sido incrementado **antes o después** de acceder a la memoria, dependiendo del diseño del microcódigo.

- **Si el incremento se hizo antes** del fallo, el sistema operativo tendrá que **decrementar el registro** al restaurar el estado.
- **Si el incremento ocurre después**, no será necesario deshacerlo.

#### **3. Soluciones hardware vs. software**
Algunas arquitecturas de CPU, como mencionan los diseñadores del Motorola 680x0, ofrecen una **solución hardware** para este problema. Las máquinas pueden incluir:

- **Un registro oculto** que guarda el valor del contador de programa justo antes de ejecutar cada instrucción.
- **Un segundo registro** que guarda el estado de los registros involucrados en autoincremento o autodecremento.

Con esta información, el sistema operativo puede **deshacer todos los efectos secundarios** de la instrucción (como el autoincremento) y asegurarse de que se pueda **reiniciar** la instrucción sin ambigüedad.

Si esta información no está disponible en el hardware, el sistema operativo **debe hacer una serie de suposiciones** y realizar una serie de operaciones para intentar determinar qué ocurrió y cómo restaurar el estado correctamente.

#### **4. Resumen de la solución en la práctica**
El proceso de reiniciar una instrucción fallida se puede dividir en varios pasos críticos:

1. **Identificar el punto de fallo:** El sistema operativo debe averiguar qué parte de la instrucción causó el fallo (instrucción misma, primer operando o segundo operando).
2. **Deshacer los efectos secundarios (como autoincremento):** Si la instrucción utilizó autoincremento o autodecremento, el sistema debe restaurar los registros a su estado previo.
3. **Reiniciar la instrucción:** Una vez que la página ha sido cargada y el sistema operativo ha restaurado el estado necesario, se puede reiniciar la ejecución de la instrucción que causó el fallo.


### Bloqueo de páginas en memoria
#### **1. El problema de la interacción entre memoria virtual y E/S**
Imaginemos un escenario donde un proceso solicita leer datos desde un archivo o un dispositivo (por ejemplo, una operación de lectura de disco o red). El sistema operativo asigna un **búfer de memoria** para almacenar los datos leídos en el **espacio de direcciones** del proceso. Mientras el proceso espera que se complete la operación de E/S, se suspende para dar paso a otro proceso.

Ahora bien, durante este tiempo en que el proceso está suspendido y otro proceso está ejecutándose, puede ocurrir lo siguiente:

- **Fallos de página:** El segundo proceso puede generar fallos de página, lo que activa el algoritmo de paginación para manejar la carga de las páginas que el proceso necesita en memoria.
- **Posible eliminación de páginas en uso:** Si el **algoritmo de paginación es global**, existe una pequeña probabilidad de que una de las páginas del proceso que está esperando E/S sea seleccionada para ser **eliminada** de la memoria. Esto es problemático, ya que puede ocurrir que el proceso de **E/S DMA** (Acceso Directo a Memoria) esté transfiriendo datos a la página de memoria que podría ser desalojada.

##### **Consecuencia:**
Si se elimina la página que está siendo utilizada para la E/S mientras los datos están siendo transferidos a ella, **se corrompen los datos**. Una parte de los datos podría terminar sobrescribiendo la página que acaba de ser cargada, lo que resulta en una pérdida o corrupción de datos.


#### **2. Soluciones al problema de la eliminación de páginas involucradas en E/S**

Existen dos enfoques principales para resolver este problema:

##### **a) Bloqueo de páginas en memoria (Pinning)**
**Pinning** o **bloqueo de páginas** significa que, mientras un proceso está realizando una operación de E/S, las páginas de memoria que están involucradas en esa operación se **"fijan"** o **bloquean** en la memoria. Esto significa que estas páginas no pueden ser eliminadas ni desplazadas durante la operación de E/S.

- **Funcionamiento:** Cuando el proceso emite una operación de E/S, el sistema operativo asegura que las páginas que contienen el búfer de E/S **no se toquen** por el algoritmo de paginación. Esto evita que se eliminen mientras se realiza la transferencia de datos.
- **Ventajas:** Garantiza que las páginas necesarias para E/S permanezcan en memoria, previniendo que se sobrescriban durante las operaciones de lectura o escritura.

##### **b) Uso de búferes del kernel**
Otra solución es hacer que el sistema operativo gestione los búferes de E/S en el **espacio de direcciones del kernel**, en lugar de hacerlo directamente en el espacio de direcciones de los procesos de usuario.

- **Funcionamiento:** El kernel realiza las operaciones de E/S utilizando búferes propios, asegurándose de que los datos sean gestionados correctamente en su propio espacio de memoria. Luego, después de que los datos han sido transferidos al búfer del kernel, los datos se **copian** a las páginas de usuario.
- **Ventajas:** Este enfoque evita que las páginas de E/S sean interferidas por el sistema de paginación del proceso de usuario, ya que la E/S se maneja de forma aislada en el espacio del kernel.

---

#### **3. Elección de la solución**
Ambas soluciones son válidas y se utilizan en diferentes contextos. La elección entre **"pinning" de páginas** y el uso de **búferes del kernel** depende de varios factores:

- **Pinning de páginas** es más eficiente en términos de rendimiento cuando el acceso a los datos es frecuente y debe ocurrir de manera rápida, ya que evita la necesidad de copiar datos entre los búferes del kernel y las páginas de usuario.
- **Búferes del kernel** proporcionan una mayor **flexibilidad y seguridad**, ya que los datos se mantienen protegidos en el espacio de direcciones del kernel, pero podría haber un costo adicional de copiar los datos a la memoria de usuario.


### **Almacén de Respaldo**
En esta sección se describe cómo se maneja el almacenamiento de respaldo para la **memoria virtual** cuando las páginas de un proceso son desalojadas de la memoria principal y transferidas al disco. El proceso de intercambio (swap) permite liberar espacio en memoria y almacenar las páginas de un proceso en el disco cuando no se están utilizando activamente, para que otras páginas puedan ser cargadas en memoria.


#### **1. Partición de intercambio (swap space)**
Uno de los métodos más sencillos para gestionar el almacenamiento de respaldo es tener una **partición de intercambio** especial en el disco, también conocida como **swap space**. Esta partición es **separada del sistema de archivos** normal y se utiliza exclusivamente para almacenar las páginas de memoria que han sido desplazadas.

- **Sin sistema de archivos en la partición de intercambio:** Esta partición no tiene un sistema de archivos tradicional, lo que elimina la sobrecarga de la conversión de desplazamientos en archivos a direcciones de bloques.
- **Uso eficiente del disco:** La partición de intercambio se organiza simplemente mediante números de bloques relativos al inicio de la partición. No hay necesidad de un sistema de archivos completo, ya que el espacio en disco se organiza y se accede de manera directa.

#### **2. Inicialización y asignación de espacio en la partición de intercambio**
Cuando el sistema se inicia, la partición de intercambio comienza vacía y se representa en memoria por una única entrada que indica su tamaño y el inicio de la partición.

- **Asignación de espacio para procesos:** Cuando se inicia un proceso, se asigna un área de la partición de intercambio para almacenar su imagen. El tamaño del área es proporcional a la **imagen de núcleo** del proceso. A medida que se inician más procesos, se les asignan áreas de la partición según sus necesidades.
- **Liberación de espacio:** Cuando un proceso termina, su espacio en la partición de intercambio se libera para que pueda ser utilizado por otros procesos.

#### **3. Cálculo de la dirección en el disco**
El sistema mantiene la **dirección de disco** para cada proceso, especificando dónde se encuentra su área de intercambio. Para calcular la dirección en el disco donde se debe escribir una página, simplemente se suma el **desplazamiento de la página** en el espacio de direcciones virtuales del proceso al inicio del área de intercambio.

#### **4. Manejo del crecimiento dinámico de procesos**
Los procesos pueden **incrementar su tamaño** durante su ejecución, especialmente en áreas como los **datos** o la **pila**, lo que presenta un desafío para la asignación de espacio en la partición de intercambio:

- **Áreas separadas para diferentes segmentos:** Una solución es reservar áreas separadas para el **texto**, **datos** y **pila** del proceso. Esto permite gestionar mejor el espacio de intercambio y prevenir problemas cuando el tamaño de estas áreas cambia.
- **Asignación dinámica de espacio:** También se puede optar por no asignar espacio en el disco de antemano y, en su lugar, **asignar espacio cuando se intercambie una página hacia fuera de memoria** y **liberarlo cuando la página se vuelva a cargar** en memoria. Este enfoque reduce la cantidad de espacio en el disco ocupado por un proceso, pero introduce la necesidad de **gestionar dinámicamente las direcciones de disco** para cada página.

#### **5. Opciones de almacenamiento de respaldo**
El modelo más simple (en el que las páginas se almacenan de manera contigua en el disco) tiene algunas limitaciones y complejidades, por lo que se exploran alternativas:

![[archivos/imagenes/Pasted image 20241208190604.png]]

##### **Modelo de partición de intercambio fija (Figura 3-29a)**
En este modelo, la partición de intercambio tiene una **ubicación fija** en el disco. Las páginas que están en memoria tienen una **copia correspondiente** en el disco, almacenada en posiciones fijas y ordenadas de acuerdo con el número de página virtual. Si la página se modifica en memoria, su copia en disco puede volverse **obsoleta** y deberá actualizarse.

- **Ventaja:** El cálculo de la dirección en el disco es sencillo: se conoce el inicio del área de intercambio y las páginas se organizan de forma contigua.
- **Desventaja:** Este modelo requiere espacio fijo para todas las páginas del proceso, lo que puede no ser eficiente en términos de uso de espacio.

##### **Modelo de partición de intercambio dinámica (Figura 3-29b)**
En este modelo, no hay **ubicaciones fijas** en el disco para las páginas. Cuando se necesita intercambiar una página fuera de la memoria, el sistema selecciona una página vacía en el disco en el momento y **actualiza el mapa de disco** para reflejar la ubicación de la página.

- **Ventaja:** Este modelo permite una mayor flexibilidad, ya que no se reserva espacio fijo de antemano, sino que se asigna dinámicamente a medida que las páginas se intercambian.
- **Desventaja:** Se necesita una **tabla de mapeo** por proceso para llevar un registro de las páginas en el disco, lo que puede introducir complejidad adicional en el sistema.

#### **6. Alternativas de almacenamiento cuando no hay partición de intercambio fija**
En algunos casos, como cuando no hay suficiente espacio de disco para una partición de intercambio dedicada, se pueden utilizar **archivos del sistema de archivos normal** como área de intercambio. Por ejemplo, **Windows** usa este enfoque.

##### **Optimización con archivos ejecutables**
Una optimización interesante es utilizar el archivo ejecutable del proceso como área de intercambio para el **texto del programa**, ya que este segmento es de **sólo lectura**. Si la memoria se llena y es necesario desalojar páginas del texto, estas pueden simplemente **descartarse y recargarse desde el archivo ejecutable** cuando se necesiten nuevamente. Esto evita ocupar espacio adicional en el disco para el texto de los programas y optimiza el uso del almacenamiento.


### **Separación de Política y Mecanismo**

La separación de **política** y **mecanismo** es un principio fundamental en la administración de sistemas complejos, como la gestión de memoria en los sistemas operativos. Este enfoque ayuda a reducir la complejidad al desacoplar las decisiones de alto nivel (política) de la implementación detallada (mecanismo), lo que facilita la flexibilidad y la adaptabilidad de los sistemas operativos.

En el contexto de la gestión de memoria, esta separación se puede lograr mediante la división del administrador de memoria en dos componentes principales, lo que permite delegar la responsabilidad de las decisiones de política a los procesos de usuario, mientras que los mecanismos de bajo nivel son gestionados por el sistema operativo. Este enfoque fue implementado inicialmente en el sistema operativo **Mach**.

#### **Modelo de Separación: Mecanismo y Política en la Gestión de Memoria**
En el sistema que se describe, la gestión de la memoria se divide en tres componentes principales, que interactúan para manejar los fallos de página:

1. **Manejador de la MMU (Unidad de Gestión de Memoria)**:
    
    - Este componente maneja las interacciones más cercanas al hardware y está diseñado para ser dependiente de la plataforma. Su responsabilidad es controlar la memoria física y gestionar las referencias de memoria directa de las páginas virtuales, haciendo uso de registros específicos de la máquina y configuraciones de hardware.
    - Es el componente que más directamente interactúa con la arquitectura de hardware y tiene que ser adaptado a diferentes plataformas.
2. **Manejador de fallos de página (en el kernel)**:
    
    - Este manejador se encarga de interceptar los fallos de página y coordina la carga de páginas desde el disco cuando es necesario. Está incluido en el **núcleo (kernel)** y es independiente de la máquina, lo que significa que puede ejecutarse en diferentes arquitecturas de hardware sin modificaciones significativas.
    - Su tarea principal es decidir qué hacer cuando una página no se encuentra en memoria y manejar la parte técnica de la paginación.
3. **Paginador externo (en espacio de usuario)**:
    
    - El paginador externo es un proceso que se ejecuta en **espacio de usuario** y maneja la política de paginación, como la decisión de qué páginas cargar y desalojar. A través de este componente, se define la **política** del sistema, es decir, los criterios para la gestión de la memoria virtual, como el reemplazo de páginas y la asignación de espacio en el disco para el respaldo.
    - Este componente está separado del núcleo, lo que permite que se modifique y se adapte sin afectar al sistema operativo directamente.

![[archivos/imagenes/Pasted image 20241208191344.png]]

#### **Flujo de Manejo de Fallos de Página:**
1. **Fallo de Página:**
    
    - Cuando un proceso intenta acceder a una página que no está presente en la memoria, se produce un fallo de página, y el manejador de fallos de página del kernel se encarga de interceptarlo.
2. **Notificación al Paginador Externo:**
    
    - El manejador de fallos de página determina qué página se necesita y notifica al paginador externo. Este proceso de comunicación puede implicar enviar un mensaje al paginador que se ejecuta en espacio de usuario para indicarle qué página debe ser cargada desde el disco.
3. **Carga de la Página:**
    
    - El **paginador externo** lee la página desde el disco y la copia a su espacio de direcciones. Esta acción la lleva a cabo en un área dedicada de su propio espacio de usuario.
4. **Incorporación de la Página en la Memoria del Usuario:**
    
    - Una vez que el paginador externo ha cargado la página, notifica al manejador de fallos de página sobre la ubicación de la página en su espacio de direcciones.
    - El manejador de fallos de página luego desasigna la página del espacio de direcciones del paginador externo y le pide al manejador de la MMU que la coloque en el espacio de direcciones del proceso de usuario.
5. **Reinicio del Proceso:**
    
    - Finalmente, el proceso del usuario puede reanudar su ejecución, con la página requerida ya disponible en memoria.

---

#### **Ventajas y Desventajas de Separar Política y Mecanismo:**

##### **Ventajas:**
- **Modularidad y Flexibilidad:** Al separar el mecanismo (operaciones básicas de paginación) de la política (estrategias de reemplazo de páginas), se logra una mayor modularidad y flexibilidad en el sistema. Esto permite que las decisiones sobre la gestión de la memoria puedan ser ajustadas sin modificar las operaciones de bajo nivel que interactúan directamente con el hardware.
- **Mayor Adaptabilidad:** Este enfoque facilita la adaptación del sistema a diferentes plataformas y configuraciones, ya que el manejador de la MMU puede ser ajustado para cada hardware, mientras que las políticas de paginación se pueden modificar sin afectar la infraestructura fundamental del sistema operativo.

##### **Desventajas:**
- **Sobrecarga de Comunicación:** La principal desventaja de este enfoque es la **sobrecarga adicional** de comunicar el sistema de usuario (el paginador externo) con el kernel en varias ocasiones durante el manejo de fallos de página. Cada vez que se necesita información o se toman decisiones de política, el sistema debe cruzar el límite entre el espacio de usuario y el espacio del kernel, lo que introduce **latencia** y **gastos operativos adicionales**.
- **Mensajería Compleja:** La interacción entre el manejador de fallos de página y el paginador externo a través de mensajes puede ser compleja y costosa, especialmente si se involucra en una carga de trabajo con frecuentes fallos de página. Esto puede afectar el rendimiento global del sistema.

#### **Consideraciones Finales:**
Aunque el modelo que separa la política y el mecanismo en la gestión de memoria tiene ventajas significativas, especialmente en términos de **flexibilidad** y **modularidad**, también presenta desafíos como la sobrecarga de la comunicación entre el espacio de usuario y el espacio del kernel. A medida que los sistemas de hardware mejoran y los procesos se hacen más complejos, muchos desarrolladores pueden aceptar sacrificar un poco de rendimiento para obtener una **mayor confiabilidad** y **mantenimiento más sencillo** en sus sistemas. Este enfoque modular permite que los algoritmos de paginación y las políticas de gestión de memoria se ajusten y evolucionen sin necesidad de alterar los componentes fundamentales del sistema operativo.

# Segmentación 
La segmentación es una técnica de administración de memoria que organiza la memoria en unidades lógicas, llamadas segmentos, que permiten que distintas partes de un programa se manejen de manera independiente. A diferencia de la memoria virtual unidimensional (paginación), que organiza las direcciones en una secuencia continua, la segmentación divide el espacio de direcciones en segmentos de tamaño variable que pueden crecer y reducirse de forma independiente, lo cual es útil para problemas en los que las estructuras de datos tienen un tamaño dinámico.

#### Características clave de la segmentación:

1. **Segmentos independientes**:
    
    - Cada segmento tiene una longitud dinámica que puede variar durante la ejecución del programa. Esto permite que estructuras como pilas, tablas de símbolos o árboles de análisis sintáctico crezcan o se reduzcan sin interferir con otros segmentos.
    - Ejemplo: En un compilador, las tablas de símbolos, el texto del código fuente, las constantes, el árbol de análisis y la pila pueden estar en segmentos separados y crecer de manera independiente según las necesidades del programa.
2. **Direcciones segmentadas**:
    
    - Para acceder a una dirección dentro de un segmento, se utilizan dos componentes: un número de segmento y una dirección dentro de ese segmento.
    - Esto simplifica la vinculación de procedimientos, ya que, por ejemplo, cuando un procedimiento se recompila, su dirección inicial no cambia, lo que facilita el manejo de direcciones sin necesidad de reconfigurar otros procedimientos que lo llaman.
3. **Protección de segmentos**:
    
    - La segmentación permite especificar diferentes tipos de protección para cada segmento. Por ejemplo, un segmento de código puede ser solo ejecutable, mientras que un segmento de datos puede ser de lectura y escritura.
    - Esta protección es útil para detectar errores de programación, ya que el sistema puede interceptar intentos de acceder incorrectamente a un segmento.
4. **Ventajas sobre la paginación**:
    
    - **Flexibilidad**: La segmentación es más flexible para administrar estructuras de datos de tamaño variable, como pilas o tablas de símbolos, ya que cada segmento puede crecer o reducirse sin afectar a otros.
    - **Simplicidad en la vinculación**: Los programas con múltiples procedimientos pueden beneficiarse de la segmentación, ya que no requieren cambios en las direcciones de los procedimientos que no se modifican.
5. **Memoria segmentada frente a memoria paginada**:
    
    - En la paginación, el programador no tiene control sobre la estructura de la memoria, ya que la memoria se divide en páginas de tamaño fijo. Sin embargo, en la segmentación, el programador tiene control sobre la organización de la memoria, lo que permite optimizar el uso de la misma.
    - En un sistema segmentado, cada segmento tiene una protección específica, y el acceso no autorizado (por ejemplo, lectura de un segmento de solo ejecución) puede ser detectado fácilmente. En la paginación, este tipo de control es más difícil, ya que el sistema operativo maneja la asignación de páginas de manera transparente.

![[archivos/imagenes/Pasted image 20241208192915.png]]

![[archivos/imagenes/Pasted image 20241208192927.png]]

#### Ejemplo práctico:

En la segmentación, un programa podría tener varios segmentos:

- **Segmento 0**: Contiene el texto del código fuente.
- **Segmento 1**: Contiene la tabla de símbolos.
- **Segmento 2**: Contiene las constantes del programa.
- **Segmento 3**: Contiene el árbol de análisis sintáctico.
- **Segmento 4**: Contiene la pila de llamadas.

Cada segmento puede crecer o reducirse independientemente. Esto es diferente de la memoria unidimensional, donde los diferentes elementos (por ejemplo, tablas y pilas) compiten por el espacio contiguo, lo que puede llevar a problemas si una estructura crece más de lo esperado.

En resumen, la segmentación ofrece una manera más flexible y estructurada de organizar la memoria, especialmente útil para programas con estructuras de datos dinámicas o complejas.

### Implementación de segmentación pura
La **implementación de segmentación pura** se diferencia de la **paginación** principalmente en que los **segmentos no tienen un tamaño fijo**; esto les permite tener tamaños variables según las necesidades del programa en ejecución. Sin embargo, esta flexibilidad en la asignación de memoria también introduce un problema importante: la **fragmentación externa**.

![[archivos/imagenes/Pasted image 20241208193117.png]]

#### Descripción del proceso de implementación y la fragmentación externa:

1. **Distribución inicial de segmentos**: En la figura 3-34(a), inicialmente la memoria física contiene cinco segmentos. Cada segmento ocupa una porción de la memoria de tamaño variable.
    
2. **Desalojo y reasignación de segmentos**: Si un segmento, como el **segmento 1**, se desaloja y se coloca un nuevo segmento más pequeño (por ejemplo, el **segmento 7**), se observa que, debido a la variabilidad en el tamaño de los segmentos, puede quedar un **hueco de memoria** entre el segmento 7 y el segmento 2 (ver figura 3-34(b)).
    
3. **Fragmentación externa**: A medida que más segmentos se desalojan y otros más pequeños se asignan a la memoria (como en las figuras 3-34(c) y 3-34(d), donde el **segmento 4** es reemplazado por el **segmento 5**, y el **segmento 3** por el **segmento 6**), la memoria puede acabar con múltiples espacios vacíos (huecos) entre los segmentos. Esta situación se conoce como **fragmentación externa**, ya que los huecos no están contiguos entre sí, lo que dificulta la asignación de nuevos segmentos.
    
4. **Efecto de tablero de ajedrez**: A medida que el sistema sigue funcionando, se acumulan más huecos en la memoria, creando una **fragmentación externa** o **efecto de tablero de ajedrez**. Este efecto se caracteriza por la memoria que está "desperdiciada" en los huecos entre los segmentos asignados, aunque en teoría, podría ser utilizada por otros segmentos si se compactara la memoria.
    
5. **Compactación**: Una posible solución para la **fragmentación externa** es la **compactación**. Este proceso implica mover los segmentos ocupados de manera que los huecos (espacios vacíos) queden al final de la memoria, permitiendo que los segmentos contiguos ocupen espacios sin huecos. Esto requiere un tiempo adicional, ya que implica reubicar los segmentos activos y actualizar sus tablas de segmentos.
    

#### Resumen de las ventajas y desventajas de la segmentación pura:
- **Ventajas**:
    - Flexibilidad en el tamaño de los segmentos, lo que facilita la asignación de memoria de manera más dinámica y eficiente para diferentes tipos de datos o estructuras (por ejemplo, procedimientos, pilas, tablas de símbolos).
    - La segmentación permite una mayor protección a nivel de segmento, ya que cada segmento puede tener distintas protecciones de acceso (por ejemplo, solo lectura, solo ejecución, etc.).
- **Desventajas**:
    - **Fragmentación externa**: Los huecos que quedan al reasignar segmentos pueden desperdiciar memoria si no se gestionan correctamente.
    - El proceso de **compactación** puede ser costoso en términos de rendimiento, ya que requiere mover los segmentos y actualizar sus direcciones.

La segmentación pura es una técnica poderosa pero puede ser menos eficiente que la paginación cuando se trata de manejar la memoria a largo plazo, especialmente en sistemas con un alto grado de fragmentación.

### Diferencias paginacion y segmentación 
La **paginación** y la **segmentación** son dos técnicas de gestión de memoria virtual utilizadas en sistemas operativos para manejar la memoria de manera eficiente, pero se diferencian en su enfoque y en cómo gestionan la memoria y los espacios de direcciones.


- **Paginación**: La memoria se divide en **páginas de tamaño fijo**. El espacio de direcciones virtuales y la memoria física se dividen en unidades de igual tamaño llamadas páginas (en la memoria virtual) y marcos (en la memoria física). La asignación de memoria no depende del tipo de datos o su uso, sino solo del tamaño fijo de las páginas.
    
- **Segmentación**: En este caso, la memoria se divide en **segmentos de tamaño variable**, según las necesidades del programa. Cada segmento puede representar una estructura lógica diferente del programa, como un procedimiento, una pila, una tabla de datos, etc. La longitud de cada segmento puede cambiar durante la ejecución del programa.
    

- **Paginación**: El tamaño de las páginas es **fijo** y generalmente se elige al momento de la creación del sistema operativo (típicamente entre 4 KB y 64 KB). Este tamaño fijo facilita la gestión, pero puede llevar a un uso ineficiente de la memoria si el programa no utiliza todo el espacio de cada página.
    
- **Segmentación**: Los **segmentos son de tamaño variable**, lo que significa que pueden adaptarse al tamaño real de las estructuras del programa. Por ejemplo, un procedimiento podría tener un segmento de tamaño pequeño, mientras que una tabla de datos podría tener un segmento mucho mayor. Esto permite una gestión de memoria más eficiente en ciertos casos, ya que los segmentos solo ocupan el espacio que realmente necesitan.
    


- **Paginación**: El programa ve la memoria como un espacio **unidimensional** y continuo. Las páginas y los marcos están organizados en bloques de igual tamaño, y el programa no tiene conocimiento de cómo se organiza la memoria física. El sistema operativo gestiona automáticamente la asignación de páginas en la memoria física.
    
- **Segmentación**: La memoria es vista como un espacio **bidimensional**, donde cada segmento tiene una **entidad lógica** que tiene un propósito específico (por ejemplo, un procedimiento, una pila, una tabla de datos). El programador o el sistema operativo gestionan los segmentos de manera independiente, lo que proporciona un control más granular sobre cómo se organiza la memoria.
    

- **Paginación**: Debido a que las páginas tienen un tamaño fijo, es más fácil realizar una asignación de memoria eficiente, pero puede surgir un problema conocido como **fragmentación interna**. Esto ocurre cuando un programa no utiliza toda la memoria dentro de una página, lo que lleva a un desperdicio de espacio.
    
- **Segmentación**: La segmentación tiene la ventaja de **adaptarse a la estructura lógica** del programa, ya que los segmentos pueden crecer o reducirse dinámicamente. Sin embargo, puede sufrir de **fragmentación externa**, donde el espacio libre en la memoria se dispersa entre los segmentos asignados, lo que puede llevar a la ineficiencia en la utilización de la memoria.
    

- **Paginación**: La protección de la memoria se realiza a nivel de página. Aunque se puede establecer protección (lectura, escritura, ejecución) para las páginas, es más difícil establecer una protección más granular para diferentes tipos de datos dentro de la misma página.
    
- **Segmentación**: Cada segmento puede tener **diferentes niveles de protección**. Por ejemplo, un segmento de código puede ser de solo ejecución, mientras que un segmento de datos puede ser de lectura/escritura. Esto proporciona un control más fino sobre la protección de la memoria.
    

- **Paginación**: La paginación puede ser más eficiente en términos de **asignación de memoria** debido a su tamaño de página fijo, pero puede llevar a **fragmentación interna** (espacio desperdiciado dentro de cada página), y la administración de las tablas de páginas puede requerir un overhead adicional.
    
- **Segmentación**: La segmentación permite **una gestión más flexible de la memoria**, ya que los segmentos pueden tener tamaños variables, lo que puede reducir la fragmentación interna. Sin embargo, **la fragmentación externa** (espacios vacíos entre segmentos) puede ser un problema, lo que requiere procesos de **compactación** de la memoria, que pueden ser costosos en términos de rendimiento.
    

|Característica|Paginación|Segmentación|
|---|---|---|
|**Tamaño de unidades**|Fijo (páginas)|Variable (segmentos)|
|**Espacio de direcciones**|Unidimensional (espacio continuo de páginas)|Bidimensional (segmentos lógicos)|
|**Control sobre la memoria**|Menos control sobre el contenido de las páginas|Mayor control, ya que los segmentos son lógicos|
|**Fragmentación**|Interna (dentro de las páginas)|Externa (huecos entre segmentos)|
|**Protección**|A nivel de página (más general)|A nivel de segmento (más específico)|
|**Compromisos de rendimiento**|Eficiencia, pero puede haber desperdicio interno|Más flexible, pero puede sufrir de fragmentación externa|

### Segmentación con paginación: MULTICS
La **segmentación con paginación** es una técnica que combina las ventajas de la segmentación y la paginación para gestionar la memoria de manera más eficiente. Un ejemplo importante de un sistema que implementó esta técnica es **MULTICS**, un sistema operativo desarrollado para las máquinas Honeywell 6000.

#### Conceptos Fundamentales
- **Segmentación**: En MULTICS, la memoria se divide en **segmentos** de tamaño variable, que representan diferentes estructuras lógicas del programa (por ejemplo, código, datos, pila). Esta técnica proporciona **modularidad**, **protección** y **compartición** entre programas.
    
- **Paginación**: Los **segmentos de MULTICS se pagan** en unidades fijas de tamaño, lo que permite que solo las **páginas que se necesitan** estén en memoria. Esto elimina la necesidad de mantener todo el segmento en memoria, optimizando el uso de la memoria principal.
    
![[archivos/imagenes/Pasted image 20241208193602.png]]

#### ¿Cómo Funciona la Segmentación con Paginación en MULTICS?
1. **Estructura de la Memoria Virtual**:
    - MULTICS tiene **hasta 2^18 segmentos** (más de 250,000), cada uno de hasta 65,536 palabras de longitud.
    - Cada **segmento se trata como una unidad de memoria virtual** y se **paga** en páginas.
    - La **tabla de segmentos** de cada programa contiene un descriptor para cada segmento.
    - La tabla de segmentos misma también está paginada, ya que puede tener un número considerable de entradas (más de 250,000).
2. **El Descriptor de Segmento**:
    - El descriptor de un segmento contiene **información crucial** sobre ese segmento: si está en memoria, la dirección de la tabla de páginas correspondiente, el tamaño del segmento, los **bits de protección**, etc.
    - Cuando el segmento está en memoria, el descriptor contiene un **puntero a la tabla de páginas** de ese segmento.
3. **Dirección Virtual**:
    - Una dirección virtual en MULTICS consta de dos partes:
        - **Número de segmento**: Identifica el segmento en la memoria.
        - **Dirección dentro del segmento**: Se divide en:
            - **Número de página**: Determina cuál página dentro del segmento se refiere.
            - **Desplazamiento dentro de la página**: Ubicación exacta dentro de la página.
4. **Proceso de Dirección**: Cuando ocurre una referencia a memoria, se sigue un proceso:
    
    1. Se localiza el **descriptor del segmento** utilizando el número de segmento.
    2. Si la **tabla de páginas** del segmento está en memoria, se busca la entrada correspondiente.
    3. Si la página deseada está en memoria, se obtiene la **dirección física** de la palabra.
    4. Si la página no está en memoria, se genera un **fallo de página** y se carga la página en memoria.

![[archivos/imagenes/Pasted image 20241208193654.png]]

![[archivos/imagenes/Pasted image 20241208193809.png]]

![[archivos/imagenes/Pasted image 20241208193817.png]]

#### Uso de TLB en MULTICS
- Para mejorar el rendimiento, **MULTICS utiliza un TLB** (Translation Lookaside Buffer) de 16 entradas, que almacena las páginas de memoria recientemente referenciadas. Esto permite acceder rápidamente a las direcciones de memoria sin tener que consultar las tablas de segmentos y páginas.
    
- Si la dirección solicitada está en el **TLB**, se obtiene directamente el **marco de página** desde ahí.
    
- Si no está en el TLB, se consulta el **descriptor de segmento** y la **tabla de páginas** para obtener la dirección de memoria física, y el TLB se actualiza con esta información.
    

![[archivos/imagenes/Pasted image 20241208193745.png]]

#### Ventajas y Funciones Combinadas

La **combinación de segmentación y paginación** en MULTICS tiene varias ventajas:

- **Segmentación** facilita la programación y proporciona protección y compartición, permitiendo que diferentes segmentos de un mismo programa se compartan entre diferentes usuarios.
- **Paginación** mejora la utilización de la memoria al cargar solo las páginas necesarias, reduciendo la fragmentación externa y permitiendo que grandes segmentos se mantengan parcialmente en memoria.

#### Resumen del Proceso de Direccionamiento:

1. **Número de segmento** se usa para localizar el descriptor del segmento.
2. El descriptor señala la **tabla de páginas** (si está en memoria).
3. **Número de página** dentro del segmento se utiliza para encontrar el **marco de página** en la memoria física.
4. Se **sumará el desplazamiento** al marco de página para obtener la **dirección final**.
5. Finalmente, se lleva a cabo la **operación de lectura/escritura**.

