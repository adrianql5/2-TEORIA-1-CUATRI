x [[archivos/bibliografia/2-Sistemas operativos moderno 3ed Tanenbaum.pdf|2-Sistemas operativos moderno 3ed Tanenbaum]]

Escrito por **Adrián Quiroga Linares**.

La **memoria principal** (*RAM*) es un recurso esencial que debe ser administrado cuidadosamente. Aunque las computadoras actuales tienen mucha más memoria que las de hace décadas, los programas crecen a un ritmo más rápido que la capacidad de las memorias. Se dice que **"los programas se expanden para llenar la memoria disponible"**, lo que presenta desafíos para su gestión. A pesar de que los programadores desearían tener una memoria infinita, rápida, no volátil y económica, la tecnología actual no ofrece tales soluciones.

En lugar de esto, las computadoras tienen una **jerarquía de memoria**, que incluye **memoria caché** (*rápida, costosa y volátil*), **memoria principal** (*de velocidad media y precio moderado*), almacenamiento en **disco** (*lento, económico y no volátil*), y **almacenamiento removible**. El sistema operativo debe gestionar esta jerarquía de manera eficiente. Esto se logra a **través del administrador de memoria, encargado de asignar y liberar memoria según sea necesario**.

![[archivos/imagenes/Pasted image 20241121183519.png]]

# Sin abstracción de la memoria: 
En los sistemas más antiguos y simples, como las primeras computadoras mainframes (antes de 1960), minicomputadoras (antes de 1970) y computadoras personales (antes de 1980), no existía **abstracción de memoria**. Los programas interactuaban directamente con la **memoria física**, lo que significa que cada programa veía un conjunto lineal de direcciones físicas desde 0 hasta un valor máximo, donde cada dirección correspondía a una celda con un tamaño fijo de bits (típicamente 8 bits, un byte). Esto significaba:

1. **Acceso directo**: Si un programa ejecutaba una instrucción como `MOV REGISTRO1, 1000`, simplemente accedía a la ubicación física 1000 en la memoria.
2. **No había separación entre programas**: Si dos programas intentaban usar la misma dirección de memoria, podían sobrescribir los datos del otro, lo que resultaba en fallos inmediatos.

#### Organización de la memoria en sistemas sin abstracción

A pesar de no tener abstracción de memoria, existían diversas formas de organizar la memoria en estos sistemas, como se muestra en la figura 3-1:

1. **Sistema operativo en RAM (Figura 3-1a)**:
    
    - El sistema operativo residía en la parte inferior de la memoria RAM.
    - Este modelo era común en las primeras mainframes y minicomputadoras.
    - **Problema**: Un error en el programa del usuario podía sobrescribir el sistema operativo.
2. **Sistema operativo en ROM (Figura 3-1b)**:
    
    - El sistema operativo se colocaba en la parte superior de la memoria, en una ROM.
    - Común en sistemas integrados y computadoras de bolsillo.
    - La ROM protegía el sistema operativo de ser modificado, ya que era de solo lectura.
3. **Sistema operativo dividido entre RAM y ROM (Figura 3-1c)**:
    
    - El sistema operativo principal estaba en RAM, y los controladores de dispositivos en ROM.
    - Ejemplo: Las primeras computadoras personales, como las que usaban MS-DOS.
    - **BIOS (Basic Input Output System)**: Parte del sistema operativo en ROM.

![[archivos/imagenes/Pasted image 20241121183354.png]]

#### Limitaciones de los sistemas sin abstracción

1. **Ejecutar un solo programa a la vez**:
    
    - Un programa se cargaba en memoria y se ejecutaba.
    - Al terminar, se cargaba otro programa, sobrescribiendo al primero.
    - El sistema era secuencial: el usuario introducía comandos y esperaba a que cada programa finalizara.
2. **Conflictos entre programas**:
    
    - Sin abstracción, un programa podía borrar o corromper datos del sistema operativo o de otro programa.
3. **Falta de paralelismo**:
    
    - La única forma de lograr cierto paralelismo era usando múltiples **hilos** dentro del mismo programa. Sin embargo, este enfoque tenía limitaciones, ya que los hilos comparten la misma memoria y no permiten ejecutar programas independientes simultáneamente.

#### Soluciones para múltiples programas sin abstracción

Aunque no había abstracción de memoria, se desarrollaron estrategias para permitir la ejecución de varios programas:

1. **Intercambio de programas**:
    
    - Cuando un programa terminaba o se pausaba, su contenido en memoria se guardaba en disco.
    - Otro programa se cargaba desde el disco a la memoria, eliminando conflictos.
2. **Protección de memoria con hardware**:
    
    - En la IBM 360, la memoria se dividía en bloques de 2 KB con **llaves de protección** de 4 bits.
    - Cada proceso tenía una llave que debía coincidir con la del bloque de memoria que intentaba acceder. Si no coincidían, el hardware generaba una interrupción (trap).
    - Este enfoque evitaba que los procesos interfieran entre sí o con el sistema operativo.

#### Problema de reubicación

Un gran desafío era la **reubicación de direcciones** cuando varios programas compartían la memoria:

1. **Referencias absolutas**:
    
    - Cada programa usaba direcciones absolutas. Si un programa esperaba encontrar una instrucción en la dirección 24, no podía funcionar correctamente si se cargaba en otra ubicación.
2. **Reubicación estática**:
    
    - Para resolver esto, durante la carga del programa se sumaba un valor constante a todas las direcciones del programa, ajustándolas según la posición en memoria.
    - Problemas:
        - Era lento, ya que cada dirección debía ajustarse manualmente.
        - Requería información adicional en los programas para distinguir entre direcciones (que necesitaban ajuste) y constantes (que no debían modificarse).

![[archivos/imagenes/Pasted image 20241121183424.png]]

#### Aplicaciones modernas de sistemas sin abstracción

Aunque en los sistemas modernos (como mainframes y PCs) la memoria física ya no se utiliza directamente, en sistemas simples como dispositivos integrados (p. ej., radios, lavadoras, microondas), el software sigue utilizando **memoria física absoluta**. Razones:

- Los programas se conocen de antemano y son específicos para el dispositivo.
- Los usuarios no pueden cargar su propio software.

En algunos casos, un sistema operativo mínimo actúa como una biblioteca para facilitar tareas comunes, como el sistema operativo **e-cos**.


# Espacios de Direcciones
Exponer directamente la memoria física a los procesos tiene desventajas, principalmente:

1. **Problemas de protección:** Los procesos pueden alterar accidental o intencionalmente el sistema operativo.
2. **Dificultad para ejecutar múltiples programas:** Es complejo mantener varios programas en memoria al mismo tiempo sin interferencias.

Para resolver esto, se introduce una **abstracción de memoria** conocida como el **espacio de direcciones**.

---
### **La noción de un espacio de direcciones**
Un **espacio de direcciones** es el conjunto de direcciones que un proceso puede utilizar para acceder a la memoria. Cada proceso tiene su propio espacio, independiente de los demás, salvo casos específicos de compartición.

Este concepto se aplica a múltiples contextos, como:

- **Direcciones IP:** Espacio de 32 bits (IPv4: 0 a 232−12^{32}-1).
- **Puertos de E/S:** Espacio de direcciones de 0 a 16,383 en el Pentium.
- **Dominios de Internet:** Cadenas alfanuméricas, como en ".com".

El desafío consiste en asignar a cada programa un espacio de direcciones que corresponda a distintas ubicaciones físicas sin interferencias.

---
#### **Registros base y límite**
Una solución clásica utiliza **reubicación dinámica** con registros especiales en el hardware de la CPU:

1. **Registro base:** Contiene la dirección física donde empieza el programa.
2. **Registro límite:** Define la longitud del programa.

Cuando un proceso accede a la memoria:
- El hardware suma automáticamente el valor del registro base a la dirección generada por el programa.
- Verifica si la dirección resultante excede el rango permitido (base + límite). Si es así, genera un error y aborta el acceso.

##### **Ventajas:**
- Permite a cada proceso un espacio de direcciones privado.
- Protege los registros base y límite, para que solo el sistema operativo pueda modificarlos.

##### **Desventajas:**
- Se requiere realizar una suma y una comparación en cada acceso a memoria, lo que puede ser lento sin circuitos especiales.

![[archivos/imagenes/Pasted image 20241121185123.png]]
---

#### **Conclusión**
Los espacios de direcciones permiten a los sistemas operativos abstraer y gestionar la memoria de forma segura y eficiente, haciendo posible la ejecución de múltiples programas simultáneamente sin interferencias. Este concepto evolucionó con el tiempo hacia métodos más avanzados en los procesadores modernos.

### Itercambio
El intercambio (_swapping_) es una estrategia de administración de memoria que permite a los sistemas operativos ejecutar procesos incluso cuando no hay suficiente memoria física disponible para alojarlos todos al mismo tiempo. Se basa en mover procesos completos entre la memoria principal (RAM) y el almacenamiento secundario (disco) según sea necesario.

#### **Motivación para el Intercambio**
1. **Cantidad limitada de RAM:** En sistemas modernos, la cantidad total de RAM necesaria para ejecutar todos los procesos concurrentemente puede exceder la memoria disponible.
    
    - Por ejemplo, aplicaciones de usuario como navegadores o editores de video pueden consumir entre 50 y 200 MB cada una.
    - Además, procesos en segundo plano como actualizaciones de software o comprobaciones de correo ocupan memoria, incluso antes de que el usuario ejecute sus propias aplicaciones.
2. **Requerimientos dinámicos:** Los procesos pueden necesitar más memoria durante su ejecución debido a estructuras dinámicas como el _heap_ o la pila.



#### **Cómo Funciona el Intercambio**
1. **Movimiento de procesos:**
    - Cuando un proceso está listo para ejecutarse, se carga completamente en la memoria.
    - Una vez que ha usado su tiempo de CPU asignado o se encuentra inactivo, puede ser devuelto al disco, liberando espacio en la memoria.

2. **Ejemplo de Operación:**
    - Inicialmente, sólo el proceso A está en la memoria.
    - Luego, se cargan los procesos B y C, desplazando a A si es necesario.
    - Más tarde, A regresa a memoria en una ubicación diferente, requiriendo que sus direcciones se ajusten.

3. **Reubicación de direcciones:**
    - Cuando un proceso se mueve, las direcciones internas que usa deben ser actualizadas.
    - Esto puede realizarse mediante:
        - **Software:** Reescribiendo las direcciones durante el intercambio.
        - **Hardware:** Usando registros base y límite para traducir las direcciones durante la ejecución.


![[archivos/imagenes/Pasted image 20241121185439.png]]

#### **Desafíos del Intercambio**
1. **Fragmentación de la memoria:**
    - Con el tiempo, el intercambio puede generar espacios vacíos dispersos (fragmentación externa).
        
    - Una técnica para solucionar esto es la **compactación de memoria**, donde los procesos se agrupan desplazándolos hacia abajo en la memoria.
        
    - Sin embargo, este proceso es costoso en términos de tiempo de CPU.
        
    
    > Por ejemplo, en un sistema con 1 GB de RAM y un ancho de banda de 4 bytes cada 20 nanosegundos, la compactación completa tomaría cerca de 5 segundos.
    
2. **Asignación de memoria adicional:**
    - Cuando se espera que los procesos crezcan (por ejemplo, usando _heap_), se puede asignar espacio extra para evitar moverlos con frecuencia.
    - Si un proceso crece más allá del espacio asignado, puede:
        - Usar un hueco adyacente.
        - Moverse a otro lugar en la memoria.
        - Intercambiarse al disco hasta que haya espacio disponible.
3. **Eficiencia:**
    - Sólo debe intercambiarse al disco la memoria realmente en uso por el proceso, ya que intercambiar espacio extra es ineficiente.

#### **Esquemas para Crecimiento de Procesos**
1. **Crecimiento de segmentos únicos:**
    - Si sólo se espera que crezca un segmento (por ejemplo, datos), se reserva espacio adicional entre procesos.

2. **Crecimiento de múltiples segmentos:**
    - En lenguajes de programación que usan tanto _heap_ como pila, ambos pueden crecer simultáneamente en direcciones opuestas:
        - _Heap_ crece hacia arriba.
            
        - _Pila_ crece hacia abajo.
            
    
    > Si el espacio reservado entre ambos se agota, el proceso deberá moverse o intercambiarse.

![[archivos/imagenes/Pasted image 20241121185557.png]]

#### **Conclusión**
El intercambio es una solución efectiva cuando la memoria física no es suficiente para contener todos los procesos. Sin embargo, tiene limitaciones debido al tiempo de procesamiento requerido para mover procesos, gestionar fragmentación y realizar compactación. Esta estrategia sentó las bases para la **memoria virtual**, que ofrece mayor flexibilidad al permitir que procesos se ejecuten parcialmente en memoria, tema que se aborda en la sección siguiente.

### Administración de la memoria libre
Cuando la memoria se asigna dinámicamente, el sistema operativo administra el espacio disponible mediante dos métodos principales: **mapas de bits** y **listas libres**. Cada método tiene ventajas y desventajas según el diseño y las necesidades del sistema.

#### **1. Administración de Memoria con Mapas de Bits**
En este método:
- **División de la memoria**: La memoria se divide en unidades de asignación. Estas unidades pueden ser pequeñas (unas palabras) o grandes (varios kilobytes).
- **Mapa de bits**: Por cada unidad de memoria, existe un bit en el mapa:
    - **0**: Indica que la unidad está libre.
    - **1**: Indica que la unidad está ocupada.

**Ejemplo**: La memoria de la figura 3-6(a) tiene procesos y huecos representados como bloques. Su mapa de bits correspondiente es una secuencia de bits, donde las áreas sombreadas indican unidades libres.

**Diseño del mapa**:
- El tamaño del mapa depende del tamaño de la memoria y de la unidad de asignación.
- Ejemplo: Con unidades de 4 bytes, un mapa de bits requiere 1 bit por cada 4 bytes de memoria. Esto equivale a que el mapa ocupa 1/33 del tamaño total de la memoria.

**Desafíos**:
1. **Búsqueda lenta**: Encontrar un bloque libre de tamaño kk implica buscar en el mapa hasta hallar kk bits consecutivos en 0. Esto puede cruzar límites entre palabras del mapa, volviendo el proceso más lento.
2. **Fragmentación interna**: Si el proceso no ocupa un múltiplo exacto de la unidad de asignación, el espacio sobrante se desperdicia.

![[archivos/imagenes/Pasted image 20241121190131.png]]

#### **2. Administración de Memoria con Listas Ligadas**
En este método:
- **Representación**: La memoria se gestiona como una lista ligada de segmentos. Cada segmento puede ser un proceso o un hueco vacío.
    - **Nodo de la lista**: Contiene información sobre el tipo (proceso o hueco), la dirección inicial, la longitud y un puntero al siguiente segmento.

**Ventajas**:
- La lista se mantiene ordenada por direcciones, lo que facilita actualizaciones cuando un proceso termina o es intercambiado.

**Gestión de huecos**: Cuando un proceso finaliza, su espacio se convierte en un hueco. Esto implica cuatro posibles combinaciones según los vecinos (ver figura 3-7):
1. Un único proceso vecino se reemplaza por un hueco.
2. Dos entradas (un hueco y un proceso) se fusionan.
3. Se eliminan dos entradas y se crea un hueco mayor.
4. Tres entradas (dos huecos y un proceso) se combinan en una sola.

![[archivos/imagenes/Pasted image 20241121190250.png]]

#### **3. Algoritmos de Asignación**
Los algoritmos más comunes son:

1. **Primer Ajuste**:
    - Recorre la lista hasta encontrar el primer hueco suficientemente grande.
    - Es rápido porque no busca más allá del primer hueco adecuado.
2. **Siguiente Ajuste**:    
    - Similar al primer ajuste, pero empieza a buscar desde donde quedó la última búsqueda, no desde el principio.
    - Es ligeramente menos eficiente que el primer ajuste.
3. **Mejor Ajuste**:
    - Busca en toda la lista el hueco más pequeño que sea suficiente.
    - Ventaja: Reduce el desperdicio al dividir grandes huecos innecesariamente.
    - Desventaja: Es más lento y puede fragmentar la memoria con huecos pequeños e inutilizables.
4. **Peor Ajuste**:
    - Selecciona siempre el hueco más grande disponible.
    - Es poco eficiente en la práctica, ya que crea fragmentación rápidamente.
5. **Ajuste Rápido**:
    - Mantiene listas separadas para tamaños comunes (e.g., 4 KB, 8 KB, etc.).
    - Es muy rápido, pero puede causar fragmentación si no se fusionan los huecos vecinos.

---

#### **Optimizaciones**
1. **Listas separadas**:
    - Una lista para procesos y otra para huecos. Esto acelera la asignación pero complica la desasignación.
    - Si la lista de huecos se ordena por tamaño, se optimiza el mejor ajuste.
2. **Información embebida**:
    - En los huecos, se almacena directamente el tamaño y el puntero al siguiente nodo, eliminando la necesidad de estructuras adicionales.

#### Resumen
- **Mapas de bits** son simples y ocupan poca memoria, pero la búsqueda es lenta.
- **Listas libres** son más versátiles, especialmente con algoritmos como el primer o mejor ajuste, aunque pueden ser más complejas de manejar.
- La elección entre ambos métodos depende del balance entre rapidez, eficiencia de memoria y facilidad de implementación.


# Memoria Virtual
La **memoria virtual** es un concepto fundamental en los sistemas operativos modernos que permite a los programas acceder a un espacio de direcciones lógico mayor que la memoria física disponible. Este mecanismo resuelve problemas históricos asociados con la limitación de memoria física y la necesidad de manejar programas que son demasiado grandes para caberen ella.

### Concepto de Memoria Virtual
Introducida en 1961 por Fotheringham, la memoria virtual automatizó este proceso y eliminó la carga de trabajo del programador. La idea básica es que:

- Cada programa tiene su propio **espacio de direcciones lógico**, que es independiente del tamaño de la memoria física.
- Este espacio de direcciones se divide en unidades llamadas **páginas**, que son bloques contiguos de direcciones lógicas.
- Las páginas pueden estar asociadas a la memoria física en un momento dado, pero no todas tienen que estar presentes simultáneamente.

Cuando un programa intenta acceder a una dirección que no está en la memoria física, ocurre un **fallo de página**. En este caso:

1. El hardware detecta la ausencia de la página requerida.
2. El sistema operativo interviene para buscar la página faltante en el disco.
3. La página se carga en la memoria física, y la instrucción que generó el fallo se reintenta.

#### Comparación con Registros Base y Límite
La memoria virtual puede considerarse una evolución de los registros base y límite, que se utilizaban para manejar espacios de direcciones simples. Mientras que estos registros permitían asociar segmentos específicos de un programa (como texto o datos) a ubicaciones fijas de memoria, la memoria virtual extiende este concepto al permitir la asociación dinámica de **todo el espacio de direcciones lógico** en pequeñas unidades (páginas) que se distribuyen a lo largo de la memoria física.

#### Ventajas de la Memoria Virtual
1. **Eficiencia en Sistemas Multiprogramados:** Permite que varias partes de distintos programas estén en la memoria simultáneamente, optimizando el uso de la CPU al cambiar entre procesos mientras las páginas necesarias se cargan desde el disco.
2. **Flexibilidad para Programas Grandes:** Los programas pueden tener un espacio de direcciones lógico mayor que la memoria física sin requerir que el programador los divida manualmente.
3. **Aislamiento y Seguridad:** Cada programa opera en su propio espacio de direcciones lógico, lo que reduce la probabilidad de que un programa afecte a otro.


### **Paginación**
La paginación es una técnica ampliamente utilizada en los sistemas de memoria virtual para gestionar eficientemente la relación entre el espacio de direcciones virtuales y el espacio de memoria física disponible. Este método divide tanto las direcciones virtuales como la memoria física en bloques de tamaño fijo, conocidos como **páginas** y **marcos de página**, respectivamente. A continuación, se explica en detalle el concepto y funcionamiento de la paginación.

#### **Direcciones Virtuales y Físicas**
1. **Direcciones Virtuales**:
    - Las **direcciones virtuales** son generadas por los programas cuando acceden a la memoria. Por ejemplo, una instrucción como `MOV REG, 1000` accede a la dirección virtual 1000.
    - Estas direcciones no corresponden directamente a ubicaciones en la memoria física cuando se utiliza memoria virtual.
    - En cambio, las direcciones virtuales forman el **espacio de direcciones virtuales**, que puede ser mucho mayor que la memoria física disponible.
2. **Direcciones Físicas**:
    - La **memoria física** contiene un espacio de direcciones más limitado. Sin memoria virtual, las direcciones virtuales se colocan directamente en el bus de memoria y se accede a la ubicación física correspondiente.
    - En sistemas con memoria virtual, las direcciones virtuales se transforman en direcciones físicas a través de la **Unidad de Gestión de Memoria (MMU, por sus siglas en inglés)**.

#### **Función de la MMU**
La **MMU** asocia direcciones virtuales con direcciones físicas. Esto se logra mediante una estructura llamada **tabla de páginas**, que contiene:

- Un **índice** basado en el número de página virtual.
- El **marco de página físico** correspondiente.
- Un **bit de presente/ausente**, que indica si la página está cargada en la memoria física.

![[archivos/imagenes/Pasted image 20241202164641.png]]

#### **Estructura de la Paginación**
##### **División en Páginas y Marcos**
- **Páginas**: Unidades del espacio de direcciones virtuales, de tamaño fijo (por ejemplo, 4 KB).
- **Marcos de página**: Bloques equivalentes en la memoria física.
- Por ejemplo, en un sistema con 64 KB de espacio virtual y 32 KB de memoria física:
    - El espacio virtual se divide en **16 páginas** (64 KB ÷ 4 KB).
    - La memoria física se divide en **8 marcos de página** (32 KB ÷ 4 KB).

![[archivos/imagenes/Pasted image 20241202164738.png]]

##### **Tabla de Páginas**
- Asocia cada página virtual a un marco de página físico o marca la página como "no presente".
- En el ejemplo:
    - Solo 8 páginas virtuales pueden estar en memoria física simultáneamente.
    - Las páginas restantes se almacenan en el disco y se cargan según sea necesario.

![[archivos/imagenes/Pasted image 20241202164827.png]]

#### **Transformación de Direcciones**
1. **División de Direcciones Virtuales**:
    - Una dirección virtual se divide en dos partes:
        - **Número de página virtual**: Determina qué página contiene la dirección.
        - **Desplazamiento dentro de la página**: Indica la ubicación exacta dentro de la página.
    - Por ejemplo, una dirección virtual de 16 bits se divide en:
        - 4 bits para el número de página (16 páginas posibles).
        - 12 bits para el desplazamiento (4 KB por página).
2. **Conversión por la MMU**:
    - El número de página virtual se usa como índice en la tabla de páginas.
    - Si la página está presente:
        - Se obtiene el número del marco de página físico.
        - El desplazamiento se combina con este número para formar la dirección física.
    - Si la página no está presente:
        - Ocurre un **fallo de página**.

![[archivos/imagenes/Pasted image 20241202165036.png]]

#### **Fallo de Página y Gestión**
##### **Fallo de Página**
- Si el programa intenta acceder a una página virtual no cargada, la MMU provoca un **trap** al sistema operativo.
- El sistema operativo:
    1. Selecciona un marco de página físico a desalojar (usando técnicas como **LRU**, menos recientemente usado).
    2. Escribe la página desalojada al disco, si ha sido modificada.
    3. Carga la página requerida desde el disco al marco recién liberado.
    4. Actualiza la tabla de páginas para reflejar los cambios.

##### **Ejemplo**:
- Dirección virtual: `32780` (byte 12 dentro de la página virtual 8).
- Si la página virtual 8 no está cargada:
    1. El sistema operativo selecciona un marco físico para liberar.
    2. Carga la página 8 en memoria.
    3. Asocia la página virtual 8 con un marco físico.
    4. Reintenta la operación, ahora accediendo a la dirección física correcta.


![[archivos/imagenes/Pasted image 20241204132639.png]]

#### **Ventajas del Tamaño de Página como Potencia de 2**
- Simplifica el cálculo de la dirección física:
    - Los bits más altos determinan el número de página.
    - Los bits más bajos corresponden al desplazamiento.
- Ejemplo:
    - Dirección virtual `8196` (0010000000000100 en binario):
        - Página virtual: `2` (bits más altos).
        - Desplazamiento: `4` (bits más bajos).
        - La tabla de páginas indica que la página virtual `2` está en el marco físico `6`.
        - Dirección física: `24580`.

---
### **Tablas de Páginas**

#### **División de la Dirección Virtual**

En sistemas con memoria virtual, una dirección virtual consta de dos partes principales:

1. **Número de página virtual:** Representa la página virtual dentro del espacio de direcciones virtuales.
2. **Desplazamiento:** Representa la posición exacta dentro de esa página.

Por ejemplo, en una dirección de 16 bits con páginas de 4 KB:

- Los **4 bits superiores** definen la página virtual, permitiendo identificar hasta 16 páginas.
- Los **12 bits inferiores** representan el desplazamiento dentro de la página, cubriendo las direcciones de 0 a 4095.

La traducción de direcciones implica utilizar el número de página virtual como índice en una tabla de páginas, donde se almacena la asociación entre páginas virtuales y marcos de página físicos.

#### **Función de la Tabla de Páginas**
La **tabla de páginas** actúa como una función que asocia:

- **Entrada:** Número de página virtual.
- **Salida:** Número del marco de página físico.

El resultado se utiliza para reemplazar el campo de página virtual en la dirección virtual con el marco de página físico, formando así una dirección física. Este mecanismo permite que el programa trabaje con un espacio de direcciones virtuales que puede ser más grande que la memoria física disponible.

#### **Estructura de una Entrada en la Tabla de Páginas**
Cada entrada de la tabla de páginas contiene varios campos que ayudan al sistema a manejar la traducción y la gestión de memoria. Una entrada típica tiene un tamaño común de **32 bits** y puede incluir los siguientes elementos:

1. **Número de Marco de Página:**
    
    - Es el valor clave que permite asociar una página virtual con un marco físico.
    - Es el principal objetivo de la tabla.
2. **Bit de Presente/Ausente:**
    
    - Indica si la página virtual está actualmente cargada en la memoria física.
    - Si el bit está en `0`, acceder a esa página genera un **fallo de página**, desencadenando una acción del sistema operativo.
3. **Bits de Protección:**
    
    - Determinan los permisos de acceso.
    - Configuración básica:
        - `0`: Lectura/escritura.
        - `1`: Solo lectura.
    - Configuración avanzada: Permisos separados para lectura, escritura y ejecución.
4. **Bit de Modificada (o Sucia):**
    
    - Se establece automáticamente cuando una página se modifica.
    - Ayuda al sistema operativo a decidir si es necesario escribir la página de vuelta al disco antes de reemplazarla.
5. **Bit de Referenciada:**
    
    - Se marca cuando una página se utiliza (ya sea para lectura o escritura).
    - Es crucial para los **algoritmos de reemplazo de páginas**, ya que indica qué páginas están activamente en uso.
6. **Bit para Deshabilitar Caché:**
    
    - Utilizado para páginas asociadas a dispositivos de entrada/salida (E/S) en lugar de memoria convencional.
    - Garantiza que las operaciones se realicen directamente con el dispositivo y no con datos obsoletos en la caché.

![[archivos/imagenes/Pasted image 20241202170713.png]]

#### **Consideraciones Importantes**
1. **Fallo de Página y Manejador de Disco:**
    
    - La tabla de páginas no incluye información sobre la ubicación en disco de una página no cargada.
    - Esa información la gestiona el sistema operativo en sus propias estructuras de datos.
2. **Memoria Virtual como Abstracción:**
    
    - La memoria virtual abstrae la memoria física, permitiendo que los programas operen en un espacio de direcciones uniforme.
    - Similar a cómo los procesos abstraen la CPU, las tablas de páginas y la memoria virtual crean una ilusión de memoria ilimitada.
3. **Tamaño de Página como Potencia de Dos:**
    
    - Facilita la división de direcciones y la traducción mediante operaciones simples de bits.
    - Ejemplo: Con 4 KB por página, los 12 bits inferiores de una dirección virtual corresponden siempre al desplazamiento.


### Aceleración de la paginación
La **paginación** en sistemas operativos es un mecanismo que permite usar la memoria de forma eficiente mediante la asociación de direcciones virtuales a direcciones físicas. Para **acelerarla**, se introducen técnicas y hardware especializado que minimizan los costos asociados a este proceso. Una de las herramientas más importantes para lograrlo es el **Translation Lookaside Buffer (TLB)**.

#### **¿Qué es el TLB?**
El **Translation Lookaside Buffer (TLB)** es una pequeña memoria caché de hardware, integrada generalmente en la **Unidad de Manejo de Memoria (MMU)**. Su función es almacenar temporalmente las traducciones más recientes entre direcciones virtuales y físicas. Esto evita tener que acceder continuamente a la tabla de páginas principal en la memoria, que es un proceso lento.

#### **Funcionamiento del TLB**
1. **Consulta de direcciones virtuales:**
    
    - Cuando la CPU necesita traducir una dirección virtual a una dirección física, primero consulta el TLB.
    - Si la dirección está en el TLB (**acierto en el TLB**), la traducción ocurre directamente en nanosegundos.
    - Si no está en el TLB (**fallo en el TLB**), el sistema busca la entrada correspondiente en la tabla de páginas en la memoria principal y actualiza el TLB con esta nueva entrada.
2. **Gestión de entradas:**
    
    - Cada entrada del TLB contiene:
        - Número de página virtual.
        - Marco de página física correspondiente.
        - Bits de control, como el bit de **protección** (lectura/escritura/ejecución) y el bit **modificado** (indica si la página fue escrita).
    - Si una página es reemplazada en el TLB (por un fallo), el bit modificado se copia de vuelta a la tabla de páginas para mantener la coherencia.

#### **¿Cómo acelera la paginación el TLB?**
1. **Reducción de accesos a la tabla de páginas:**
    
    - Sin un TLB, cada referencia de memoria requeriría al menos un acceso adicional a la tabla de páginas en memoria principal, lo cual es lento.
    - Con el TLB, una gran proporción de estas referencias puede resolverse directamente en el hardware, sin acceder a la memoria principal.
2. **Principio de localidad:**
    
    - Los programas tienden a acceder repetidamente a un subconjunto pequeño de páginas durante un periodo corto (localidad espacial y temporal). Esto significa que una caché pequeña como el TLB puede ser altamente efectiva.
3. **Velocidad de hardware:**
    
    - El TLB opera con velocidades similares a la de la CPU, lo que evita que la traducción de direcciones sea un cuello de botella.


#### **Tipos de fallos en el TLB**
1. **Fallo suave:**
    
    - La página no está en el TLB, pero sí en la memoria principal.
    - Solución: actualizar el TLB con la entrada correspondiente. Este proceso toma unas pocas decenas de instrucciones y nanosegundos.
2. **Fallo duro:**
    
    - La página no está ni en el TLB ni en la memoria principal.
    - Solución: cargar la página desde el disco al marco de memoria adecuado y luego actualizar el TLB. Este proceso es mucho más lento, ya que implica operaciones de E/S de disco y puede tardar varios milisegundos.


#### **Optimización del uso del TLB**
1. **Precarga de páginas:**
    
    - El sistema operativo puede anticiparse y cargar entradas al TLB antes de que sean necesarias, basado en patrones de uso del programa.
2. **Estrategias de reemplazo:**
    
    - Cuando el TLB está lleno, utiliza algoritmos como **Least Recently Used (LRU)** para decidir qué entrada reemplazar.
3. **Caché de software para el TLB:**
    
    - Algunas máquinas mantienen una pequeña caché de entradas de tabla de páginas gestionada por software en memoria fija. Esto ayuda a reducir fallos adicionales durante la resolución de un fallo en el TLB.



### Tablas de páginas para memorias extensas
#### **1. Tablas de páginas multinivel**

Este método organiza las tablas de páginas en niveles jerárquicos para manejar eficientemente espacios de direcciones grandes sin cargar tablas innecesarias en memoria.

##### **Cómo funcionan:**

1. **Dirección virtual particionada:**  
    Una dirección virtual de 32 bits se divide en:
    
    - **TP1 (10 bits):** Índice para la tabla de páginas de nivel superior.
    - **TP2 (10 bits):** Índice para una tabla de segundo nivel.
    - **Desplazamiento (12 bits):** Define la posición dentro de una página (tamaño de página = 4 KB).
2. **Jerarquía de tablas:**
    
    - La tabla de nivel superior tiene **1024 entradas (2¹⁰)**, y cada entrada apunta a una tabla de segundo nivel.
    - Cada tabla de segundo nivel también tiene **1024 entradas** y cubre un espacio de direcciones de **4 MB** (1024 páginas de 4 KB).
3. **Ejemplo:**
    
    - Si la dirección virtual es `0x00403004`:
        - **TP1 = 1**: Selecciona la segunda entrada de la tabla de nivel superior (espacio de 4 MB a 8 MB).
        - **TP2 = 2**: Selecciona la tercera entrada de la tabla de segundo nivel dentro de este espacio.
        - **Desplazamiento = 4**: Define la posición dentro de la página.
    - La dirección física resultante se obtiene combinando el marco de página y el desplazamiento.
4. **Ventajas:**
    
    - Sólo las tablas necesarias están en memoria, ahorrando espacio.
    - Es eficiente para procesos con huecos grandes en su espacio de direcciones.
5. **Escalabilidad:**
    
    - Se puede extender a tres o más niveles para manejar espacios aún mayores (por ejemplo, sistemas de 64 bits).

![[archivos/imagenes/Pasted image 20241204135457.png]]

#### **2. Tablas de páginas invertidas**

Este método es más adecuado para direcciones virtuales de 64 bits, donde las tablas tradicionales serían demasiado grandes.

##### **Cómo funcionan:**

1. **Estructura:**
    
    - En lugar de una entrada por página virtual, hay una entrada por **marco de página físico**.
    - Cada entrada almacena la relación `(proceso, página virtual)` que ocupa ese marco físico.
2. **Ejemplo de ahorro de espacio:**
    
    - En un sistema de 64 bits con 1 GB de RAM y páginas de 4 KB:
        - Una tabla tradicional requeriría **2⁵² entradas**, lo cual es inmenso.
        - Una tabla invertida solo necesita **262,144 entradas** (una por marco de 4 KB en 1 GB de RAM).
3. **Desafío:**
    
    - La traducción de direcciones virtuales a físicas es más compleja porque no se puede usar el índice directamente.
    - Requiere buscar en la tabla invertida la entrada `(proceso, página virtual)` para encontrar el marco físico.
4. **Optimización con hash:**
    
    - Se usa una **tabla hash** para acelerar las búsquedas.
    - Las direcciones virtuales con el mismo valor de hash se agrupan en una lista encadenada.
    - Una vez encontrado el marco físico, se almacena en el **TLB** para futuras referencias rápidas.
5. **Ventajas:**
    
    - Reduce significativamente el espacio necesario para las tablas.
    - Es práctico para sistemas con direcciones de 64 bits y grandes espacios de direcciones virtuales.

![[archivos/imagenes/Pasted image 20241204135523.png]]

#### **Comparación entre ambos métodos:**

|**Aspecto**|**Tablas multinivel**|**Tablas invertidas**|
|---|---|---|
|**Espacio requerido**|Crece con el espacio de direcciones virtuales.|Proporcional al tamaño de la memoria física.|
|**Búsqueda**|Rápida, usando índices jerárquicos.|Más lenta, requiere buscar en la tabla invertida.|
|**Uso del TLB**|Acelera las traducciones de direcciones.|Fundamental para compensar búsquedas lentas.|
|**Aplicación típica**|Sistemas de 32 bits o direcciones no muy grandes.|Sistemas de 64 bits con grandes espacios virtuales.|

---

En resumen, las **tablas multinivel** son eficientes para direcciones de tamaño moderado al evitar mantener toda la tabla en memoria, mientras que las **tablas invertidas** son necesarias para direcciones de 64 bits debido al inmenso tamaño de las tablas tradicionales. Ambos métodos usan el **TLB** para acelerar el acceso a direcciones.


### Algoritmos de reemplazo de páginas
El **algoritmo de reemplazo de páginas óptimo (OPT)** es un modelo teórico que se utiliza como referencia para evaluar la eficacia de otros algoritmos de reemplazo de páginas. Aunque es imposible implementarlo en un sistema práctico, es útil para comparar su rendimiento con algoritmos realizables.

#### ¿Cómo funciona el algoritmo?

1. **Definición del objetivo:** El algoritmo busca minimizar los fallos de página en el futuro.
2. **Decisión basada en el futuro:**
    - Cada página en memoria se etiqueta con el número de instrucciones que se ejecutarán antes de que esa página sea referenciada de nuevo.
    - Cuando ocurre un fallo de página, el algoritmo selecciona para desalojar la página con la **etiqueta más alta**, es decir, aquella que no será utilizada hasta más adelante en el futuro.

#### Ejemplo:

Imagina que tienes 3 marcos de página y una secuencia de referencias de páginas:  
A, B, C, A, D, B, A, E, C.

1. **Estado inicial:** Los marcos están vacíos.
    
    - **A** se carga en el primer marco. (Fallo de página)
    - **B** se carga en el segundo marco. (Fallo de página)
    - **C** se carga en el tercer marco. (Fallo de página)
2. **Referencia a A:** A ya está en memoria. (Sin fallo)
    
3. **Referencia a D:** La memoria está llena, se debe reemplazar una página.
    
    - Las etiquetas son:
        - A: Se usará en la posición 6.
        - B: Se usará en la posición 6.
        - C: Se usará en la posición 8.
    - El algoritmo elige **C** porque será usada más adelante.  
        **D** reemplaza a **C**. (Fallo de página)
4. Y así sucesivamente, el algoritmo siempre decide basándose en cuándo se necesitará cada página.
    

#### ¿Por qué no es implementable?

El problema principal es que el sistema operativo **no puede prever el futuro**. Al momento de un fallo de página, no sabe cuál será la próxima referencia a cada página. Sin embargo, se puede simular usando un **rastreo previo** de las referencias, lo cual solo es posible en un entorno controlado, como durante una simulación para comparar algoritmos.

#### Usos del algoritmo óptimo

- **Evaluación de rendimiento:** Sirve como punto de referencia para medir qué tan cerca está un algoritmo práctico del óptimo.
- **Simulación:** Se puede usar en simuladores para determinar la secuencia ideal de reemplazos para un programa y entrada específica.


### Explicación del Algoritmo **NRU (Not Recently Used)**

El algoritmo **NRU** es un método práctico y eficiente para seleccionar qué página desalojar en caso de un fallo de página. Utiliza dos bits de estado asociados a cada página en la tabla de páginas:

- **R (Referenciada):** Indica si la página fue referenciada (lectura o escritura) recientemente.
- **M (Modificada):** Indica si la página fue modificada (escrita) mientras estaba en memoria.

#### ¿Cómo funciona el NRU?

1. **Clasificación de las páginas en 4 clases:**
    
    - Las páginas se clasifican según los valores de sus bits **R** y **M** en las siguientes categorías:
        - **Clase 0:** R = 0, M = 0 (No referenciada ni modificada).
        - **Clase 1:** R = 0, M = 1 (No referenciada, pero modificada).
        - **Clase 2:** R = 1, M = 0 (Referenciada, pero no modificada).
        - **Clase 3:** R = 1, M = 1 (Referenciada y modificada).
2. **Selección de la página a eliminar:**
    
    - Se elige una página al azar de la **clase de menor numeración que no esté vacía**.
    - Esto implica la siguiente prioridad para ser desalojadas:
        1. **Clase 0:** Estas páginas son las menos costosas de eliminar (no referenciadas ni modificadas).
        2. **Clase 1:** Moderadamente costosas, ya que requieren ser escritas al disco antes de eliminarlas.
        3. **Clase 2:** Son páginas de uso frecuente, pero no modificadas, por lo que tienen menor prioridad.
        4. **Clase 3:** Son las más costosas de eliminar porque son de uso frecuente y están modificadas.
3. **Actualización periódica del bit R:**
    
    - En cada **interrupción de reloj**, el sistema operativo **borra el bit R** de todas las páginas.
    - Esto permite distinguir entre las páginas que han sido referenciadas recientemente y las que no.
    - El bit **M** no se borra automáticamente porque se necesita para saber si una página modificada debe escribirse al disco.

#### Ejemplo:

Supongamos que tenemos las siguientes páginas en memoria con sus bits R y M:

|Página|R|M|Clase|
|---|---|---|---|
|A|0|0|0|
|B|0|1|1|
|C|1|0|2|
|D|1|1|3|

Si ocurre un fallo de página:

1. El algoritmo busca una página en la clase más baja:
    
    - Encuentra que la página **A** (Clase 0) es elegible para ser desalojada.
    - Si no hubiera páginas en Clase 0, seleccionaría al azar una página de Clase 1, y así sucesivamente.
2. **Desaloja la página A**, ya que es la menos costosa.
    

#### Ventajas del NRU:

- **Eficiencia razonable:** Aunque no es óptimo, proporciona un buen rendimiento.
- **Facilidad de implementación:** Utiliza información simple (bits R y M).
- **Priorización inteligente:** Intenta minimizar el coste al desalojar páginas menos importantes.

#### Limitaciones del NRU:

- **Decisión aleatoria dentro de una clase:** No utiliza ningún criterio adicional para elegir entre páginas de la misma clase.
- **No es óptimo:** No considera patrones de uso futuro, a diferencia del algoritmo teórico óptimo.


### Explicación del Algoritmo **FIFO (First-In, First-Out)**

El algoritmo **FIFO** es uno de los métodos más simples para la gestión de reemplazo de páginas en sistemas de memoria virtual. Su funcionamiento se basa en una estructura de lista que almacena las páginas en el orden en que ingresaron a la memoria.

#### Funcionamiento del Algoritmo FIFO

1. **Lista ordenada por tiempo de llegada:**
    
    - El sistema operativo mantiene una lista de todas las páginas en memoria.
    - Las páginas se agregan al **final de la lista** cuando se cargan en memoria.
    - La página que se encuentra en el **frente de la lista** es la que lleva más tiempo en memoria.
2. **Mecanismo de reemplazo:**
    
    - Cuando ocurre un **fallo de página** (la página requerida no está en memoria):
        1. **Elimina** la página del frente de la lista (la más antigua).
        2. **Agrega** la nueva página al final de la lista.

#### Ejemplo

Supongamos que tenemos 3 marcos de página disponibles y la siguiente secuencia de referencias a páginas: **A, B, C, D, A, B, E, D, C, A**.

- Al inicio, la memoria está vacía.
- Aplicamos FIFO para reemplazo de páginas:

|Referencia|Estado de la Memoria|Página Eliminada|Fallo de Página|
|---|---|---|---|
|A|A|-|Sí|
|B|A, B|-|Sí|
|C|A, B, C|-|Sí|
|D|B, C, D|A|Sí|
|A|C, D, A|B|Sí|
|B|D, A, B|C|Sí|
|E|A, B, E|D|Sí|
|D|B, E, D|A|Sí|
|C|E, D, C|B|Sí|
|A|D, C, A|E|Sí|

**Total de fallos de página:** 10.

#### Problemas de FIFO

1. **Reemplazo no inteligente:**
    
    - FIFO elimina la página que lleva más tiempo en memoria, sin importar si ha sido referenciada recientemente o si es probable que se necesite pronto.
    - Esto puede llevar a la eliminación de páginas importantes, afectando el rendimiento.
2. **Anomalía de Belady:**
    
    - En algunos casos, agregar más marcos de página puede **incrementar** el número de fallos de página, algo contraintuitivo.
    - Este fenómeno se llama **anomalía de Belady** y ocurre porque FIFO no toma en cuenta patrones de acceso.

#### Ventajas de FIFO

- **Simplicidad:** Es fácil de implementar y mantener.
- **Baja sobrecarga:** No requiere estadísticas ni bits adicionales.

#### Limitaciones de FIFO

- **Rendimiento subóptimo:** No considera patrones de acceso ni el estado reciente de las páginas.
- **Poco adaptable:** No distingue entre páginas frecuentemente usadas y poco usadas.


### **Algoritmo de Segunda Oportunidad**

El **algoritmo de segunda oportunidad** es una mejora sobre **FIFO** que evita reemplazar páginas frecuentemente utilizadas. Lo hace al evaluar el bit de referencia (**R**) de la página más antigua antes de decidir si debe ser desalojada.

#### **Funcionamiento**

1. **Lista de páginas:**  
    Se mantiene una lista de las páginas en memoria, ordenadas según su tiempo de llegada, como en FIFO.
    
2. **Inspección del bit R:**
    
    - Cuando ocurre un fallo de página, se examina la página más antigua.
    - Si el bit **R** es **0**, significa que la página no ha sido referenciada recientemente, por lo que es desalojada.
    - Si el bit **R** es **1**, indica que la página ha sido referenciada. En este caso:
        - El bit **R** se desactiva (se pone en 0).
        - La página se mueve al **final de la lista**, simulando que acaba de llegar a la memoria.
        - Se continúa inspeccionando la siguiente página.
3. **Iteración continua:**
    
    - El proceso se repite hasta encontrar una página con **R = 0**, que será la página desalojada.

#### **Ejemplo**

Supongamos que tenemos las páginas **A, B, C, D** en memoria, en ese orden de llegada, y ocurre un fallo de página al intentar cargar **E**. Los valores de **R** son los siguientes:

|Página|R (Bit de referencia)|
|---|---|
|A|1|
|B|0|
|C|1|
|D|0|

- Se inspecciona **A**:
    
    - **R = 1**, así que se pone **R = 0** y se mueve al final de la lista.
- Se inspecciona **B**:
    
    - **R = 0**, por lo que **B** se desaloja y **E** ocupa su lugar.

Nuevo estado de memoria: **C, D, A, E**.

![[archivos/imagenes/Pasted image 20241205110145.png]]


### **Algoritmo del Reloj**

El **algoritmo del reloj** es una optimización del algoritmo de segunda oportunidad que organiza las páginas en una **estructura circular** similar a un reloj.

#### **Funcionamiento**

1. **Estructura circular:**
    
    - Las páginas se almacenan en una lista circular.
    - Una "manecilla" apunta a la página más antigua.
2. **Inspección del bit R:**
    
    - Cuando ocurre un fallo de página, se inspecciona la página señalada por la manecilla:
        - Si **R = 0**, se reemplaza con la nueva página y la manecilla avanza a la siguiente posición.
        - Si **R = 1**, el bit **R** se pone en **0** y la manecilla avanza a la siguiente página.
3. **Iteración:**
    
    - Este proceso se repite hasta encontrar una página con **R = 0**.

#### **Ejemplo**

Supongamos que tenemos un reloj con las páginas **A, B, C, D** y los bits **R** como sigue:

|Página|R (Bit de referencia)|
|---|---|
|A|1|
|B|1|
|C|0|
|D|1|

La manecilla apunta inicialmente a **A**:

- Inspecciona **A**:
    
    - **R = 1**, se pone **R = 0** y la manecilla avanza.
- Inspecciona **B**:
    
    - **R = 1**, se pone **R = 0** y la manecilla avanza.
- Inspecciona **C**:
    
    - **R = 0**, se reemplaza con la nueva página.

Nuevo estado del reloj: **E, B, D, A** (la manecilla ahora apunta a **B**).

---
![[archivos/imagenes/Pasted image 20241205110528.png]]


### LRU
El algoritmo **LRU (Least Recently Used)** es una técnica de reemplazo de páginas que intenta aproximar el comportamiento del algoritmo óptimo, basándose en la idea de que las páginas que se han usado recientemente probablemente se volverán a usar pronto. Aquí tienes un resumen de los puntos clave y las implementaciones descritas:

#### **Definición del algoritmo LRU**

- **Principio**: Descarta la página que no se haya utilizado durante el período más largo de tiempo.
- **Fundamento**: Las páginas que no se han usado en mucho tiempo probablemente seguirán sin usarse por un tiempo más.


#### **Implementaciones del algoritmo**

##### **1. Lista enlazada**

- **Descripción**: Mantener una lista enlazada de páginas en memoria.
    - **Más reciente**: La página más usada recientemente se coloca al frente.
    - **Menos reciente**: La página menos usada se coloca al final.
- **Desventaja**: Cada acceso a memoria requiere buscar la página, moverla al frente y actualizar la lista, lo cual es costoso.


##### **2. Contador con hardware especial**

- **Descripción**:
    1. Se utiliza un contador global (C) que se incrementa automáticamente con cada instrucción.
    2. Cada entrada de la tabla de páginas tiene un campo para almacenar el valor actual de C cuando la página es referenciada.
    3. En caso de fallo de página, el sistema operativo inspecciona los contadores y descarta la página con el menor valor.
- **Ventaja**: Implementación más directa.
- **Desventaja**: Requiere hardware adicional (un contador y espacio extra en la tabla de páginas).

---

##### **3. Matriz de bits**

- **Descripción**:
    - Para un sistema con nn marcos de página, se utiliza una matriz de n×nn \times n bits.
    - **Reglas**:
        1. Al referenciar la página kk, se ponen en 1 todos los bits de la fila kk y en 0 todos los de la columna kk.
        2. La fila cuyo valor binario sea el menor representa la página menos usada recientemente.
- **Ejemplo**:
    - Con 4 páginas y referencias: 0, 1, 2, 3, 2, 1, 0, 3, 2, 3, se genera una matriz que evoluciona con cada referencia.
    - La fila con el valor más bajo binario indica cuál página descartar.
- **Ventaja**: Permite ordenar fácilmente las páginas por antigüedad de uso.
- **Desventaja**: Requiere hardware especial y memoria adicional para la matriz.

---

#### **Ventajas y desventajas del LRU**

- **Ventajas**:
    - Proporciona un buen rendimiento en términos de tasas de fallos de página.
    - Se aproxima bien al algoritmo óptimo.
- **Desventajas**:
    - Requiere un soporte de hardware considerable para implementaciones eficientes.
    - Las aproximaciones puramente por software son lentas debido a los costos de mantenimiento de estructuras como listas.

![[archivos/imagenes/Pasted image 20241205110818.png]]




### Algoritmo de envejecimiento:

1. **Inicialización**:
    
    - Cada página tiene un contador asociado, inicializado en 0.
    - El hardware mantiene un bit de referencia (**R**) por página, que se establece en 1 si la página es accedida.
2. **Ciclo en cada pulso de reloj**:
    
    - **Desplazamiento del contador**: Los contadores de todas las páginas se desplazan 1 bit a la derecha.
    - **Actualización con el bit R**: El valor de **R** se inserta en el bit más significativo (izquierda) del contador.
    - **Reinicio de R**: El bit **R** se pone en 0 para comenzar el siguiente ciclo.
3. **Selección de página para reemplazo**:
    
    - Cuando ocurre un fallo de página, se selecciona la página con el **contador menor** para ser reemplazada.
    - En caso de empate, se elige cualquiera de las páginas empatadas.

![[archivos/imagenes/Pasted image 20241205111806.png]]

#### Ventajas:

- **Aproximación al LRU**: Las páginas con contadores mayores son aquellas más usadas recientemente, simulando el comportamiento de LRU.
- **Eficiencia**: Sólo requiere actualizar contadores en cada interrupción de reloj, lo que es computacionalmente manejable.
- **Control del horizonte temporal**: Los contadores tienen un límite de bits (por ejemplo, 8), lo que permite ignorar referencias demasiado antiguas.

#### Limitaciones:

1. **Granularidad temporal**:
    
    - No distingue entre dos accesos que ocurren dentro del mismo intervalo de reloj.
    - Puede cometer errores en la selección si dos páginas tienen contadores idénticos.
2. **Horizonte limitado**:
    
    - Si dos páginas tienen contadores en 0, no es posible distinguir si fueron referenciadas recientemente o hace mucho tiempo.
3. **Resolución**:
    
    - La precisión depende de la frecuencia del reloj y el tamaño del contador. Por ejemplo, con un pulso cada 20 ms y un contador de 8 bits, el algoritmo recuerda referencias hasta 160 ms atrás.

En términos prácticos, el algoritmo de envejecimiento es útil porque mantiene un balance entre precisión y eficiencia, aunque no sea tan exacto como LRU puro.


### WS
El algoritmo del conjunto de trabajo es un enfoque eficiente para manejar el reemplazo de páginas en sistemas de memoria virtual. A continuación, se resumen los conceptos clave y el funcionamiento de este algoritmo:

#### **Conceptos principales**

1. **Conjunto de trabajo**:
    
    - Es el conjunto de páginas que un proceso necesita en un momento dado para ejecutarse con pocos fallos de página.
    - Se define como las páginas referenciadas en las últimas kk referencias a memoria o dentro de un periodo de tiempo τ\tau.
2. **Localidad de referencia**:
    
    - Los procesos suelen acceder a un subconjunto pequeño de páginas repetidamente durante un periodo específico, cambiando lentamente con el tiempo.
3. **Paginación bajo demanda**:
    
    - Las páginas solo se cargan cuando se necesitan, lo que minimiza la carga inicial, pero puede causar fallos de página frecuentes al principio.
4. **Prepaginación**:
    
    - El sistema intenta anticiparse a las páginas que un proceso necesitará al reanudar su ejecución, cargando previamente las páginas del conjunto de trabajo.
5. **Thrashing (sobrepaginación)**:
    
    - Ocurre cuando un proceso genera demasiados fallos de página debido a que su conjunto de trabajo no cabe en la memoria disponible.

![[archivos/imagenes/Pasted image 20241205112322.png]]

#### **Funcionamiento del algoritmo del conjunto de trabajo**

1. **Estructura requerida**:
    
    - Una tabla de páginas con:
        - Tiempo de último uso de cada página.
        - Bit RR (referenciada), que indica si la página fue usada durante el pulso de reloj actual.
2. **Proceso del algoritmo**:
    
    - Se ejecuta en cada fallo de página:
        1. Se exploran las páginas en memoria.
        2. Si R=1R = 1:
            - Actualizar el tiempo de último uso con el tiempo virtual actual.
        3. Si R=0R = 0:
            - Calcular la edad de la página: edad=tiempo actual−tiempo de uˊltimo uso\text{edad} = \text{tiempo actual} - \text{tiempo de último uso}.
            - Si edad>τ\text{edad} > \tau, la página ya no está en el conjunto de trabajo y puede ser reemplazada.
            - Si edad≤τ\text{edad} \leq \tau, reservar la página como potencial candidata, priorizando la más antigua (menor tiempo de último uso).
3. **Desalojo de páginas**:
    
    - Si se encuentra una página fuera del conjunto de trabajo, se reemplaza.
    - Si todas las páginas están en el conjunto de trabajo:
        - Seleccionar la más antigua con R=0R = 0.
        - Si todas tienen R=1R = 1, elegir una al azar, preferiblemente una página limpia (no modificada).
4. **Interrupciones periódicas**:
    
    - Se ejecuta un proceso para borrar el bit RR de todas las páginas en cada pulso de reloj, lo que permite determinar si han sido referenciadas recientemente.

![[archivos/imagenes/Pasted image 20241205112341.png]]

#### **Ventajas y desafíos**

**Ventajas**:

- Reduce significativamente los fallos de página al mantener el conjunto de trabajo en memoria.
- Se adapta dinámicamente a los cambios en el comportamiento de los procesos.

**Desafíos**:

- El cálculo exacto del conjunto de trabajo puede ser costoso en términos de tiempo y recursos.
- Requiere mecanismos de hardware y software para mantener información precisa sobre las páginas (como el bit RR y el tiempo de último uso).

En conclusión, el modelo del conjunto de trabajo equilibra el uso eficiente de la memoria y el rendimiento de los procesos, convirtiéndolo en un enfoque esencial para sistemas multiprogramados.

### WS Clock
El algoritmo **WSClock** es una mejora al algoritmo del conjunto de trabajo, utilizando la estructura de un reloj circular para decidir qué página reemplazar. Este método es más eficiente que el conjunto de trabajo básico al evitar recorrer toda la tabla de páginas en cada fallo de página. A continuación, se resumen los pasos principales del algoritmo WSClock:

#### **Estructura del WSClock**

- **Lista circular de marcos de página**:
    - Cada entrada contiene:
        - **Bit R (referenciado)**: Indica si la página ha sido accedida recientemente.
        - **Tiempo de último uso**: Utilizado para calcular la "edad" de la página.
        - **Bit M (modificado)**: Indica si la página ha sido modificada (no siempre se muestra explícitamente en el algoritmo básico).

#### **Proceso del algoritmo WSClock**

1. **Revisión inicial**:
    
    - La manecilla apunta a una página.
    - Si el bit **R = 1**, la página se considera activa (parte del conjunto de trabajo):
        - Se pone **R = 0** y la manecilla avanza al siguiente marco.
        - Repite este proceso con las siguientes páginas.
2. **Página con R = 0**:
    
    - Se analiza si la página está **fuera del conjunto de trabajo**:
        - Si la **edad** (tiempo desde el último uso) es mayor que un umbral **τ**:
            - **Página limpia**: Se reemplaza directamente (ya tiene copia válida en disco).
            - **Página sucia**: Se programa para escritura en disco, pero la búsqueda continúa con la siguiente página.
3. **Escrituras planificadas**:
    
    - Si una página sucia se programa para escritura, el algoritmo sigue avanzando hasta encontrar una página limpia para reemplazo inmediato.
    - Para limitar la cantidad de escrituras, se puede establecer un **máximo de n escrituras** por ciclo.
4. **Ciclo completo del reloj**:
    
    - **Caso 1**: Se han planificado escrituras.
        - Se espera a que termine al menos una escritura.
        - La primera página limpia encontrada se usa como reemplazo.
    - **Caso 2**: No se han planificado escrituras.
        - Si todas las páginas están en el conjunto de trabajo:
            - Se reemplaza una página limpia (si existe).
            - Si no hay páginas limpias, se selecciona la página actual como víctima y se escribe en disco.


![[archivos/imagenes/Pasted image 20241205112701.png]]

#### **Ventajas del WSClock**

- **Eficiencia**: Reduce el recorrido completo de la tabla de páginas al utilizar una estructura circular.
- **Flexibilidad**: Integra decisiones basadas en el estado del bit R, la edad de la página y el estado (limpia o sucia).
- **Reducción del tráfico de disco**: Minimiza escrituras innecesarias al planificar solo páginas sucias.

#### **Desventajas**

- **Sobrecarga de planificación**: Puede ser más complejo implementar la gestión de escrituras en sistemas de tiempo real.
- **Dependencia de parámetros**: El rendimiento depende del ajuste correcto del umbral **τ** y el límite de escrituras.

En general, WSClock es un algoritmo ampliamente utilizado debido a su buen rendimiento y simplicidad relativa en comparación con otros algoritmos de reemplazo más complejos.


### RESUMEN
![[archivos/imagenes/Pasted image 20241205112726.png]]


# Cuestiones de Diseño para los Sistemas de Paginación