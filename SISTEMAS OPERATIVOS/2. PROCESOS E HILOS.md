# Concepto de Proceso
Un **proceso** es la abstracción de un **programa en ejecución**. Cada proceso tiene sus propias direcciones virtuales, en las que tiene su código, datos, pila, registros y más, a los que solo él tiene acceso.

Por eso, cuando se lanza a ejecutar un programa ejecutable, este pasa a ser un **proceso**. Son difíciles de de manejar porque suele haber muchos procesos vivos sin importar el número de CPUs que tenga, ya que todos se pelean por ejecutarse.

Si hay solo una CPU, no hay ejecución concurrente debido a que solo se puede ejecutar un proceso. Puede parecer que es paralelo, pero el usuario no percibe que se ejecutan cada pocos milisegundos varios trozos de diferentes procesos. Esto se llama **pseudoparalelismo**.

A lo largo del tiempo se ejecutan varias partes de los procesos de forma secuencial. Cuando un proceso no haya terminado su ejecución antes de haber perdido la CPU, cuando sea posible se reanudara en el mismo punto que esta antes del **cambio de contexto** . EL usuario tendrá la sensación de que se ejecutan en paralelo, por lo que los cambios de contexto se hacen de forma transparente al usuario.

![[archivos/imagenes/Pasted image 20240926185935.png]]

Cuando hay un **cambio de contexto**, el sistema operativo tiene que almacenar el contenido de todos los registros en memoria del proceso que tenía la CPU. De este forma hay varios **contadores de programa** lógicos en la memoria, aunque solo haya  un registro físico. De esta forma cuando el proceso tiene la oportunidad de continuar sus ejecución, esta se retoma desde el **punto exacto** en el que se quedó cuando perdió la CPU, ademas de recuperar todos los valores de los registros.
Además el **SO** debe planificar cuál va a ser el siguiente proceso en obtener la CPU y recupera de memoria todo lo necesario para su ejecución.

Un **programa** es un fichero que contiene las instrucciones y estructuras necesarias para la ejecución, que es un **ejecutable**(*en código máquina*). Un **proceso** es ese programa en ejecución con toda la información del fichero cargada en el espacio virtual que se creó para él.

En la zona de **kernel** de la memoria hay una tabla llamada **tabla de procesos**. Esta almacena toda la información sobre todos los procesos que están vivos en el sistema.
![[archivos/imagenes/Pasted image 20240930203415.png]]

En la siguiente imagen podemos ver un ejemplo de los pasos que realiza un proceso en su ejecución:
![[archivos/imagenes/Pasted image 20240930203459.png]]
Cada una de las cajas representa cada una de las **instrucciones del proceso**, leyéndose de abajo a arriba. En el **stack** se van almacenando los datos que va usando el proceso y cuando se hace un salto en la rutina se debe guardar también la **dirección de retorno** para cuando se termine la **subrutina**.
A continuación, se mete en un registro el **código**, que en realidad es un número, de la función que se ha llamado para después hacer la llamada al **sistema o trap**. Esta llamada implica pasar a la **zona núcleo o kernel.**
Una vez allí, primero se pasa por el **despachador o *handler* del kernel**, encargado de ver que código hay en el **registro.** Usando esto se accede a una línea de una tabla donde están los punteros a las funciones. A través del **puntero** se va al código concreto seleccionado. Al terminar de ejecutarse el código vuelve al modo usuario y se hacen los retornos necesarios.

A pesar de que los procesos son entidades independientes y no comparten información entre sí, se puede establecer **interacciones** entre ellos, a través de **señales, mensajes o usando memoria compartida.** Normalmente se utilizan ficheros en el disco duro a los que los procesos pueden acceder, de forma que actualizan información en el fichero y avisan a los procesos interesados del cambio para que lo lean.

# Gestión de Procesos
Muchos de los procesos se crean en el arranque del sistema y la mayoría de ellos se ejecutan en **segundo plano** (*no tienen salida visible para el usuario*). Entre ellos están los **demonios**, que son **procesos del kernel con permisos que los de usuario no tienen.**
Otra forma de crear procesos son creándolos desde otro proceso o siendo creados por el usuario.

Algunas de las funciones más comunes a la hora de manejar procesos: 
```Bash
pid = fork( ): Crea un proceso hijo idéntico al padre
pid = waitpid(pid, &statloc, opts): Espera a que un hijo termine
s = execve(name, argv, envp): Reemplaza la imagen del núcleo de un proceso
exit(status): Termina la ejecución del proceso y devuelve el estado
s = sigaction(sig, &act, &oldact): Define la acción a realizar en las señales
s = sigreturn(&context): Regresa de una señal
s = sigprocmask(how, &set, &old): Examina o cambia la máscara de la señal
s = sigpending(set): Obtiene el conjunto de señales bloqueadas
s = sigsuspend(sigmask): Reemplaza la máscara de la señal y suspende el proceso
s = kill(pid, sig): Envía una señal a un proceso
residual = alarm(seconds): Establece el reloj de alarma
s = pause( ): Suspende el proceso que hizo la llamada hasta la siguiente señal
```

## Creación de un proceso
La llamada al sistema **fork** se usa como una función para crear un proceso que es un copia exacta (*mismas posiciones relativas, mismos datos e incluso mismo estado*) del **proceso padre** (*proceso que ejecutó el fork*).

Desde que se ejecuta el **fork**, ambos procesos tienen las mismas variables, pero son valores **independientes**, lo que implica que, si uno de los procesos **modifica la variable**, el otro proceso **no ve el cambio** en el dato porque son **direcciones virtuales** (*es decir, son iguales, pero no son los mismo*). El proceso padre no puede leer nada de ningún otro proceso, sin importar si es su hijo o no, solo puede acceder a sus **propias direcciones**.

La única diferencia entre el **proceso padre y el hijo** es que para el primero el **fork** devuelve el **PID** (*Process Identifier*) del hijo y para el segundo **devuelve un 0**. Esa diferencia es necesaria para saber separar los caminos y las funciones de cada proceso. Por eso hacemos:
```C
pid = fork()
if (pid == 0) {/*código del hijo*/}
else {/*código del padre*/}
```

Ejemplo de la no compartición de datos:
```C
main() {
	int par, x=0;
	if ((par=fork()) == -1){
		printf("Error en la ejecución del fork");
		exit(0);
	} else if (par==0) { // proceso hijo
		x=x+2;
		printf("\nProceso hijo, x= %d\n”, x);
	} else // proceso padre
		printf("\nProceso padre, x= %d\n”, x);
	printf("Finalizar\n");
}
```
Cuando se crea al **proceso hijo**, ambos procesos tienen en una de sus direcciones la **variable x con valor 0**. Sin embargo el hijo cambia el valor de **x a 2**, solo él ve el cambio, mientas que el apdre siguen con **x = 0**. A la hora de imprimir los resultados, **el orden es impredecible**, porque **ambos pelean por el shell** y es el **planificador** quien decide quien imprime antes. Fuera del *if* hay un **print que ambos van a imprimir** y no se sabrá quien escribió cada uno.

Puede darse el caso de que salga primero la frase del hijo, la frase del padre, uno de los mensajes de finalizar, el promt (*la parte del Shell donde se escribe un nuevo comando*) y después el otro finalizar. Esto se debe a que el **Shell solo espera a que el padre termine** (*proceso principal*) y no tiene en cuenta si el **hijo termina o no.**

En estos casos, se dice que el **proceso hijo se ha quedado huérfano** y presenta un problema ya que no tiene padre, condición que es obligatoria para todos menos para el **init**. Cuando esto ocurre el procesos hijo es **adoptado** por otro proceso que normalmente suele ser el **init** (*el proceso que se crea durante el arranque del sistema y que es el proceso padre principal o proceso raíz*). También puede ser que init cree un nuevo proceso que haga de **padrastro** en lugar de ser adoptados por el propio init.

```C
int fichero1, fichero2;
char caracter;

main(int argc, char* argv[]) {
	if (argc !=3) exit(1)
	fichero1=open(argv[1], 0444); //Lectura
	fichero2=open(argv[2], 0666); //Escritura
	if (fichero1==-1) printf("\nError al abrir el fichero 1\n");
	if (fichero2==-1) printf("\nError al abrir el fichero 2\n");
	fork();
	leer_escribir();
	exit(0);
}

int leer_escribir() {
	for (;;) {
	if(read(fichero1,&caracter,1)!=1)
		return(0);
	write(fichero2,&caracter,1);
	}
}
```
El padre abre ambos ficheros, uno de lectura y otro de escritura. AL hacer el **fork** , ambos procesos tienen 2 ficheros. Ambos tienen el mismo código a partir del fork y ejecutan la función. Con el lazo infinito se leen los carácter de un fichero y se copian en otro.

Los fichero tienen un puntero que marca el carácter al que se están apuntando, solo hay un puntero por archivo, no uno por proceso. Los dos procesos quieren hacer lo mismo, ambos leen y escriben, pero con el orden es impredecible, se puede producir lo siguiente:
El padre lee un carácter y almacena el dato e incrementa el puntero del archivo, pero justo ahí pierde la CPU. El hijo va a leer el siguiente carácter y escribe en el segundo fichero el carácter. D esta forma el segundo archivo no será igual al primero. Se dice que se ha producido una **carrera críticab entre ambos procesos**.

## Terminación de un proceso
Puede finalizar así:
- **Salida normal**: es una terminación **voluntaria**. Lo suele hacer cuando termina su trabajo y en la última línea que se ejecuta se utiliza la llamada al sistema **exit**. El entero que se emplea sirve para ver como terminó su ejecución desde el proceso padre, que lo puede estar esperando. Si no se coloca esta llamada al sistema en el código se **ejecuta por defecto**, que el lo que hace el main de forma implícita normalmente
- **Salida por error:** es una salida voluntaria, que puede darse por un uso **erróneo del programa**, como esperar un valor del usurario y que se introduzca uno incorrecto.
- **Salida por error fatal:** es involuntaria, de forma inesperada ocurre una **excepción** que no permite continuar con la ejecución como una división entre 0 o un acceso a una **dirección no válida**.
- **Eliminado por otro proceso:** otro proceso le envía una señal que lo obliga a terminar (*lo mata*) sin importar que le quede trabajo aún por hacer. Esto se puede hacer con la **llamada al sistema de kill**.

La forma mas recomendable para terminar un proceso es invocando a la llamada al sistema **exit** que tiene como argumento un entero que puede ser tomado por el padre para controlar si todo ha salido bien. Cuando se ejecuta un **exit** en el proceso se desconecta del árbol de procesos y no produce ninguna salida, pero sigue presente en la tabla de procesos.

## Espera a la terminación de un proceso.
El resultado de la finalización de un proceso puede ser recogido por el proceso padre, con **wait** o **waitpd**.

Cuando un proceso ejecuta la llamada al sistema **wait** lo que hace es esperara a que cualquiera de sus hijos termine (*solo hijos directos, no descendientes posteriores*) y con que finalice uno de ellos esta llamada ya retorna y se puede leer el valor que proporcionó el proceso al terminar (*valor del exit*). En el paso de ejecutar un **waitpd** se espera a un hijo en concreto, quedándose el padre bloqueado hasta que el hijo finalice. Si se pone un -1 en el argumento **pid**, funciona como un wait porque espera a cualquiera de sus hijos.

Un **proceso zombi** es un proceso que **ya ha terminado** su tarea, es decir, que está muerto, **pero no ha sido eliminado** del sistema, es decir, sigue en la tabla de procesos (*situada en el kernel*). Esto se debe a que los procesos solo se borran de la tabla cuando **su padre finaliza** o hasta que su padre ejecute un **wait** o un **waitpd** asociado a él. Todos los procesos al acabar pasan a ser **zombies** hasta que se realice una de las dos acciones que provocan su finalización de la tabla de procesos.

Es posible que un padre cree a un hijo y finalice antes el padre que el hijo, creando así un proceso **huérfano**. Cuando un huérfano finaliza, **no se convierte en zombi** porque ya no tiene un padre que esté esperando por él, a pesar de haber sido adoptado,  por lo que una vez terminado se elimina directamente de la tabla de procesos.

En el código siguiente se usa el fork de forma que el proceso padre crea un hijo que tiene unas tareas propias. EL hijo espera 4 segundos antes de ejecutar su exit con el 3 como valor de salida. EL padre lo único que hace es esperar al hijo. No es posible saber si el padre ejecuta antes el wait o el proceso hijo imprime por pantalla, pero lo que es seguro es que se ejecutan con muy poca diferencia de tiempo, pareciendo paralelas. El padre se queda esperando a que el hijo finalice por lo que es mensaje del padre se va a ver con una diferencia de 4 segundos desde que se imprimió el mensaje del hijo:
```C
main() {
	int pid, estado;
	if (fork()==0){
		printf(“\nMensaje 1\n”);
		sleep(4);
		exit(3);
	} else {
		pid = wait(&estado);
		printf(“\nFinalizar\n”);
	}
}
```

## Cambiar la imagen de un proceso
En el siguiente ejemplo se vuelve a mostrar el código de un **proceso padre** y su **hijo**, para hablar de las llamadas al sistema de **cambio de imagen** de los procesos, como es el caso de la familia **execv**.

Dado un proceso, el que las invoca, **borran toda su memoria menos el kernel** y lo cambian por otro ejecutable, ejecutando este nuevo código desde el principio. En el caso particular de abajo el hijo hace un cambio de imagen utilizando la función **execve** donde el primer parámetro es el **fichero ejecutable**, dirección donde está el código donde se va a color ahora en el proceso. Cuando termine, se ejecuta el exit correspondiente haciendo que el padre puede continuar.

Esto implica que el padre solo espera a su hijo, así que en el caso de que el hijo con su nueva imagen cree nuevos procesos, el padre no será consciente de ellos. Es posible que alguno de los descendientes del hijo aún no haya terminado cuando el hijo si termina, implicando también la finalización del padre y haciendo que se mezclen elementos del padre y de alguno de los descendientes.

```C
#define TRUE 1
while (TRUE) { /* se repite en forma indefinida */
	type_prompt(); /* muestra el indicador de comando en la pantalla */
	read_command(command, parameters); // lee la entrada de la terminal
	if (fork() !=0) { /* usa fork para el proceso hijo */
		/* Codigo del padre. */
		waitpid(-1, &status, 0); /* espera a que el hijo termine */
	} else { /* Codigo del hijo. */
		execve(command, parameters, 0); /*ejecuta el comando de cambio de imagen */
	}1
}
```

## Señales
Las **señales** son avisos que reciben los procesos acerca de eventos que pueden ocurrir en el sistema, y se suelen utilizar como **mecanismos de comunicación y/o sincronización entre procesos**. Estas están asociadas a unos pocos números enteros de forma que, cuando un proceso recibe una de llas, la identifica para determinar cuál es la causa del aviso. Son similares a las **interrupciones** pero con la diferencia de que **las interrupciones son asvisos que se realizan al S.O** mientras que las **señales estan dirigidas a un proceso**.

Un señal puede ser generada por: *otros procesos(kill), suscesos en el hardware, interrupciones del terminal(CONRTROL +C), notificaciones de E/S, alamas, etc.*

Cuando se recibe una señal se debe identificar y cada una de ellas tiene asociada un comportamiento por defecto. Esta acción se realiza en el proceso receptor de la señal formando parte de su **espacio virtual**.

```C
#include <signal.h>
main(){
	int a ;
	a = fork();
	if (a == 0) {
		while (1) {
		printf(“pid del proceso hijo = %d \n”, getpid());
		sleep(1);
		}
	}
	sleep(10);
	printf(“Terminación del proceso con pid = %d\n, a);
	kill(a, SIGTERM);
}
```
 En este ejemplo hay 2 procesos. EL hijo tiene un bucle infinito en el que imprime y después se bloquea durante un segundo. El padre se bloquea 10 segundos, imprime y envía al hijo una señal utilizando el pid del hijo para marcar el destinatario en la función **kill** y la señal que desea enviarle.

---
El uso de kill también se puede hacer desde la consola solo que su formato pasa a ser **kill-Señal pid**.


Es posible que se desee cambiar el comportamiento del proceso cuando recibe una señal, es por ello por lo que se utiliza la función **signal**. Esta función tiene 2 argumentos: la señal de la que se varía el comportamiento y un puntero a la función que se ejecutará cuando se reciba la señal (**signal(señal, puntero a la función manejadora)**) sin importar quién le envía la señal.

EN el caso de emplear signal y después querer restablecer la acción por defecto solo hay que ejecutar signal con **SIG_DFL** en el campo de la función manejadora. Lo mismo con **SIG_IGN** si se desea ignorar este tipo de señal.

También se puede emplear la llamada al sistema **sigaction** que da mayor flexibilidad ya que además de recibir los mismo parámetros que signal, también permite especificar otros parámetro y/o banderas para la gestión de la señal. Un ejemplo de uso de esta llamada es el siguiente: 
```C
#include <stdio.h>
#include <stdlib.h>
#include <signal.h>
main(){
	int codigo_error = 0;
	struct sigaction gestion;
	gestion.sa_handler = gestor; /* Manejador de la señal */
	gestion.sa_mask = 0; /* Máscara para tener en cuenta la señal o no */
	gestion.sa_flags = SA_ONESHOT; /* Bandera, solo resuelve la primera señal con el
manejador y el resto de veces que la reciba
actuará por defecto */
	codigo_error = sigaction (SIGINT, gestion, 0);
	if (codigo_error == SIG_ERR) {
		perror (“Error al definir el gestor de SIGINT”);
		exit(-1);
	}
/*Código del programa*/
	while(1);
}
void gestor (int señal){
	/*Código de manejo de la señal*/
}
```
Algunas señales comunes:
![[archivos/imagenes/Pasted image 20241001223027.png]]
## Implementación de Procesos
Un **grupo de procesos** es un proceso con sus hijo y sus respectivos descendientes. Es importante hablar de grupos porque en ocasiones es posible enviar señales al grupo en su totalidad, aunque las señales son tratadas de forma individual por cada uno de los procesos.

EL proceso **init** es especial porque es el único que **no tiene padre en el sistema** y el resto de los procesos son descendientes de él. El proceso **Shell** se crea cada vez que se abre una terminal y este crea más procesos según los comando que se ejecuten. En **Linux** los procesos siempre se pueden representar en forma de árbol debido a la jerarquía entre procesos.

Cada proceso tiene un estado en el cual se encuentra, que pueden estar en uno de los siguientes estados, representado con 2 bits en cada proceso.
- **En ejecución:** el proceso está **haciendo uso de la CPU** en este momento. Solo puede haber tantos procesos en este estado como CPUs tenga el sistema
- **Bloqueado:** el proceso no puede avanzar porque puede estar **esperando alguna condición**. No es candidato para utilizar la CPU, por lo que el **planificador** no puede elegirlo.
- **Listo/Preparado:** el proceso no está haciendo uso de la CPU por lo que no está avanzando, pero el **planificador** puede ponerlo a ejecutar en cualquier momento.
![[archivos/imagenes/Pasted image 20241003203816.png]]

Un proceso **en ejecución** puede pasar a **estado bloqueado** cuando espera una condición que le impide seguir su ejecución. El SO lo que hace ahora es ir a la tabla de procesos para trabajar con uno de los procesos que está **listo**, que ejecuta el que decide el **planificador**. Nunca va a ocurrir que un proceso bloqueado pase a ejecutarse, ya que debe pasar por el **estado listo** para que el **planificador** lo elija para ejecutarse, ni que un proceso lito pase a bloqueado.

Un proceso puede pasar de **estar ejecutándose** a estar en **estado listo**, esto se debe a que el SO puede quitarle la CPU para dársela a otro proceso.

En Unix el diagrama de los estados en los que se puede encontrar un proceso es mucho más complejo: 
![[archivos/imagenes/Pasted image 20241003204338.png]]

No todos los procesos son iguales: unos pueden ser del **usuario** y otros del SO(*demonios*). Además, los procesos tienen una **prioridad** asignada en la tabla de procesos, obteniendo mayor preferencia sobre otros cuando el **planificador** selecciona que proceso va a ir antes. Solo se le puede varias la prioridad a los procesos de usuario. La prioridad suele disminuir cuando mayor ser **su uso de CPU**.

Cuando un proceso ejecuta un *fscanf* pasa de estarse ejecutando a estado bloqueado porque hay que ir al disco, bloqueando así el proceso. Cuando finaliza la operación de acceso al disco se lanza una **interrupción** que provoca que el proceso que tenía ahora la CPU pase a **estado listo**. En **manejador de la interrupción** mira a qué proceso afecta la interrupción y lo desbloquea para pasarlo a estado listo. Una vez completado esto, el sistema ejecuta el planificador para ver a qué proceso se le concede la CPU disponible. Al menos hay dos candidatos listos (el que ejecutó el *fscanf* y era receptor de la interrupción y el proceso que al que se le quitó la CPU cuando llegó la interrupción). El **planificador** debe elegir entre ellos.


## Interrupciones (tiene que ver con el tema 5 pero lo explicó aquí)

Esta parte solo se centra en la **captura y resolución de las interrupciones**, obviando como se gestionan globalmente. Las interrupciones normalmente vienen lanzadas desde las **controladores de los dispositivos de E/S** aunque también están las de reloj (*quantums*).
![[archivos/imagenes/Pasted image 20241003205031.png]]

Cuando se recibe una interrupción habrá un proceso en ejecución. Cuando esta llega, hay que soltar a una rutina de la **zona de kernel**, por lo que hay que guardar en el **stack** la dirección de retorno. Después se salta a una rutina del sistema operativo llamada **manejadora de interrupciones** que detecta cual es la causa de la interrupción y salta a la rutina concreta para resolver este tipo de interrupción. Esta es tomada de una lista de direcciones de memoria, llamada **vector de interrupciones**.

Una vez identificada la rutina, se ejecuta y se retorna a la instrucción del proceso que se almacenó al inicio. Normalmente estas interrupciones van dirigidas a algún proceso en concreto que estaba esperando, (*en estado bloqueado*) y la interrupción funciona como aviso para cambiarle el estado a listo. Puede ser necesario volver a **lanzar el planificador.**



# Hilos
Los **hilos** (threads) son un concepto fundamental en la programación concurrente. Un hilo es una unidad de ejecución dentro de un proceso, que permite realizar tareas de forma simultánea dentro del mismo espacio de direcciones.
![[archivos/imagenes/Pasted image 20241022154236.png]]
### Diferencia entre Proceso e Hilo

Por defecto, un proceso tiene un único hilo de ejecución. Este hilo tiene acceso a todos los recursos del proceso, como la memoria, archivos abiertos, etc. Sin embargo, un proceso puede crear varios hilos para ejecutar partes diferentes de su código al mismo tiempo, cada uno accediendo a los mismos datos.

#### Proceso vs. Hilo
- **Proceso**: Tiene su propio espacio de direcciones, lo que implica que cada proceso tiene su propia copia de variables, archivos y otros recursos. Cuando se cambia de un proceso a otro (cambio de contexto), se requiere copiar el estado completo (registros, memoria, etc.), lo cual es costoso.
- **Hilo**: Comparte el mismo espacio de direcciones con otros hilos del mismo proceso, lo que permite que se comuniquen entre sí de manera más eficiente. El cambio de contexto entre hilos es más rápido, ya que comparten gran parte de la información del proceso.

### Ejecución en Hilos
Cuando un proceso tiene varios hilos:
- Si existe solo una CPU, el sistema operativo alterna entre los hilos (ejecución en **pseudo-paralelo**), lo que significa que parece que se ejecutan al mismo tiempo aunque no lo hacen en realidad.
- Si hay múltiples CPUs, cada hilo puede ejecutarse en paralelo en diferentes núcleos.

### Ventajas de los Hilos
1. **Menor costo de cambio de contexto**: Al compartir el espacio de direcciones, el cambio entre hilos dentro del mismo proceso es más rápido que entre procesos.
2. **Creación y destrucción más rápida**: Los hilos se crean y destruyen más rápido que los procesos, lo que reduce la sobrecarga cuando se necesita realizar tareas concurrentes.
3. **Colaboración más simple**: Dado que los hilos comparten memoria, es más fácil compartir información entre ellos en comparación con los procesos, que necesitan mecanismos como señales o memoria compartida.

### Ejemplo 1: Procesador de Textos
En un procesador de textos, un proceso puede tener varios hilos:
- Un hilo se encarga de gestionar la entrada del teclado.
- Otro hilo formatea el texto.
- Un tercer hilo guarda copias de seguridad en el disco.

Todos estos hilos operan en el mismo documento, ya que está almacenado en la memoria compartida del proceso. Mientras unos hilos realizan operaciones de E/S (entrada/salida), otro puede estar utilizando la CPU, aprovechando al máximo los recursos del sistema.

![[archivos/imagenes/Pasted image 20241022155406.png]]
### Ejemplo 2: Servidor Web
Un servidor web puede manejar múltiples solicitudes al mismo tiempo gracias a los hilos. Cada hilo puede atender una petición diferente de los usuarios, buscando la página solicitada en el servidor y devolviéndola al cliente sin interferir con otros hilos.
![[archivos/imagenes/Pasted image 20241022160249.png]]
### Estructura de un Hilo
Aunque los hilos comparten el espacio de direcciones del proceso al que pertenecen, cada hilo tiene su propio conjunto de recursos específicos:
- Contador de programa
- Pila de ejecución
- Conjunto de registros
Estos elementos son exclusivos de cada hilo y no se comparten.
![[archivos/imagenes/Pasted image 20241022160544.png]]
### Memoria Compartida
En el espacio de memoria compartida por los hilos de un proceso, existen variables globales accesibles por todos. Además, cada hilo puede tener variables locales que solo son accesibles por ese hilo. No obstante, si otro hilo conoce la dirección de memoria de una variable, también puede acceder a ella, ya que comparten el mismo espacio de direcciones.

### Hilo Principal
El **hilo principal** de un programa es generalmente el que comienza la ejecución (el `main`). Si este hilo crea nuevos hilos, el principal puede continuar su ejecución mientras los otros hilos ejecutan sus propias tareas en paralelo.

En resumen, los hilos permiten dividir la ejecución de un proceso en varias secuencias independientes que cooperan entre sí, lo que es ideal para realizar tareas concurrentes que requieren compartir información rápida y eficientemente.


### Funciones para el uso de hilos en C

#### 1. **`pthread_create()`**: Creación de hilos

La función `pthread_create()` se utiliza para crear un nuevo hilo dentro de un proceso en C.

```c
int pthread_create(pthread_t *hilo, const pthread_attr_t *atributos, void *(*funcion)(void *), void *argumento);
```

- **`pthread_t *hilo`**: Este primer argumento es un puntero a una variable de tipo `pthread_t`, que almacenará el identificador del hilo creado.
- **`const pthread_attr_t *atributos`**: Un puntero a una estructura que define los atributos del hilo, como su prioridad o tamaño de la pila. Si no se desea especificar atributos, se puede pasar `NULL` para usar los valores por defecto.
- **`void *(*funcion)(void *)`**: Aquí se pasa la función que será ejecutada por el hilo. Esta función debe aceptar un argumento de tipo puntero `void *` y devolver un puntero `void *`. Es obligatorio que las funciones de los hilos sigan esta firma.
- **`void *argumento`**: Este último argumento es un puntero a los datos que se desean pasar a la función del hilo. Es común pasar un puntero a una variable que contiene los datos que el hilo va a procesar.

#### Ejemplo: Creación de 10 hilos

```c
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>

#define NUMERO_DE_HILOS 10

void *imprimir_hola_mundo(void *tid) {
    printf("Hola mundo. Saludos del hilo %d\n", (int)(intptr_t)tid);
    pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
    pthread_t hilos[NUMERO_DE_HILOS];
    int estado, i;
    for (i = 0; i < NUMERO_DE_HILOS; i++) {
        printf("Aqui main. Creando hilo %d\n", i);
        estado = pthread_create(&hilos[i], NULL, imprimir_hola_mundo, (void *)(intptr_t)i);
        if (estado != 0) {
            printf("Ups. pthread_create devolvió el código de error %d\n", estado);
            exit(-1);
        }
    }
    pthread_exit(NULL); // Evitar que main termine antes de que los hilos acaben.
}
```

En este código:
- Se crean 10 hilos que ejecutan la función `imprimir_hola_mundo`.
- El hilo principal sigue ejecutándose mientras los hilos se crean, lo que puede causar que los valores impresos de `i` cambien antes de que el hilo lo lea, lo cual genera el problema de "índices confusos".

#### Problema con la variable `i`

En el ejemplo anterior, el valor de `i` cambia mientras los hilos están corriendo, porque el hilo principal no se detiene. Al usar `pthread_create()`, el hilo toma una referencia a `i`, pero como el hilo principal sigue incrementando `i`, los hilos pueden imprimir el valor incorrecto.

##### Solución 1: Usar `intptr_t`

En este caso, se convierte el valor de `i` a un tipo de datos `intptr_t` antes de pasarlo como argumento para evitar el problema de desincronización de índices.

#### 2. **`pthread_exit()`**: Terminación de un hilo

La función `pthread_exit()` permite que un hilo finalice su ejecución de forma controlada. Esta llamada es importante, ya que:
- El hilo que la invoca deja de ejecutarse, liberando los recursos asociados.
- Si no se invoca explícitamente, el hilo terminará cuando su función retorne.

```c
void pthread_exit(void *retorno);
```

- **`retorno`**: El valor de retorno que el hilo puede devolver a otros hilos que lo esperen.

#### 3. **`pthread_join()`**: Sincronización entre hilos

`pthread_join()` permite que un hilo espere a otro hilo para asegurarse de que termine su ejecución. Esto es útil cuando se necesita esperar que un hilo complete su tarea antes de continuar.

```c
int pthread_join(pthread_t hilo, void **retorno);
```

- **`hilo`**: El identificador del hilo que debe terminar.
- **`retorno`**: Un puntero que almacenará el valor devuelto por el hilo a través de `pthread_exit()`.

#### 4. **`pthread_yield()`**: Ceder la CPU

La llamada `pthread_yield()` permite que un hilo ceda voluntariamente la CPU para que otros hilos puedan ejecutarse. Es útil cuando un hilo no tiene tareas inmediatas y permite que otros hilos aprovechen el tiempo de CPU.

```c
int pthread_yield(void);
```

#### Ejemplo: Dividir el trabajo de un vector entre hilos

```c
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>

#define NUMERO_DE_HILOS 4
#define VECTOR_SIZE 100

int vector[VECTOR_SIZE];
int suma_parcial[NUMERO_DE_HILOS];

void *sumar_parte(void *i) {
    int inicio = ((intptr_t)i) * (VECTOR_SIZE / NUMERO_DE_HILOS);
    int fin = inicio + (VECTOR_SIZE / NUMERO_DE_HILOS);
    suma_parcial[(intptr_t)i] = 0;

    for (int j = inicio; j < fin; j++) {
        suma_parcial[(intptr_t)i] += vector[j];
    }

    pthread_exit(NULL);
}

int main() {
    pthread_t hilos[NUMERO_DE_HILOS];
    int estado;

    // Inicializar el vector
    for (int i = 0; i < VECTOR_SIZE; i++) {
        vector[i] = 1; // Ejemplo: llenar con unos para que la suma sea más sencilla
    }

    // Crear los hilos
    for (intptr_t i = 0; i < NUMERO_DE_HILOS; i++) {
        estado = pthread_create(&hilos[i], NULL, sumar_parte, (void *)i);
        if (estado != 0) {
            printf("Ups. pthread_create devolvió el código de error %d\n", estado);
            exit(-1);
        }
    }

    // Esperar a que todos los hilos terminen
    for (int i = 0; i < NUMERO_DE_HILOS; i++) {
        pthread_join(hilos[i], NULL);
    }

    // Sumar los resultados parciales
    int suma_total = 0;
    for (int i = 0; i < NUMERO_DE_HILOS; i++) {
        suma_total += suma_parcial[i];
    }

    printf("Suma total: %d\n", suma_total);

    pthread_exit(NULL);
}
```

En este código:
- Se dividen los elementos de un vector entre varios hilos para sumarlos de manera concurrente.
- Cada hilo suma una parte del vector, y luego el hilo principal espera a que terminen con `pthread_join()` y calcula la suma total.

### Resumen de funciones principales de hilos

- **`pthread_create()`**: Crea un nuevo hilo.
- **`pthread_exit()`**: Finaliza un hilo.
- **`pthread_join()`**: Espera a que un hilo específico termine.
- **`pthread_yield()`**: Cede voluntariamente la CPU.
- **`pthread_attr_init()`**: Inicializa una estructura de atributos para hilos.
- **`pthread_attr_destroy()`**: Libera una estructura de atributos de hilos.

## Hilos en el espacio de usuario:

En un sistema que utiliza **hilos en el espacio de usuario**, el kernel, que es el núcleo del sistema operativo, no tiene información directa sobre los hilos individuales que corren dentro de un proceso. El kernel solo conoce y maneja los **procesos** en general, y para cada proceso mantiene una entrada en su **tabla de procesos** (Process Table), que almacena toda la información relevante para gestionar un proceso, como su estado, prioridad, y recursos asignados. 

Por otro lado, la **gestión de los hilos** dentro de un proceso ocurre completamente en el **espacio de usuario**. Aquí, el código del proceso incluye un sistema de gestión de hilos propio, que controla la creación, ejecución y finalización de los hilos. Este código, normalmente implementado como una **biblioteca de hilos** (como una librería específica de hilos en C, por ejemplo), incluye funcionalidades que permiten a la aplicación gestionar sus propios hilos de manera interna, sin intervención del kernel.

#### Tabla de hilos
En este contexto, el proceso mantiene su propia **tabla de hilos**. Esta tabla es similar a la tabla de procesos del kernel, pero solo contiene información sobre los hilos que pertenecen a ese proceso en particular. La tabla de hilos almacena el estado de cada hilo, sus registros, su pila, y cualquier otra información relevante para gestionar el hilo. Sin embargo, **el kernel no tiene acceso a esta tabla** y no sabe cuántos hilos existen dentro del proceso o cómo están organizados.

#### Planificación y conmutación de hilos
Cuando hablamos de la ejecución de procesos en un sistema operativo, el **planificador del kernel** (scheduler) es el encargado de decidir qué proceso obtendrá el control de la CPU en cada momento. Sin embargo, cuando los hilos están gestionados en el espacio de usuario, **el planificador del proceso** se encarga de decidir qué hilo dentro de ese proceso se ejecutará cuando el proceso en general obtenga acceso a la CPU.

Este proceso se puede descomponer en dos niveles de planificación:

1. **Planificación de procesos (kernel)**: El kernel selecciona un proceso de la lista de procesos listos para ejecutar y le asigna la CPU. Aquí, el kernel no sabe cuántos hilos contiene el proceso ni cuál de esos hilos se ejecutará.
   
2. **Planificación de hilos (usuario)**: Una vez que el proceso ha sido seleccionado por el kernel para ejecutarse, el **planificador del espacio de usuario** selecciona qué hilo del proceso va a utilizar la CPU. Este planificador es parte del propio código del proceso y usa la tabla de hilos para gestionar su decisión.

![[archivos/imagenes/Pasted image 20241022165441.png]]
#### Bloqueo y cambios de contexto
Uno de los mayores inconvenientes de los hilos en el espacio de usuario es lo que sucede cuando uno de estos hilos realiza una operación **bloqueante**. Por ejemplo, si un hilo ejecuta una llamada bloqueante como `scanf()`, **todo el proceso se bloquea**. Esto es porque el kernel solo percibe el proceso como un todo, no tiene visibilidad sobre los hilos. El kernel interpreta que el proceso está bloqueado y **forzará un cambio de contexto** hacia otro proceso, suspendiendo la ejecución de todos los hilos de ese proceso, incluso si algunos de ellos podrían continuar ejecutándose.

#### Soluciones al problema del bloqueo
Para mitigar este problema de bloqueo, una práctica común es usar la función `pthread_yield()` justo antes de realizar una operación que potencialmente podría bloquear el proceso. **`pthread_yield()` cede la CPU** de forma voluntaria a otros hilos que necesiten ejecutarse. Además, algunas bibliotecas de hilos realizan comprobaciones previas antes de que se ejecute una operación que pueda bloquear, como revisar si un recurso está disponible antes de intentar acceder a él.

#### Ventajas y desventajas de los hilos en el espacio de usuario
1. **Ventajas**:
   - **Planificación personalizada**: Los hilos pueden ser gestionados y planificados de manera independiente al kernel, lo que permite implementar algoritmos de planificación personalizados para optimizar el rendimiento del proceso.
   - **Escalabilidad**: Los hilos en el espacio de usuario son más eficientes en términos de memoria, ya que el kernel no necesita mantener información sobre cada hilo, solo sobre el proceso en su conjunto.
   - **Menos cambios de contexto**: Al estar gestionados en el espacio de usuario, los hilos no requieren un cambio de contexto a nivel del kernel, lo que hace que su conmutación sea más rápida.

2. **Desventajas**:
   - **Bloqueo global del proceso**: Si un hilo realiza una operación bloqueante, todo el proceso se bloquea, suspendiendo la ejecución de todos los hilos.
   - **No hay paralelismo real**: Dado que el kernel no conoce la existencia de los hilos, no puede asignar diferentes hilos de un mismo proceso a diferentes CPUs, lo que significa que todos los hilos de un proceso se ejecutan en una sola CPU a la vez, lo que limita el paralelismo.

En resumen, los **hilos en el espacio de usuario** ofrecen mayor control y eficiencia para algunas aplicaciones, pero introducen desafíos en términos de manejo de bloqueos y escalabilidad a nivel de múltiples CPUs.



## Hilos en el espacio de kernel
Cuando los hilos son gestionados en el **espacio de kernel**, el kernel tiene control completo sobre todos los hilos de todos los procesos. Esto significa que tanto la **tabla de procesos** como la **tabla de hilos** (que contiene la información sobre cada hilo) están en el kernel. Esta tabla de hilos es similar a la de procesos, pero contiene la información específica de cada hilo, como su estado, registros, y la CPU asignada.

En este modelo:

- **El kernel gestiona los hilos directamente**: Puede asignar tiempos de CPU (quantums) a hilos individuales, no solo a procesos completos. Esto mejora la eficiencia del uso de los recursos, ya que el kernel puede seleccionar cualquier hilo de cualquier proceso para ejecutar, sin importar de qué proceso provenga.

- **Cambio entre hilos**: El kernel puede planificar la ejecución de cualquier hilo en cualquier momento. Puede cambiar de un hilo a otro, incluso si estos hilos pertenecen a distintos procesos. Este cambio de hilos es más flexible que en el espacio de usuario, donde solo el proceso decide qué hilo ejecuta.

- **Bloqueo de un hilo**: Si un hilo se bloquea (por ejemplo, al esperar una entrada o salida), **solo ese hilo se bloquea**, no afecta al resto de los hilos del mismo proceso. En el modelo de hilos en el espacio de usuario, el bloqueo de un hilo podía hacer que todo el proceso se bloquee, afectando a otros hilos dentro de ese proceso.

Sin embargo, este enfoque también tiene algunas desventajas:

- **Tabla de hilos muy grande**: Como el kernel gestiona todos los hilos de todos los procesos, la tabla de hilos puede llegar a ser **muy grande**. Su tamaño mínimo es equivalente al de la tabla de procesos, pero puede aumentar mucho más dependiendo de la cantidad de hilos que existan en el sistema.

- **Coste adicional de rendimiento**: Al gestionarse los hilos en el espacio de kernel, cada vez que se hace un cambio de contexto entre hilos o procesos, es necesario realizar un **trap** (una trampa al sistema) para pasar del espacio de usuario al espacio de kernel y viceversa. Este cambio entre zonas conlleva un coste adicional en términos de tiempo, lo que puede hacer que la gestión de hilos sea más **lenta** en comparación con los hilos gestionados completamente en el espacio de usuario.
![[archivos/imagenes/Pasted image 20241022170224.png]]
## Implementaciones Híbridas

Las implementaciones híbridas son una solución intermedia entre las implementaciones de hilos en el espacio de usuario y las de hilos en el espacio de kernel. Estas combinan lo mejor de ambos enfoques, permitiendo un equilibrio entre eficiencia y flexibilidad.

En una **implementación híbrida**, se utiliza una combinación de hilos gestionados en el espacio de kernel y en el espacio de usuario:

1. **Hilos de kernel**: Solo algunos de los hilos del proceso son gestionados directamente por el kernel. Estos hilos son los que aparecen en la **tabla de hilos del kernel**, y son los únicos que el kernel conoce y administra directamente. Estos hilos son denominados **hilos de kernel**. El tamaño de esta tabla es limitado, lo que controla la cantidad de información que el kernel necesita manejar.

2. **Hilos de usuario**: Además de los hilos de kernel, el proceso también puede tener **hilos gestionados en el espacio de usuario**. Estos hilos no son visibles para el kernel directamente, sino que se agrupan en torno a los hilos de kernel. Un grupo de hilos de usuario "compite" por el uso de uno de los hilos de kernel, de forma que varios hilos de usuario pueden compartir un único hilo de kernel.

3. **Agrupación de hilos**: Los hilos de usuario se agrupan en conjuntos que compiten entre sí para obtener tiempo de ejecución en los hilos de kernel. Dentro de cada grupo, un planificador en el espacio de usuario decide cuál de los hilos de usuario debe ejecutar en el hilo de kernel asignado. De esta manera, se limita la cantidad de hilos que el kernel necesita gestionar directamente, manteniendo una tabla de hilos pequeña.

#### Ventajas:

- **Optimización del uso de recursos**: Al tener solo un número limitado de hilos gestionados por el kernel, se reduce la sobrecarga de administración. Los hilos de usuario se gestionan con mayor flexibilidad en el espacio de usuario.
  
- **Flexibilidad y escalabilidad**: La implementación híbrida permite crear muchos hilos de usuario sin aumentar de forma significativa la carga en el kernel, ya que solo un subconjunto de esos hilos tiene representación en la tabla de hilos del kernel.

#### Desventajas:

- **Competencia entre hilos**: Los hilos de usuario dentro de un mismo grupo compiten por los recursos del hilo de kernel. Esto puede generar una **penalización por la competencia** o "pelea" entre hilos, ya que no todos los hilos de usuario pueden ejecutarse simultáneamente, y pueden producirse cuellos de botella en el acceso al CPU.

En resumen, las implementaciones híbridas buscan un **equilibrio entre eficiencia y control**, limitando el número de hilos gestionados por el kernel mientras mantienen la posibilidad de crear muchos hilos de usuario. Esto permite aprovechar algunas de las ventajas de los hilos en el espacio de kernel (como evitar el bloqueo del proceso completo) mientras se limita la carga administrativa.

![[archivos/imagenes/Pasted image 20241022170442.png]]

## Hilos emergentes
Los hilos emergentes se crean dentro de un proceso cuando llega un mensaje a través de la red, proveniente de otro proceso que se está ejecutando en otra máquina. La función de este hilo es leer la información del mensaje y una vez hecho esto, se elimina.
![[archivos/imagenes/Pasted image 20241022170527.png]]

## Hilos en Linux
Vamos a desglosar y explicar **detalladamente** cómo funcionan los hilos en Linux y cómo la función `clone()` permite crearlos con diferentes grados de compartición, tanto de procesos como de hilos.

### Hilos en Linux: Espacio de Kernel

En **Linux**, los hilos se gestionan en el **espacio de kernel**, lo que significa que el kernel tiene conocimiento directo de todos los hilos y es responsable de su planificación, gestión y sincronización. 

A diferencia de otros sistemas donde los hilos de usuario y del kernel se manejan por separado, en Linux, los hilos no son una entidad completamente distinta de los procesos. Los hilos en Linux son en realidad procesos ligeros, lo que significa que son **instancias del mismo proceso** que comparten recursos como la memoria, pero que se pueden programar y ejecutar de manera independiente. El kernel los trata como **procesos con ciertas propiedades compartidas** (memoria, archivos abiertos, etc.).

### La función `clone()`

La función `clone()` en Linux es una herramienta muy poderosa que se utiliza para crear tanto **procesos** como **hilos**. La diferencia entre un proceso y un hilo radica en el **nivel de compartición de recursos**. La función `clone()` te permite decidir qué recursos se comparten entre el proceso padre y el hijo/hilo, dependiendo de las **banderas** que se pasen como argumento.

#### Sintaxis de `clone()`

```c
int clone(int (*func)(void *), void *stack, int flags, void *arg);
```

- **func**: Es un puntero a la función que el nuevo proceso o hilo ejecutará.
- **stack**: Un puntero al espacio de memoria donde se almacenará la pila del nuevo proceso o hilo.
- **flags**: Las banderas que especifican qué recursos se compartirán entre el proceso padre y el hijo/hilo.
- **arg**: Un argumento que se pasa a la función `func`.

La función `clone()` **internamente utiliza una llamada al sistema `fork`**, pero con mayor flexibilidad. La clave está en las **banderas** del argumento `flags`, que permiten especificar qué partes del estado del proceso padre se compartirán con el nuevo hilo o proceso.

### Banderas de `clone()`: Grado de Compartición

Dependiendo de las banderas que se utilicen, `clone()` puede crear un **proceso** o un **hilo** dentro de un proceso. Las banderas más comunes son las siguientes:

- **`CLONE_VM`**: Comparte el espacio de direcciones (memoria). Esto es esencial para los hilos, ya que los hilos dentro de un proceso comparten el mismo espacio de memoria. Si esta bandera está activa, el nuevo hilo o proceso compartirá la misma memoria que el proceso padre.
  
- **`CLONE_FS`**: Comparte las referencias a los sistemas de archivos (directorio de trabajo, máscara de creación de archivos). Esto significa que ambos, el proceso padre y el nuevo hilo o proceso, verán el mismo directorio actual.

- **`CLONE_FILES`**: Comparte las tablas de descriptores de archivos abiertos. Si esta bandera está activa, el nuevo hilo o proceso heredará todos los archivos abiertos del proceso padre.

- **`CLONE_SIGHAND`**: Comparte los manejadores de señales. Los hilos dentro de un proceso suelen compartir los manejadores de señales, lo que significa que si un hilo recibe una señal, el proceso completo puede manejarla.

- **`CLONE_THREAD`**: Crea un hilo en lugar de un proceso separado. Este hilo compartirá completamente el estado con el proceso padre, excepto el estado de los registros de CPU y la pila, que son únicos para cada hilo.

### ¿Qué se crea: Proceso o Hilo?

Dependiendo de las **combinaciones de banderas**, `clone()` puede crear un **nuevo proceso** o un **nuevo hilo**. Veamos los dos casos:

1. **Creación de un nuevo proceso**: Si no se utiliza ninguna de las banderas mencionadas (o solo se activan algunas), el `clone()` creará un **proceso nuevo**, similar a lo que hace `fork()`. El nuevo proceso tendrá su propio espacio de memoria, archivos, manejadores de señales, etc.

2. **Creación de un nuevo hilo**: Si se utilizan banderas como `CLONE_VM`, `CLONE_FS`, `CLONE_FILES`, `CLONE_SIGHAND` y `CLONE_THREAD`, entonces el `clone()` creará un **hilo** dentro del proceso actual. En este caso, el nuevo hilo compartirá todos los recursos con el proceso padre, pero tendrá su propio contexto de ejecución (su propia pila y registros).

### Ejemplo Práctico

Supongamos que queremos crear un **hilo** usando `clone()`:

```c
#define _GNU_SOURCE
#include <sched.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int hilo_funcion(void *arg) {
    printf("Hilo: ¡Hola, soy un hilo!\n");
    return 0;
}

int main() {
    const int tamaño_pila = 1024 * 1024;  // Tamaño de la pila del nuevo hilo.
    void *pila_hilo = malloc(tamaño_pila);
    
    if (!pila_hilo) {
        perror("No se pudo asignar memoria para la pila");
        exit(1);
    }

    // Crear un nuevo hilo con clone
    if (clone(hilo_funcion, pila_hilo + tamaño_pila, CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | CLONE_THREAD, NULL) == -1) {
        perror("Error al crear hilo con clone");
        exit(1);
    }

    // Esperar un poco para que el hilo termine
    sleep(1);
    printf("Proceso principal: ¡El hilo ha terminado!\n");

    free(pila_hilo);
    return 0;
}
```

En este ejemplo:

- **`hilo_funcion`**: Es la función que el nuevo hilo ejecutará.
- **`pila_hilo`**: Es el espacio en memoria para la pila del nuevo hilo.
- **`flags`**: Se utilizan las banderas `CLONE_VM`, `CLONE_FS`, `CLONE_FILES`, `CLONE_SIGHAND` y `CLONE_THREAD` para indicar que queremos crear un **hilo** y no un proceso independiente.

### Resumen

- En Linux, los **hilos** se gestionan en el **espacio de kernel**, lo que significa que el kernel tiene conocimiento directo de ellos y puede planificarlos de manera eficiente.
- La función `clone()` se usa para crear tanto **procesos** como **hilos**, dependiendo de las **banderas** que se utilicen.
- Las **banderas** permiten controlar qué recursos (memoria, archivos, señales, etc.) se comparten entre el proceso padre y el nuevo hilo o proceso.
- Si se activan las banderas adecuadas, se puede crear un **hilo** que comparta recursos con el proceso padre. De lo contrario, se creará un **nuevo proceso**.

En resumen, `clone()` es una herramienta versátil que ofrece un control granular sobre la creación de hilos y procesos en Linux.